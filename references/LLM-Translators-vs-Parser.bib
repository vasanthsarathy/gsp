@article{ahnCanNotSay,
  title = {Do {{As I Can}}, {{Not As I Say}}: {{Grounding Language}} in {{Robotic Affordances}}},
  author = {Ahn, Michael and Brohan, Anthony and Brown, Noah and Chebotar, Yevgen and Cortes, Omar and David, Byron and Finn, Chelsea and Fu, Chuyuan and Gopalakrishnan, Keerthana and Hausman, Karol and Herzog, Alex and Ho, Daniel and Hsu, Jasmine and Ibarz, Julian and Ichter, Brian and Irpan, Alex and Jang, Eric and Ruano, Rosario Jauregui and Jeffrey, Kyle and Jesmonth, Sally and Joshi, Nikhil J and Julian, Ryan and Kalashnikov, Dmitry and Kuang, Yuheng and Lee, Kuang-Huei and Levine, Sergey and Lu, Yao and Luu, Linda and Parada, Carolina and Pastor, Peter and Quiambao, Jornell and Rao, Kanishka and Rettinghouse, Jarek and Reyes, Diego and Sermanet, Pierre and Sievers, Nicolas and Tan, Clayton and Toshev, Alexander and Vanhoucke, Vincent and Xia, Fei and Xiao, Ted and Xu, Peng and Xu, Sichun and Yan, Mengyuan and Zeng, Andy},
  abstract = {Large language models can encode a wealth of semantic knowledge about the world. Such knowledge could be extremely useful to robots aiming to act upon high-level, temporally extended instructions expressed in natural language. However, a significant weakness of language models is that they lack real-world experience, which makes it difficult to leverage them for decision making within a given embodiment. For example, asking a language model to describe how to clean a spill might result in a reasonable narrative, but it may not be applicable to a particular agent, such as a robot, that needs to perform this task in a particular environment. We propose to provide real-world grounding by means of pretrained skills, which are used to constrain the model to propose natural language actions that are both feasible and contextually appropriate. The robot can act as the language model's ``hands and eyes,'' while the language model supplies high-level semantic knowledge about the task. We show how low-level skills can be combined with large language models so that the language model provides high-level knowledge about the procedures for performing complex and temporally extended instructions, while value functions associated with these skills provide the grounding necessary to connect this knowledge to a particular physical environment. We evaluate our method on a number of real-world robotic tasks, where we show the need for real-world grounding and that this approach is capable of completing long-horizon, abstract, natural language instructions on a mobile manipulator. The project's website, video, and open source can be found at say-can.github.io.},
  langid = {english},
  file = {/home/vsarathy/Zotero/storage/76AGU3FI/Ahn et al. - Do As I Can, Not As I Say Grounding Language in R.pdf}
}

@article{arnoldInformationStructureLinguistic2013,
  title = {Information {{Structure}}: {{Linguistic}}, {{Cognitive}}, and {{Processing Approaches}}},
  shorttitle = {Information {{Structure}}},
  author = {Arnold, Jennifer E. and Kaiser, Elsi and Kahn, Jason M. and Kim, Lucy Kyoungsook},
  year = {2013},
  journal = {Wiley interdisciplinary reviews. Cognitive science},
  volume = {4},
  number = {4},
  pages = {403--413},
  issn = {1939-5078},
  doi = {10.1002/wcs.1234},
  urldate = {2023-07-26},
  abstract = {Language form varies as a result of the information being communicated. Some of the ways in which it varies include word order, referential form, morphological marking, and prosody. The relevant categories of information include the way a word or its referent have been used in context, for example whether a particular referent has been previously mentioned or not, and whether it plays a topical role in the current utterance or discourse. We first provide a broad review of linguistic phenomena that are sensitive to information structure. We then discuss several theoretical approaches to explaining information structure: information status as a part of the grammar; information status as a representation of the speaker's and listener's knowledge of common ground and/or the knowledge state of other discourse participants; and the optimal systems approach. These disparate approaches reflect the fact that there is little consensus in the field about precisely which information status categories are relevant, or how they should be represented. We consider possibilities for future work to bring these lines of work together in explicit psycholinguistic models of how people encode information status and use it for language production and comprehension.},
  pmcid = {PMC4491328},
  pmid = {26150905},
  file = {/home/vsarathy/Zotero/storage/STJEFMSL/Arnold et al. - 2013 - Information Structure Linguistic, Cognitive, and .pdf}
}

@inproceedings{baral2011using,
  title = {Using Inverse {{$\lambda$}} and Generalization to Translate English to Formal Languages},
  booktitle = {Proceedings of the Ninth International Conference on Computational Semantics},
  author = {Baral, Chitta and Dzifcak, Juraj and Gonzalez, Marcos Alvarez and Zhou, Jiayu},
  year = {2011},
  pages = {35--44},
  publisher = {{Association for Computational Linguistics}}
}

@book{chaiLanguageActionInteractive2018,
  title = {Language to {{Action}}: {{Towards Interactive Task Learning}} with {{Physical Agents}}},
  shorttitle = {Language to {{Action}}},
  author = {Chai, Joyce and Gao, Qiaozi and She, Lanbo and Yang, Shaohua and {Saba-Sadiya}, Sari and Xu, Guangyue},
  year = {2018},
  month = jul,
  pages = {9},
  doi = {10.24963/ijcai.2018/1},
  abstract = {Language communication plays an important role in human learning and knowledge acquisition. With the emergence of a new generation of cognitive robots, empowering these robots to learn directly from human partners becomes increasingly important. This paper gives a brief introduction to interactive task learning where humans can teach physical agents new tasks through natural language communication and action demonstration. It discusses research challenges and opportunities in language and communication grounding that are critical in this process. It further highlights the importance of commonsense knowledge, particularly the very basic physical causality knowledge, in grounding language to perception and action.},
  file = {/home/vsarathy/Zotero/storage/H23R3R6X/Chai et al. - 2018 - Language to Action Towards Interactive Task Learn.pdf}
}

@article{changDRSPIDERDIAGNOSTIC2023,
  title = {{{DR}}.{{SPIDER}}: {{A DIAGNOSTIC EVALUATION BENCH- MARK TOWARDS TEXT-TO-SQL ROBUSTNESS}}},
  author = {Chang, Shuaichen and Wang, Jun and Dong, Mingwen and Pan, Lin and Zhu, Henghui and Li, Alexander Hanbo and Lan, Wuwei and Zhang, Sheng and Jiang, Jiarong and Lilien, Joseph and Ash, Steve and Wang, William and Wang, Zhiguo and Castelli, Vittorio and Xiang, Bing and Ng, Patrick},
  year = {2023},
  abstract = {Neural text-to-SQL models have achieved remarkable performance in translating natural language questions into SQL queries. However, recent studies reveal that text-to-SQL models are vulnerable to task-specific perturbations. Previous curated robustness test sets usually focus on individual phenomena. In this paper, we propose a comprehensive robustness benchmark1 based on Spider, a cross-domain text-to-SQL benchmark, to diagnose the model robustness. We design 17 perturbations on databases, natural language questions, and SQL queries to measure the robustness from different angles. In order to collect more diversified natural question perturbations, we utilize large pretrained language models (PLMs) to simulate human behaviors in creating natural questions. We conduct a diagnostic study of the state-of-the-art models on the robustness set. Experimental results reveal that even the most robust model suffers from a 14.0\% performance drop overall and a 50.7\% performance drop on the most challenging perturbation. We also present a breakdown analysis regarding text-to-SQL model designs and provide insights for improving model robustness.},
  langid = {english},
  file = {/home/vsarathy/Zotero/storage/S3RELPAJ/Chang et al. - 2023 - DR.SPIDER A DIAGNOSTIC EVALUATION BENCH- MARK TOW.pdf}
}

@article{clarkWideCoverageEfficientStatistical2007,
  title = {Wide-{{Coverage Efficient Statistical Parsing}} with {{CCG}} and {{Log-Linear Models}}},
  author = {Clark, Stephen and Curran, James R.},
  year = {2007},
  journal = {Computational Linguistics},
  volume = {33},
  number = {4},
  pages = {493--552},
  doi = {10.1162/coli.2007.33.4.493},
  urldate = {2023-10-20},
  file = {/home/vsarathy/Zotero/storage/2K93M3X2/Clark and Curran - 2007 - Wide-Coverage Efficient Statistical Parsing with C.pdf}
}

@misc{dettmersQLoRAEfficientFinetuning2023,
  title = {{{QLoRA}}: {{Efficient Finetuning}} of {{Quantized LLMs}}},
  shorttitle = {{{QLoRA}}},
  author = {Dettmers, Tim and Pagnoni, Artidoro and Holtzman, Ari and Zettlemoyer, Luke},
  year = {2023},
  month = may,
  number = {arXiv:2305.14314},
  eprint = {2305.14314},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2305.14314},
  urldate = {2023-10-20},
  abstract = {We present QLoRA, an efficient finetuning approach that reduces memory usage enough to finetune a 65B parameter model on a single 48GB GPU while preserving full 16-bit finetuning task performance. QLoRA backpropagates gradients through a frozen, 4-bit quantized pretrained language model into Low Rank Adapters\textasciitilde (LoRA). Our best model family, which we name Guanaco, outperforms all previous openly released models on the Vicuna benchmark, reaching 99.3\% of the performance level of ChatGPT while only requiring 24 hours of finetuning on a single GPU. QLoRA introduces a number of innovations to save memory without sacrificing performance: (a) 4-bit NormalFloat (NF4), a new data type that is information theoretically optimal for normally distributed weights (b) double quantization to reduce the average memory footprint by quantizing the quantization constants, and (c) paged optimziers to manage memory spikes. We use QLoRA to finetune more than 1,000 models, providing a detailed analysis of instruction following and chatbot performance across 8 instruction datasets, multiple model types (LLaMA, T5), and model scales that would be infeasible to run with regular finetuning (e.g. 33B and 65B parameter models). Our results show that QLoRA finetuning on a small high-quality dataset leads to state-of-the-art results, even when using smaller models than the previous SoTA. We provide a detailed analysis of chatbot performance based on both human and GPT-4 evaluations showing that GPT-4 evaluations are a cheap and reasonable alternative to human evaluation. Furthermore, we find that current chatbot benchmarks are not trustworthy to accurately evaluate the performance levels of chatbots. A lemon-picked analysis demonstrates where Guanaco fails compared to ChatGPT. We release all of our models and code, including CUDA kernels for 4-bit training.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning},
  file = {/home/vsarathy/Zotero/storage/W36BFV6L/Dettmers et al. - 2023 - QLoRA Efficient Finetuning of Quantized LLMs.pdf;/home/vsarathy/Zotero/storage/B5PTCFDT/2305.html}
}

@inproceedings{dzifcakWhatHowIt2009,
  title = {What to Do and How to Do It: {{Translating}} Natural Language Directives into Temporal and Dynamic Logic Representation for Goal Management and Action Execution},
  shorttitle = {What to Do and How to Do It},
  booktitle = {2009 {{IEEE International Conference}} on {{Robotics}} and {{Automation}}},
  author = {Dzifcak, J. and Scheutz, M. and Baral, C. and Schermerhorn, P.},
  year = {2009},
  month = may,
  pages = {4163--4168},
  publisher = {{IEEE}},
  address = {{Kobe}},
  doi = {10.1109/ROBOT.2009.5152776},
  urldate = {2023-10-20},
  abstract = {Robots that can be given instructions in spoken language need to be able to parse a natural language utterance quickly, determine its meaning, generate a goal representation from it, check whether the new goal conflicts with existing goals, and if acceptable, produce an action sequence to achieve the new goal (ideally being sensitive to the existing goals).},
  isbn = {978-1-4244-2788-8},
  langid = {english},
  file = {/home/vsarathy/Zotero/storage/9L5L78LD/Dzifcak et al. - 2009 - What to do and how to do it Translating natural l.pdf}
}

@article{evtikhievOutBLEUHow2023,
  title = {Out of the {{BLEU}}: How Should We Assess Quality of the {{Code Generation}} Models?},
  shorttitle = {Out of the {{BLEU}}},
  author = {Evtikhiev, Mikhail and Bogomolov, Egor and Sokolov, Yaroslav and Bryksin, Timofey},
  year = {2023},
  month = sep,
  journal = {Journal of Systems and Software},
  volume = {203},
  eprint = {2208.03133},
  primaryclass = {cs},
  pages = {111741},
  issn = {01641212},
  doi = {10.1016/j.jss.2023.111741},
  urldate = {2023-10-18},
  abstract = {In recent years, researchers have created and introduced a significant number of various code generation models. As human evaluation of every new model version is unfeasible, the community adopted automatic evaluation metrics such as BLEU to approximate the results of human judgement. These metrics originate from the machine translation domain and it is unclear whether they are applicable for the code generation tasks and how well they agree with the human evaluation on this task. There are also other metrics, CodeBLEU and RUBY, developed to estimate the similarity of code, that take into account the properties of source code. However, for these metrics there are hardly any studies on their agreement with the human evaluation. Despite all that, minimal differences in the metric scores have been used in recent papers to claim superiority of some code generation models over the others. In this paper, we present a study on the applicability of six metrics -- BLEU, ROUGE-L, METEOR, ChrF, CodeBLEU, and RUBY -- for evaluation of code generation models. We conduct a study on two different code generation datasets and use human annotators to assess the quality of all models run on these datasets. The results indicate that for the CoNaLa dataset of Python one-liners, none of the metrics can correctly emulate human judgement on which model is better with {$>$}95\% certainty if the difference in model scores is less than 5 points. For the HearthStone dataset, which consists of classes of a particular structure, a difference in model scores of at least 2 points is enough to claim the superiority of one model over the other. Our findings suggest that the ChrF metric is a better fit for the evaluation of code generation models than the commonly used BLEU and CodeBLEU. Yet, finding a metric for code generation that closely agrees with humans requires additional work.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Computer Science - Software Engineering},
  file = {/home/vsarathy/Zotero/storage/UIULBQ8P/Evtikhiev et al. - 2023 - Out of the BLEU how should we assess quality of t.pdf;/home/vsarathy/Zotero/storage/KBCAQLKE/2208.html}
}

@misc{fengSentenceSimplificationLarge2023,
  title = {Sentence {{Simplification}} via {{Large Language Models}}},
  author = {Feng, Yutao and Qiang, Jipeng and Li, Yun and Yuan, Yunhao and Zhu, Yi},
  year = {2023},
  month = feb,
  number = {arXiv:2302.11957},
  eprint = {2302.11957},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2023-07-05},
  abstract = {Sentence Simplification aims to rephrase complex sentences into simpler sentences while retaining original meaning. Large Language models (LLMs) have demonstrated the ability to perform a variety of natural language processing tasks. However, it is not yet known whether LLMs can be served as a high-quality sentence simplification system. In this work, we empirically analyze the zero-/few-shot learning ability of LLMs by evaluating them on a number of benchmark test sets. Experimental results show LLMs outperform state-of-the-art sentence simplification methods, and are judged to be on a par with human annotators.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/home/vsarathy/Zotero/storage/2UP2D25E/Feng et al. - 2023 - Sentence Simplification via Large Language Models.pdf;/home/vsarathy/Zotero/storage/YXIJFQXA/2302.html}
}

@inproceedings{finegan-dollakImprovingTexttoSQLEvaluation2018,
  title = {Improving {{Text-to-SQL Evaluation Methodology}}},
  booktitle = {Proceedings of the 56th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} ({{Volume}} 1: {{Long Papers}})},
  author = {{Finegan-Dollak}, Catherine and Kummerfeld, Jonathan K. and Zhang, Li and Ramanathan, Karthik and Sadasivam, Sesh and Zhang, Rui and Radev, Dragomir},
  year = {2018},
  eprint = {1806.09029},
  primaryclass = {cs},
  pages = {351--360},
  doi = {10.18653/v1/P18-1033},
  urldate = {2023-10-18},
  abstract = {To be informative, an evaluation must measure how well systems generalize to realistic unseen data. We identify limitations of and propose improvements to current evaluations of text-to-SQL systems. First, we compare human-generated and automatically generated questions, characterizing properties of queries necessary for real-world applications. To facilitate evaluation on multiple datasets, we release standardized and improved versions of seven existing datasets and one new text-to-SQL dataset. Second, we show that the current division of data into training and test sets measures robustness to variations in the way questions are asked, but only partially tests how well systems generalize to new queries; therefore, we propose a complementary dataset split for evaluation of future work. Finally, we demonstrate how the common practice of anonymizing variables during evaluation removes an important challenge of the task. Our observations highlight key difficulties, and our methodology enables effective measurement of future development.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Databases,H.2.3,H.3.4,I.2.1,I.2.7},
  file = {/home/vsarathy/Zotero/storage/8LLNXAVU/Finegan-Dollak et al. - 2018 - Improving Text-to-SQL Evaluation Methodology.pdf;/home/vsarathy/Zotero/storage/YW2BLUGP/1806.html}
}

@article{gundelCognitiveStatusForm1993,
  title = {Cognitive {{Status}} and the {{Form}} of {{Referring Expressions}} in {{Discourse}}},
  author = {Gundel, Jeanette K. and Hedberg, Nancy and Zacharski, Ron},
  year = {1993},
  journal = {Language},
  volume = {69},
  number = {2},
  eprint = {416535},
  eprinttype = {jstor},
  pages = {274--307},
  publisher = {{Linguistic Society of America}},
  issn = {0097-8507},
  doi = {10.2307/416535},
  urldate = {2023-10-20},
  abstract = {In this paper we propose six implicationally related cognitive statuses relevant for explicating the use of referring expressions in natural language discourse. These statuses are the conventional meanings signalled by determiners and pronouns, and interaction of the statuses with Grice's Maxim of Quantity accounts for the actual distribution and interpretation of forms when necessary conditions for the use of more than one form are met. This proposal is supported by an empirical study of the distribution of referring expressions in naturally occurring discourse in five languages-English, Japanese, Mandarin Chinese, Russian, and Spanish.},
  file = {/home/vsarathy/Zotero/storage/AUJMHANA/Gundel et al. - 1993 - Cognitive Status and the Form of Referring Express.pdf}
}

@misc{huangGroundedDecodingGuiding2023,
  title = {Grounded {{Decoding}}: {{Guiding Text Generation}} with {{Grounded Models}} for {{Robot Control}}},
  shorttitle = {Grounded {{Decoding}}},
  author = {Huang, Wenlong and Xia, Fei and Shah, Dhruv and Driess, Danny and Zeng, Andy and Lu, Yao and Florence, Pete and Mordatch, Igor and Levine, Sergey and Hausman, Karol and Ichter, Brian},
  year = {2023},
  month = mar,
  number = {arXiv:2303.00855},
  eprint = {2303.00855},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2023-06-01},
  abstract = {Recent progress in large language models (LLMs) has demonstrated the ability to learn and leverage Internet-scale knowledge through pre-training with autoregressive models. Unfortunately, applying such models to settings with embodied agents, such as robots, is challenging due to their lack of experience with the physical world, inability to parse non-language observations, and ignorance of rewards or safety constraints that robots may require. On the other hand, language-conditioned robotic policies that learn from interaction data can provide the necessary grounding that allows the agent to be correctly situated in the real world, but such policies are limited by the lack of high-level semantic understanding due to the limited breadth of the interaction data available for training them. Thus, if we want to make use of the semantic knowledge in a language model while still situating it in an embodied setting, we must construct an action sequence that is both likely according to the language model and also realizable according to grounded models of the environment. We frame this as a problem similar to probabilistic filtering: decode a sequence that both has high probability under the language model and high probability under a set of grounded model objectives. We demonstrate this guided decoding strategy is able to solve complex, long-horizon embodiment tasks in a robotic setting by leveraging the knowledge of both models. The project's website can be found at grounded-decoding.github.io.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Robotics},
  file = {/home/vsarathy/Zotero/storage/HSAG3LLC/Huang et al. - 2023 - Grounded Decoding Guiding Text Generation with Gr.pdf;/home/vsarathy/Zotero/storage/R6HS5BPU/2303.html}
}

@misc{huangInnerMonologueEmbodied2022,
  title = {Inner {{Monologue}}: {{Embodied Reasoning}} through {{Planning}} with {{Language Models}}},
  shorttitle = {Inner {{Monologue}}},
  author = {Huang, Wenlong and Xia, Fei and Xiao, Ted and Chan, Harris and Liang, Jacky and Florence, Pete and Zeng, Andy and Tompson, Jonathan and Mordatch, Igor and Chebotar, Yevgen and Sermanet, Pierre and Brown, Noah and Jackson, Tomas and Luu, Linda and Levine, Sergey and Hausman, Karol and Ichter, Brian},
  year = {2022},
  month = jul,
  number = {arXiv:2207.05608},
  eprint = {2207.05608},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2023-05-18},
  abstract = {Recent works have shown how the reasoning capabilities of Large Language Models (LLMs) can be applied to domains beyond natural language processing, such as planning and interaction for robots. These embodied problems require an agent to understand many semantic aspects of the world: the repertoire of skills available, how these skills influence the world, and how changes to the world map back to the language. LLMs planning in embodied environments need to consider not just what skills to do, but also how and when to do them - answers that change over time in response to the agent's own choices. In this work, we investigate to what extent LLMs used in such embodied contexts can reason over sources of feedback provided through natural language, without any additional training. We propose that by leveraging environment feedback, LLMs are able to form an inner monologue that allows them to more richly process and plan in robotic control scenarios. We investigate a variety of sources of feedback, such as success detection, scene description, and human interaction. We find that closed-loop language feedback significantly improves high-level instruction completion on three domains, including simulated and real table top rearrangement tasks and long-horizon mobile manipulation tasks in a kitchen environment in the real world.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Robotics},
  file = {/home/vsarathy/Zotero/storage/5BWH78ZW/Huang et al. - 2022 - Inner Monologue Embodied Reasoning through Planni.pdf;/home/vsarathy/Zotero/storage/VPL5YUTE/2207.html}
}

@misc{huLLMAdaptersAdapterFamily2023,
  title = {{{LLM-Adapters}}: {{An Adapter Family}} for {{Parameter-Efficient Fine-Tuning}} of {{Large Language Models}}},
  shorttitle = {{{LLM-Adapters}}},
  author = {Hu, Zhiqiang and Wang, Lei and Lan, Yihuai and Xu, Wanyu and Lim, Ee-Peng and Bing, Lidong and Xu, Xing and Poria, Soujanya and Lee, Roy Ka-Wei},
  year = {2023},
  month = oct,
  number = {arXiv:2304.01933},
  eprint = {2304.01933},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2304.01933},
  urldate = {2023-10-20},
  abstract = {The success of large language models (LLMs), like GPT-4 and ChatGPT, has led to the development of numerous cost-effective and accessible alternatives that are created by finetuning open-access LLMs with task-specific data (e.g., ChatDoctor) or instruction data (e.g., Alpaca). Among the various fine-tuning methods, adapter-based parameter-efficient fine-tuning (PEFT) is undoubtedly one of the most attractive topics, as it only requires fine-tuning a few external parameters instead of the entire LLMs while achieving comparable or even better performance. To enable further research on PEFT methods of LLMs, this paper presents LLM-Adapters, an easy-to-use framework that integrates various adapters into LLMs and can execute these adapter-based PEFT methods of LLMs for different tasks. The framework includes state-of-the-art open-access LLMs such as LLaMA, BLOOM, and GPT-J, as well as widely used adapters such as Series adapters, Parallel adapter, Prompt-based learning and Reparametrization-based methods. Moreover, we conduct extensive empirical studies on the impact of adapter types, placement locations, and hyper-parameters to the best design for each adapter-based methods. We evaluate the effectiveness of the adapters on fourteen datasets from two different reasoning tasks, Arithmetic Reasoning and Commonsense Reasoning. The results demonstrate that using adapter-based PEFT in smaller-scale LLMs (7B) with few extra trainable parameters yields comparable, and in some cases superior, performance to powerful LLMs (175B) in zero-shot inference on both reasoning tasks.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computation and Language},
  file = {/home/vsarathy/Zotero/storage/X74BITHH/Hu et al. - 2023 - LLM-Adapters An Adapter Family for Parameter-Effi.pdf;/home/vsarathy/Zotero/storage/QXDZEVIL/2304.html}
}

@article{langleyCognitiveArchitecturesResearch2009,
  title = {Cognitive Architectures: {{Research}} Issues and Challenges},
  shorttitle = {Cognitive Architectures},
  author = {Langley, Pat and Laird, John E. and Rogers, Seth},
  year = {2009},
  month = jun,
  journal = {Cognitive Systems Research},
  volume = {10},
  number = {2},
  pages = {141--160},
  issn = {1389-0417},
  doi = {10.1016/j.cogsys.2006.07.004},
  urldate = {2023-09-13},
  abstract = {In this paper, we examine the motivations for research on cognitive architectures and review some candidates that have been explored in the literature. After this, we consider the capabilities that a cognitive architecture should support, some properties that it should exhibit related to representation, organization, performance, and learning, and some criteria for evaluating such architectures at the systems level. In closing, we discuss some open issues that should drive future research in this important area.},
  keywords = {Cognitive architectures,Cognitive processes,Intelligent systems},
  file = {/home/vsarathy/Zotero/storage/TEXKCTVQ/Langley et al. - 2009 - Cognitive architectures Research issues and chall.pdf}
}

@misc{linText2MotionNaturalLanguage2023a,
  title = {{{Text2Motion}}: {{From Natural Language Instructions}} to {{Feasible Plans}}},
  shorttitle = {{{Text2Motion}}},
  author = {Lin, Kevin and Agia, Christopher and Migimatsu, Toki and Pavone, Marco and Bohg, Jeannette},
  year = {2023},
  month = jun,
  number = {arXiv:2303.12153},
  eprint = {2303.12153},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2023-09-13},
  abstract = {We propose Text2Motion, a language-based planning framework enabling robots to solve sequential manipulation tasks that require long-horizon reasoning. Given a natural language instruction, our framework constructs both a task- and motion-level plan that is verified to reach inferred symbolic goals. Text2Motion uses feasibility heuristics encoded in Q-functions of a library of skills to guide task planning with Large Language Models. Whereas previous language-based planners only consider the feasibility of individual skills, Text2Motion actively resolves geometric dependencies spanning skill sequences by performing geometric feasibility planning during its search. We evaluate our method on a suite of problems that require long-horizon reasoning, interpretation of abstract goals, and handling of partial affordance perception. Our experiments show that Text2Motion can solve these challenging problems with a success rate of 82\%, while prior state-of-the-art language-based planning methods only achieve 13\%. Text2Motion thus provides promising generalization characteristics to semantically diverse sequential manipulation tasks with geometric dependencies between skills.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Robotics},
  file = {/home/vsarathy/Zotero/storage/4SKXMSRB/Lin et al. - 2023 - Text2Motion From Natural Language Instructions to.pdf;/home/vsarathy/Zotero/storage/KVW4SECL/2303.html}
}

@inproceedings{liuGroundingComplexNatural2023,
  title = {Grounding {{Complex Natural Language Commands}} for {{Temporal Tasks}} in {{Unseen Environments}}},
  booktitle = {7th {{Annual Conference}} on {{Robot Learning}}},
  author = {Liu, Jason Xinyu and Yang, Ziyi and Idrees, Ifrah and Liang, Sam and Schornstein, Benjamin and Tellex, Stefanie and Shah, Ankit},
  year = {2023},
  month = aug,
  urldate = {2023-10-20},
  abstract = {Grounding navigational commands to linear temporal logic (LTL) leverages its unambiguous semantics for reasoning about long-horizon tasks and verifying the satisfaction of temporal constraints. Existing approaches require training data from the specific environment and landmarks that will be used in natural language to understand commands in those environments. We propose Lang2LTL, a modular system and a software package that leverages large language models (LLMs) to ground temporal navigational commands to LTL specifications in environments without prior language data. We comprehensively evaluate Lang2LTL for five well-defined generalization behaviors. Lang2LTL demonstrates the state-of-the-art ability of a single model to ground navigational commands to diverse temporal specifications in 21 city-scaled environments. Finally, we demonstrate a physical robot using Lang2LTL can follow 52 semantically diverse navigational commands in two indoor environments.},
  langid = {english},
  file = {/home/vsarathy/Zotero/storage/E9K65NJA/Liu et al. - 2023 - Grounding Complex Natural Language Commands for Te.pdf}
}

@misc{liuLang2LTLTranslatingNatural2023,
  title = {{{Lang2LTL}}: {{Translating Natural Language Commands}} to {{Temporal Robot Task Specification}}},
  shorttitle = {{{Lang2LTL}}},
  author = {Liu, Jason Xinyu and Yang, Ziyi and Idrees, Ifrah and Liang, Sam and Schornstein, Benjamin and Tellex, Stefanie and Shah, Ankit},
  year = {2023},
  month = feb,
  number = {arXiv:2302.11649},
  eprint = {2302.11649},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2023-06-01},
  abstract = {Natural language provides a powerful modality to program robots to perform temporal tasks. Linear temporal logic (LTL) provides unambiguous semantics for formal descriptions of temporal tasks. However, existing approaches cannot accurately and robustly translate English sentences to their equivalent LTL formulas in unseen environments. To address this problem, we propose Lang2LTL, a novel modular system that leverages pretrained large language models to first extract referring expressions from a natural language command, then ground the expressions to real-world landmarks and objects, and finally translate the command into an LTL task specification for the robot. It enables any robotic system to interpret natural language navigation commands without additional training, provided that it tracks its position and has a semantic map with landmarks labeled with free-form text. We demonstrate the state-of-the-art ability to generalize to multi-scale navigation domains such as OpenStreetMap (OSM) and CleanUp World (a simulated household environment). Lang2LTL achieves an average accuracy of 88.4\% in translating challenging LTL formulas in 22 unseen OSM environments as evaluated on a new corpus of over 10,000 commands, 22 times better than the previous SoTA. Without modification, the best performing Lang2LTL model on the OSM dataset can translate commands in CleanUp World with 82.8\% accuracy. As a part of our proposed comprehensive evaluation procedures, we collected a new labeled dataset of English commands representing 2,125 unique LTL formulas, the largest ever dataset of natural language commands to LTL specifications for robotic tasks with the most diverse LTL formulas, 40 times more than previous largest dataset. Finally, we integrated Lang2LTL with a planner to command a quadruped mobile robot to perform multi-step navigational tasks in an analog real-world environment created in the lab.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Formal Languages and Automata Theory,Computer Science - Robotics},
  file = {/home/vsarathy/Zotero/storage/B6HXPN9K/Liu et al. - 2023 - Lang2LTL Translating Natural Language Commands to.pdf;/home/vsarathy/Zotero/storage/IEZXMCML/2302.html}
}

@misc{liuLLMEmpoweringLarge2023,
  title = {{{LLM}}+{{P}}: {{Empowering Large Language Models}} with {{Optimal Planning Proficiency}}},
  shorttitle = {{{LLM}}+{{P}}},
  author = {Liu, Bo and Jiang, Yuqian and Zhang, Xiaohan and Liu, Qiang and Zhang, Shiqi and Biswas, Joydeep and Stone, Peter},
  year = {2023},
  month = may,
  number = {arXiv:2304.11477},
  eprint = {2304.11477},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2023-07-28},
  abstract = {Large language models (LLMs) have demonstrated remarkable zero-shot generalization abilities: state-of-the-art chatbots can provide plausible answers to many common questions that arise in daily life. However, so far, LLMs cannot reliably solve long-horizon planning problems. By contrast, classical planners, once a problem is given in a formatted way, can use efficient search algorithms to quickly identify correct, or even optimal, plans. In an effort to get the best of both worlds, this paper introduces LLM+P, the first framework that incorporates the strengths of classical planners into LLMs. LLM+P takes in a natural language description of a planning problem, then returns a correct (or optimal) plan for solving that problem in natural language. LLM+P does so by first converting the language description into a file written in the planning domain definition language (PDDL), then leveraging classical planners to quickly find a solution, and then translating the found solution back into natural language. Along with LLM+P, we define a diverse set of different benchmark problems taken from common planning scenarios. Via a comprehensive set of experiments on these benchmark problems, we find that LLM+P is able to provide optimal solutions for most problems, while LLMs fail to provide even feasible plans for most problems.\textbackslash footnote\{The code and results are publicly available at https://github.com/Cranial-XIX/llm-pddl.git.\vphantom\}},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Robotics},
  file = {/home/vsarathy/Zotero/storage/MBWLHSYL/Liu et al. - 2023 - LLM+P Empowering Large Language Models with Optim.pdf;/home/vsarathy/Zotero/storage/58K6IT8L/2304.html}
}

@misc{liuREFLECTSummarizingRobot2023,
  title = {{{REFLECT}}: {{Summarizing Robot Experiences}} for {{Failure Explanation}} and {{Correction}}},
  shorttitle = {{{REFLECT}}},
  author = {Liu, Zeyi and Bahety, Arpit and Song, Shuran},
  year = {2023},
  month = jul,
  number = {arXiv:2306.15724},
  eprint = {2306.15724},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2023-07-27},
  abstract = {The ability to detect and analyze failed executions automatically is crucial for an explainable and robust robotic system. Recently, Large Language Models (LLMs) have demonstrated strong reasoning abilities on textual inputs. To leverage the power of LLM for robot failure explanation, we introduce a framework REFLECT, which queries LLM to identify and explain robot failures given a hierarchical summary of robot past experiences generated from multi-sensory data. Conditioned on the explanation, a task planner will generate an executable plan for the robot to correct the failure and complete the task. To systematically evaluate the framework, we create the RoboFail dataset with a variety of tasks and failure scenarios. We demonstrate that the LLM-based framework is able to generate informative failure explanations that assist successful correction planning. Videos and code available at: https://roboreflect.github.io/.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Robotics},
  file = {/home/vsarathy/Zotero/storage/RDH6ZU8S/Liu et al. - 2023 - REFLECT Summarizing Robot Experiences for Failure.pdf;/home/vsarathy/Zotero/storage/WADJGR5M/2306.html}
}

@article{margeSpokenLanguageInteraction2022,
  title = {Spoken Language Interaction with Robots: {{Recommendations}} for Future Research},
  shorttitle = {Spoken Language Interaction with Robots},
  author = {Marge, Matthew and {Espy-Wilson}, Carol and Ward, Nigel G. and Alwan, Abeer and Artzi, Yoav and Bansal, Mohit and Blankenship, Gil and Chai, Joyce and Daum{\'e}, Hal and Dey, Debadeepta and Harper, Mary and Howard, Thomas and Kennington, Casey and {Kruijff-Korbayov{\'a}}, Ivana and Manocha, Dinesh and Matuszek, Cynthia and Mead, Ross and Mooney, Raymond and Moore, Roger K. and Ostendorf, Mari and {Pon-Barry}, Heather and Rudnicky, Alexander I. and Scheutz, Matthias and Amant, Robert St. and Sun, Tong and Tellex, Stefanie and Traum, David and Yu, Zhou},
  year = {2022},
  month = jan,
  journal = {Computer Speech \& Language},
  volume = {71},
  pages = {101255},
  issn = {0885-2308},
  doi = {10.1016/j.csl.2021.101255},
  urldate = {2023-10-20},
  abstract = {With robotics rapidly advancing, more effective human\textendash robot interaction is increasingly needed to realize the full potential of robots for society. While spoken language must be part of the solution, our ability to provide spoken language interaction capabilities is still very limited. In this article, based on the report of an interdisciplinary workshop convened by the National Science Foundation, we identify key scientific and engineering advances needed to enable effective spoken language interaction with robotics. We make 25 recommendations, involving eight general themes: putting human needs first, better modeling the social and interactive aspects of language, improving robustness, creating new methods for rapid adaptation, better integrating speech and language with other communication modalities, giving speech and language components access to rich representations of the robot's current knowledge and state, making all components operate in real time, and improving research infrastructure and resources. Research and development that prioritizes these topics will, we believe, provide a solid foundation for the creation of speech-capable robots that are easy and effective for humans to work with.},
  keywords = {Challenges,Issues,Priorities,Research agenda,Users},
  file = {/home/vsarathy/Zotero/storage/RV9BIKK8/Marge et al. - 2022 - Spoken language interaction with robots Recommend.pdf}
}

@misc{mekalaZEROTOPZeroShotTaskOriented2022,
  title = {{{ZEROTOP}}: {{Zero-Shot Task-Oriented Semantic Parsing}} Using {{Large Language Models}}},
  shorttitle = {{{ZEROTOP}}},
  author = {Mekala, Dheeraj and Wolfe, Jason and Roy, Subhro},
  year = {2022},
  month = dec,
  number = {arXiv:2212.10815},
  eprint = {2212.10815},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2023-07-05},
  abstract = {We explore the use of large language models (LLMs) for zero-shot semantic parsing. Semantic parsing involves mapping natural language utterances to task-specific meaning representations. Language models are generally trained on the publicly available text and code and cannot be expected to directly generalize to domain-specific parsing tasks in a zero-shot setting. In this work, we propose ZEROTOP, a zero-shot task-oriented parsing method that decomposes a semantic parsing problem into a set of abstractive and extractive question-answering (QA) problems, enabling us to leverage the ability of LLMs to zero-shot answer reading comprehension questions. For each utterance, we prompt the LLM with questions corresponding to its top-level intent and a set of slots and use the LLM generations to construct the target meaning representation. We observe that current LLMs fail to detect unanswerable questions; and as a result, cannot handle questions corresponding to missing slots. To address this problem, we fine-tune a language model on public QA datasets using synthetic negative samples. Experimental results show that our QA-based decomposition paired with the fine-tuned LLM can correctly parse \textasciitilde 16\% of utterances in the MTOP dataset without requiring any annotated data.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computation and Language},
  file = {/home/vsarathy/Zotero/storage/GY7R5E6T/Mekala et al. - 2022 - ZEROTOP Zero-Shot Task-Oriented Semantic Parsing .pdf;/home/vsarathy/Zotero/storage/C6NJAPV9/2212.html}
}

@book{NonTransformationalSyntax2011,
  title = {Non-{{Transformational Syntax}}},
  year = {2011},
  edition = {1},
  publisher = {{John Wiley \& Sons, Ltd}},
  doi = {10.1002/9781444395037},
  urldate = {2023-10-20},
  file = {/home/vsarathy/Zotero/storage/6REMWJ5V/2011 - Non-Transformational Syntax.pdf;/home/vsarathy/Zotero/storage/VAGGBRC6/9781444395037.html}
}

@inproceedings{Quigley09,
  title = {{{ROS}}: An Open-Source Robot Operating System},
  booktitle = {Proc. of the {{IEEE}} Intl. {{Conf}}. on Robotics and Automation ({{ICRA}}) Workshop on Open Source Robotics},
  author = {Quigley, Morgan and Gerkey, Brian and Conley, Ken and Faust, Josh and Foote, Tully and Leibs, Jeremy and Berger, Eric and Wheeler, Rob and Ng, Andrew},
  year = {2009},
  month = may,
  address = {{Kobe, Japan}}
}

@misc{roziereCodeLlamaOpen2023,
  title = {Code {{Llama}}: {{Open Foundation Models}} for {{Code}}},
  shorttitle = {Code {{Llama}}},
  author = {Rozi{\`e}re, Baptiste and Gehring, Jonas and Gloeckle, Fabian and Sootla, Sten and Gat, Itai and Tan, Xiaoqing Ellen and Adi, Yossi and Liu, Jingyu and Remez, Tal and Rapin, J{\'e}r{\'e}my and Kozhevnikov, Artyom and Evtimov, Ivan and Bitton, Joanna and Bhatt, Manish and Ferrer, Cristian Canton and Grattafiori, Aaron and Xiong, Wenhan and D{\'e}fossez, Alexandre and Copet, Jade and Azhar, Faisal and Touvron, Hugo and Martin, Louis and Usunier, Nicolas and Scialom, Thomas and Synnaeve, Gabriel},
  year = {2023},
  month = aug,
  number = {arXiv:2308.12950},
  eprint = {2308.12950},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2023-10-20},
  abstract = {We release Code Llama, a family of large language models for code based on Llama 2 providing state-of-the-art performance among open models, infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks. We provide multiple flavors to cover a wide range of applications: foundation models (Code Llama), Python specializations (Code Llama - Python), and instruction-following models (Code Llama - Instruct) with 7B, 13B and 34B parameters each. All models are trained on sequences of 16k tokens and show improvements on inputs with up to 100k tokens. 7B and 13B Code Llama and Code Llama - Instruct variants support infilling based on surrounding content. Code Llama reaches state-of-the-art performance among open models on several code benchmarks, with scores of up to 53\% and 55\% on HumanEval and MBPP, respectively. Notably, Code Llama - Python 7B outperforms Llama 2 70B on HumanEval and MBPP, and all our models outperform every other publicly available model on MultiPL-E. We release Code Llama under a permissive license that allows for both research and commercial use.},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language},
  file = {/home/vsarathy/Zotero/storage/BMXZL566/Rozière et al. - 2023 - Code Llama Open Foundation Models for Code.pdf}
}

@misc{roziereCodeLlamaOpen2023a,
  title = {Code {{Llama}}: {{Open Foundation Models}} for {{Code}}},
  shorttitle = {Code {{Llama}}},
  author = {Rozi{\`e}re, Baptiste and Gehring, Jonas and Gloeckle, Fabian and Sootla, Sten and Gat, Itai and Tan, Xiaoqing Ellen and Adi, Yossi and Liu, Jingyu and Remez, Tal and Rapin, J{\'e}r{\'e}my and Kozhevnikov, Artyom and Evtimov, Ivan and Bitton, Joanna and Bhatt, Manish and Ferrer, Cristian Canton and Grattafiori, Aaron and Xiong, Wenhan and D{\'e}fossez, Alexandre and Copet, Jade and Azhar, Faisal and Touvron, Hugo and Martin, Louis and Usunier, Nicolas and Scialom, Thomas and Synnaeve, Gabriel},
  year = {2023},
  month = aug,
  number = {arXiv:2308.12950},
  eprint = {2308.12950},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2308.12950},
  urldate = {2023-10-20},
  abstract = {We release Code Llama, a family of large language models for code based on Llama 2 providing state-of-the-art performance among open models, infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks. We provide multiple flavors to cover a wide range of applications: foundation models (Code Llama), Python specializations (Code Llama - Python), and instruction-following models (Code Llama - Instruct) with 7B, 13B and 34B parameters each. All models are trained on sequences of 16k tokens and show improvements on inputs with up to 100k tokens. 7B and 13B Code Llama and Code Llama - Instruct variants support infilling based on surrounding content. Code Llama reaches state-of-the-art performance among open models on several code benchmarks, with scores of up to 53\% and 55\% on HumanEval and MBPP, respectively. Notably, Code Llama - Python 7B outperforms Llama 2 70B on HumanEval and MBPP, and all our models outperform every other publicly available model on MultiPL-E. We release Code Llama under a permissive license that allows for both research and commercial use.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computation and Language},
  file = {/home/vsarathy/Zotero/storage/6NNBE3FX/Rozière et al. - 2023 - Code Llama Open Foundation Models for Code.pdf;/home/vsarathy/Zotero/storage/KG9HNT8E/2308.html}
}

@incollection{scheutzOverviewDistributedIntegrated2019,
  title = {An {{Overview}} of the {{Distributed Integrated Cognition Affect}} and {{Reflection DIARC Architecture}}},
  booktitle = {Intelligent {{Systems}}, {{Control}} and {{Automation}}: {{Science}} and {{Engineering}}},
  author = {Scheutz, Matthias and Williams, Tom and Krause, Evan and Oosterveld, Bradley and Sarathy, Vasanth and Frasca, Tyler},
  year = {2019},
  month = jan,
  pages = {165--193},
  doi = {10.1007/978-3-319-97550-4_11},
  abstract = {DIARC has been under development for over 15 years. Different from other cognitive architectures like SOAR or ACT-R, DIARC is an intrinsically component-based distributed architecture scheme that can be instantiated in many different ways. Moreover, DIARC has several distinguishing features, such as affect processing and deep natural language integration, is open-world and multi-agent enabled, and allows for ``one-shot instruction-based learning'' of new percepts, actions, concepts, rules, and norms. In this chapter, we will present an overview of the DIARC architecture and compare it to classical cognitive architectures. After laying out the theoretical foundations, we specifically focus on the action, vision, and natural language subsystems. We then give two examples of DIARC configurations for ``one-shot learning'' and ``component-sharing''. We also briefly mention different use cases of DIARC, in particular, for autonomous robots in human-robot interaction experiments and for building cognitive models.},
  isbn = {978-3-319-97549-8},
  file = {/home/vsarathy/Zotero/storage/BZIEQNTD/Scheutz et al. - 2019 - An Overview of the Distributed Integrated Cognitio.pdf}
}

@article{singhProgPromptGeneratingSituated2022,
  title = {{{ProgPrompt}}: {{Generating Situated Robot Task Plans}} Using {{Large Language Models}}},
  author = {Singh, Ishika and Blukis, Valts and Mousavian, Arsalan and Goyal, Ankit and Xu, Danfei and Tremblay, Jonathan and Fox, Dieter and Thomason, Jesse and Garg, Animesh},
  year = {2022},
  publisher = {{arXiv}},
  doi = {10.48550/ARXIV.2209.11302},
  abstract = {\textemdash Task planning can require defining myriad do- main knowledge about the world in which a robot needs to act. To ameliorate that effort, large language models (LLMs) can be used to score potential next actions during task planning, and even generate action sequences directly, given an instruction in natural language with no additional domain information. However, such methods either require enumerating all possible next steps for scoring, or generate free-form text that may contain actions not possible on a given robot in its current context. We present a programmatic LLM prompt structure that enables plan generation functional across situated envi- ronments, robot capabilities, and tasks. Our key insight is to prompt the LLM with program-like specifications of the available actions and objects in an environment, as well as with example programs that can be executed. We make concrete recommendations about prompt structure and generation con- straints through ablation experiments, demonstrate state of the art success rates in VirtualHome household tasks, and deploy our method on a physical robot arm for tabletop tasks. Website at progprompt.github.io},
  file = {/home/vsarathy/Zotero/storage/56QREAWU/Singh et al. - 2022 - ProgPrompt Generating Situated Robot Task Plans u.pdf}
}

@book{steedmanSyntacticProcess2001,
  title = {The {{Syntactic Process}}},
  author = {Steedman, Mark},
  year = {2001},
  month = jul,
  publisher = {{MIT Press}},
  abstract = {This book covers topics in formal linguistics, intonational phonology, computational linguistics, and experimental psycholinguistics, presenting them as an integrated theory of the language faculty. In this book Mark Steedman argues that the surface syntax of natural languages maps spoken and written forms directly to a compositional semantic representation that includes predicate-argument structure, quantification, and information structure without constructing any intervening structural representation. His purpose is to construct a principled theory of natural grammar that is directly compatible with both explanatory linguistic accounts of a number of problematic syntactic phenomena and a straightforward computational account of the way sentences are mapped onto representations of meaning. The radical nature of Steedman's proposal stems from his claim that much of the apparent complexity of syntax, prosody, and processing follows from the lexical specification of the grammar and from the involvement of a small number of universal rule-types for combining predicates and arguments. These syntactic operations are related to the combinators of Combinatory Logic, engendering a much freer definition of derivational constituency than is traditionally assumed. This property allows Combinatory Categorial Grammar to capture elegantly the structure and interpretation of coordination and intonation contour in English as well as some well-known interactions between word order, coordination, and relativization across a number of other languages. It also allows more direct compatibility with incremental semantic interpretation during parsing.The book covers topics in formal linguistics, intonational phonology, computational linguistics, and experimental psycholinguistics, presenting them as an integrated theory of the language faculty in a form accessible to readers from any of those fields.},
  isbn = {978-0-262-69268-7},
  langid = {english},
  keywords = {Language Arts \& Disciplines / Linguistics / General}
}

@misc{sumersCognitiveArchitecturesLanguage2023,
  title = {Cognitive {{Architectures}} for {{Language Agents}}},
  author = {Sumers, Theodore and Yao, Shunyu and Narasimhan, Karthik and Griffiths, Thomas L.},
  year = {2023},
  month = sep,
  number = {arXiv:2309.02427},
  eprint = {2309.02427},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2023-09-18},
  abstract = {Recent efforts have incorporated large language models (LLMs) with external resources (e.g., the Internet) or internal control flows (e.g., prompt chaining) for tasks requiring grounding or reasoning. However, these efforts have largely been piecemeal, lacking a systematic framework for constructing a fully-fledged language agent. To address this challenge, we draw on the rich history of agent design in symbolic artificial intelligence to develop a blueprint for a new wave of cognitive language agents. We first show that LLMs have many of the same properties as production systems, and recent efforts to improve their grounding or reasoning mirror the development of cognitive architectures built around production systems. We then propose Cognitive Architectures for Language Agents (CoALA), a conceptual framework to systematize diverse methods for LLM-based reasoning, grounding, learning, and decision making as instantiations of language agents in the framework. Finally, we use the CoALA framework to highlight gaps and propose actionable directions toward more capable language agents in the future.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning,Computer Science - Symbolic Computation},
  file = {/home/vsarathy/Zotero/storage/GSG6RSE7/Sumers et al. - 2023 - Cognitive Architectures for Language Agents.pdf;/home/vsarathy/Zotero/storage/IVK7AEXC/2309.html}
}

@misc{touvronLlamaOpenFoundation2023,
  title = {Llama 2: {{Open Foundation}} and {{Fine-Tuned Chat Models}}},
  shorttitle = {Llama 2},
  author = {Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and Bikel, Dan and Blecher, Lukas and Ferrer, Cristian Canton and Chen, Moya and Cucurull, Guillem and Esiobu, David and Fernandes, Jude and Fu, Jeremy and Fu, Wenyin and Fuller, Brian and Gao, Cynthia and Goswami, Vedanuj and Goyal, Naman and Hartshorn, Anthony and Hosseini, Saghar and Hou, Rui and Inan, Hakan and Kardas, Marcin and Kerkez, Viktor and Khabsa, Madian and Kloumann, Isabel and Korenev, Artem and Koura, Punit Singh and Lachaux, Marie-Anne and Lavril, Thibaut and Lee, Jenya and Liskovich, Diana and Lu, Yinghai and Mao, Yuning and Martinet, Xavier and Mihaylov, Todor and Mishra, Pushkar and Molybog, Igor and Nie, Yixin and Poulton, Andrew and Reizenstein, Jeremy and Rungta, Rashi and Saladi, Kalyan and Schelten, Alan and Silva, Ruan and Smith, Eric Michael and Subramanian, Ranjan and Tan, Xiaoqing Ellen and Tang, Binh and Taylor, Ross and Williams, Adina and Kuan, Jian Xiang and Xu, Puxin and Yan, Zheng and Zarov, Iliyan and Zhang, Yuchen and Fan, Angela and Kambadur, Melanie and Narang, Sharan and Rodriguez, Aurelien and Stojnic, Robert and Edunov, Sergey and Scialom, Thomas},
  year = {2023},
  month = jul,
  number = {arXiv:2307.09288},
  eprint = {2307.09288},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2307.09288},
  urldate = {2023-10-20},
  abstract = {In this work, we develop and release Llama 2, a collection of pretrained and fine-tuned large language models (LLMs) ranging in scale from 7 billion to 70 billion parameters. Our fine-tuned LLMs, called Llama 2-Chat, are optimized for dialogue use cases. Our models outperform open-source chat models on most benchmarks we tested, and based on our human evaluations for helpfulness and safety, may be a suitable substitute for closed-source models. We provide a detailed description of our approach to fine-tuning and safety improvements of Llama 2-Chat in order to enable the community to build on our work and contribute to the responsible development of LLMs.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/home/vsarathy/Zotero/storage/HPELLUZE/Touvron et al. - 2023 - Llama 2 Open Foundation and Fine-Tuned Chat Model.pdf;/home/vsarathy/Zotero/storage/LUESPNGB/2307.html}
}

@article{vempralaChatGPTRoboticsDesign,
  title = {{{ChatGPT}} for {{Robotics}}: {{Design Principles}} and {{Model Abilities}}},
  author = {Vemprala, Sai and Bonatti, Rogerio and Bucker, Arthur and Kapoor, Ashish},
  langid = {english},
  file = {/home/vsarathy/Zotero/storage/32KX72K3/Vemprala et al. - ChatGPT for Robotics Design Principles and Model .pdf}
}

@inproceedings{vo2015nl2kr,
  title = {The {{NL2KR}} Platform for Building Natural Language Translation Systems},
  booktitle = {Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: {{Long}} Papers)},
  author = {Vo, Nguyen and Mitra, Arindam and Baral, Chitta},
  year = {2015},
  volume = {1},
  pages = {899--908}
}

@misc{wangGrammarPromptingDomainSpecific2023,
  title = {Grammar {{Prompting}} for {{Domain-Specific Language Generation}} with {{Large Language Models}}},
  author = {Wang, Bailin and Wang, Zi and Wang, Xuezhi and Cao, Yuan and Saurous, Rif A. and Kim, Yoon},
  year = {2023},
  month = may,
  number = {arXiv:2305.19234},
  eprint = {2305.19234},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2023-06-02},
  abstract = {Large language models (LLMs) can learn to perform a wide range of natural language tasks from just a handful of in-context examples. However, for generating strings from highly structured languages (e.g., semantic parsing to complex domain-specific languages), it is challenging for the LLM to generalize from just a few exemplars. We explore \$\textbackslash textbf\{grammar prompting\}\$ as a simple approach for enabling LLMs to use external knowledge and domain-specific constraints, expressed through a grammar expressed in Backus--Naur Form (BNF), during in-context learning. Grammar prompting augments each demonstration example with a specialized grammar that is minimally sufficient for generating the particular output example, where the specialized grammar is a subset of the full DSL grammar. For inference, the LLM first predicts a BNF grammar given a test input, and then generates the output according to the rules of the grammar. Experiments demonstrate that grammar prompting can enable LLMs to perform competitively on a diverse set of DSL generation tasks, including semantic parsing (SMCalFlow, Overnight, GeoQuery), PDDL planning, and even molecule generation (SMILES).},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/home/vsarathy/Zotero/storage/VKGK2JJU/Wang et al. - 2023 - Grammar Prompting for Domain-Specific Language Gen.pdf;/home/vsarathy/Zotero/storage/L84BWM3U/2305.html}
}

@misc{wangVoyagerOpenEndedEmbodied2023,
  title = {Voyager: {{An Open-Ended Embodied Agent}} with {{Large Language Models}}},
  shorttitle = {Voyager},
  author = {Wang, Guanzhi and Xie, Yuqi and Jiang, Yunfan and Mandlekar, Ajay and Xiao, Chaowei and Zhu, Yuke and Fan, Linxi and Anandkumar, Anima},
  year = {2023},
  month = may,
  number = {arXiv:2305.16291},
  eprint = {2305.16291},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2305.16291},
  urldate = {2023-06-01},
  abstract = {We introduce Voyager, the first LLM-powered embodied lifelong learning agent in Minecraft that continuously explores the world, acquires diverse skills, and makes novel discoveries without human intervention. Voyager consists of three key components: 1) an automatic curriculum that maximizes exploration, 2) an ever-growing skill library of executable code for storing and retrieving complex behaviors, and 3) a new iterative prompting mechanism that incorporates environment feedback, execution errors, and self-verification for program improvement. Voyager interacts with GPT-4 via blackbox queries, which bypasses the need for model parameter fine-tuning. The skills developed by Voyager are temporally extended, interpretable, and compositional, which compounds the agent's abilities rapidly and alleviates catastrophic forgetting. Empirically, Voyager shows strong in-context lifelong learning capability and exhibits exceptional proficiency in playing Minecraft. It obtains 3.3x more unique items, travels 2.3x longer distances, and unlocks key tech tree milestones up to 15.3x faster than prior SOTA. Voyager is able to utilize the learned skill library in a new Minecraft world to solve novel tasks from scratch, while other techniques struggle to generalize. We open-source our full codebase and prompts at https://voyager.minedojo.org/.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  file = {/home/vsarathy/Zotero/storage/W7PD4S9U/Wang et al. - 2023 - Voyager An Open-Ended Embodied Agent with Large L.pdf;/home/vsarathy/Zotero/storage/5MN97H2K/2305.html}
}

@misc{wengLLMPoweredAutonomous2023,
  title = {{{LLM Powered Autonomous Agents}}},
  author = {Weng, Lilian},
  year = {2023},
  month = jun,
  urldate = {2023-07-28},
  abstract = {Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver. Agent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent's brain, complemented by several key components:},
  chapter = {posts},
  howpublished = {https://lilianweng.github.io/posts/2023-06-23-agent/},
  langid = {english},
  file = {/home/vsarathy/Zotero/storage/DQI7VZZY/Weng - 2023 - LLM Powered Autonomous Agents.pdf;/home/vsarathy/Zotero/storage/TYA3NIEX/2023-06-23-agent.html}
}

@inproceedings{wise2016fetch,
  title = {Fetch and Freight: {{Standard}} Platforms for Service Robot Applications},
  booktitle = {Workshop on Autonomous Mobile Service Robots},
  author = {Wise, Melonee and Ferguson, Michael and King, Derek and Diehr, Eric and Dymesich, David},
  year = {2016},
  pages = {1--6}
}

@misc{wuTidyBotPersonalizedRobot2023,
  title = {{{TidyBot}}: {{Personalized Robot Assistance}} with {{Large Language Models}}},
  shorttitle = {{{TidyBot}}},
  author = {Wu, Jimmy and Antonova, Rika and Kan, Adam and Lepert, Marion and Zeng, Andy and Song, Shuran and Bohg, Jeannette and Rusinkiewicz, Szymon and Funkhouser, Thomas},
  year = {2023},
  month = may,
  number = {arXiv:2305.05658},
  eprint = {2305.05658},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2305.05658},
  urldate = {2023-05-18},
  abstract = {For a robot to personalize physical assistance effectively, it must learn user preferences that can be generally reapplied to future scenarios. In this work, we investigate personalization of household cleanup with robots that can tidy up rooms by picking up objects and putting them away. A key challenge is determining the proper place to put each object, as people's preferences can vary greatly depending on personal taste or cultural background. For instance, one person may prefer storing shirts in the drawer, while another may prefer them on the shelf. We aim to build systems that can learn such preferences from just a handful of examples via prior interactions with a particular person. We show that robots can combine language-based planning and perception with the few-shot summarization capabilities of large language models (LLMs) to infer generalized user preferences that are broadly applicable to future interactions. This approach enables fast adaptation and achieves 91.2\% accuracy on unseen objects in our benchmark dataset. We also demonstrate our approach on a real-world mobile manipulator called TidyBot, which successfully puts away 85.0\% of objects in real-world test scenarios.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Robotics},
  file = {/home/vsarathy/Zotero/storage/X8HLC4UD/Wu et al. - 2023 - TidyBot Personalized Robot Assistance with Large .pdf;/home/vsarathy/Zotero/storage/J63X53ZJ/2305.html}
}

@misc{yonedaStatlerStateMaintainingLanguage2023,
  title = {Statler: {{State-Maintaining Language Models}} for {{Embodied Reasoning}}},
  shorttitle = {Statler},
  author = {Yoneda, Takuma and Fang, Jiading and Li, Peng and Zhang, Huanyu and Jiang, Tianchong and Lin, Shengjie and Picker, Ben and Yunis, David and Mei, Hongyuan and Walter, Matthew R.},
  year = {2023},
  month = jul,
  number = {arXiv:2306.17840},
  eprint = {2306.17840},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2023-07-05},
  abstract = {Large language models (LLMs) provide a promising tool that enable robots to perform complex robot reasoning tasks. However, the limited context window of contemporary LLMs makes reasoning over long time horizons difficult. Embodied tasks such as those that one might expect a household robot to perform typically require that the planner consider information acquired a long time ago (e.g., properties of the many objects that the robot previously encountered in the environment). Attempts to capture the world state using an LLM's implicit internal representation is complicated by the paucity of task- and environment-relevant information available in a robot's action history, while methods that rely on the ability to convey information via the prompt to the LLM are subject to its limited context window. In this paper, we propose Statler, a framework that endows LLMs with an explicit representation of the world state as a form of ``memory'' that is maintained over time. Integral to Statler is its use of two instances of general LLMs -- a world-model reader and a world-model writer -- that interface with and maintain the world state. By providing access to this world state ``memory'', Statler improves the ability of existing LLMs to reason over longer time horizons without the constraint of context length. We evaluate the effectiveness of our approach on three simulated table-top manipulation domains and a real robot domain, and show that it improves the state-of-the-art in LLM-based robot reasoning. Project website: https://statler-lm.github.io/},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computation and Language,Computer Science - Robotics},
  file = {/home/vsarathy/Zotero/storage/TA4RHD6J/Yoneda et al. - 2023 - Statler State-Maintaining Language Models for Emb.pdf;/home/vsarathy/Zotero/storage/XHZ4GCUC/2306.html}
}

@misc{yuSpiderLargeScaleHumanLabeled2019,
  title = {Spider: {{A Large-Scale Human-Labeled Dataset}} for {{Complex}} and {{Cross-Domain Semantic Parsing}} and {{Text-to-SQL Task}}},
  shorttitle = {Spider},
  author = {Yu, Tao and Zhang, Rui and Yang, Kai and Yasunaga, Michihiro and Wang, Dongxu and Li, Zifan and Ma, James and Li, Irene and Yao, Qingning and Roman, Shanelle and Zhang, Zilin and Radev, Dragomir},
  year = {2019},
  month = feb,
  number = {arXiv:1809.08887},
  eprint = {1809.08887},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2023-10-18},
  abstract = {We present Spider, a large-scale, complex and cross-domain semantic parsing and text-to-SQL dataset annotated by 11 college students. It consists of 10,181 questions and 5,693 unique complex SQL queries on 200 databases with multiple tables, covering 138 different domains. We define a new complex and cross-domain semantic parsing and text-to-SQL task where different complex SQL queries and databases appear in train and test sets. In this way, the task requires the model to generalize well to both new SQL queries and new database schemas. Spider is distinct from most of the previous semantic parsing tasks because they all use a single database and the exact same programs in the train set and the test set. We experiment with various state-of-the-art models and the best model achieves only 12.4\% exact matching accuracy on a database split setting. This shows that Spider presents a strong challenge for future research. Our dataset and task are publicly available at https://yale-lily.github.io/spider},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/home/vsarathy/Zotero/storage/PWQ5MP4L/Yu et al. - 2019 - Spider A Large-Scale Human-Labeled Dataset for Co.pdf;/home/vsarathy/Zotero/storage/PPNXRW2F/1809.html}
}
