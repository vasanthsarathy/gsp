{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44deaadf",
   "metadata": {},
   "source": [
    "# Version 3\n",
    "\n",
    "The basic idea here is to extract the CPC first. This is the `core propositional content` or the the central thing that the speaker is talking about -- Could be an action or concept. In either case, it is the thing that the listener is not exepected to have presupposed. E.g., \"The purple box is open\". There the listener is expected to know about the purple box, but not that it is open. \n",
    "\n",
    "**Algorithm:**\n",
    "\n",
    "Input: utterance U, ActionDb A, ConceptDB C, AvailableTypes T\n",
    "\n",
    "1. speech_act <-- extract_speech_act(U) \n",
    "2. refs <-- extract_referents(U) \n",
    "3. ref_dict <-- extract_referent_types(U, refs, T)\n",
    "4. cpc_name <-- extract_cpc_name(U) \n",
    "5. ling_cpc_signature <-- extract_cpc_sign(U, cpc_name, ref_dict)\n",
    "6. * ling_parse <-- tether(U, ling_cpc_signature, A, C, T)\n",
    "    \n",
    "    \n",
    "For \"INSTRUCT\" speech acts, `tethering` involves:\n",
    "- comparing the linguistically derived parse (i.e., ling_parse) with available action signatures, and generating an association chain between the cpc_name and one or more corresponding actions \n",
    "    - ranked list of name matches. Filter down this list with argument matching. \n",
    "    - Failure here means agent cannot perform action\n",
    "\n",
    "For \"STATEMENT\" speech acts, `tethering` involves:\n",
    "- comparing the linguistically derived parse (i.e., ling_parse) with available concepts.\n",
    "    - Failure here means agent can learn a new fact, but not understand its meaning or be able to recognize the concept in a different setting, without further attempts at tethering. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb790689",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "779b5462",
   "metadata": {},
   "source": [
    "## Domain\n",
    "\n",
    "Objects:\n",
    "- Circuit breaker\n",
    "- m3 screw\n",
    "- NFSV\n",
    "- m3 hole\n",
    "- work area\n",
    "- conveyor \n",
    "- conveyor belt \n",
    "- deep m3 holes\n",
    "\n",
    "Actions\n",
    "- pickup\n",
    "- putdown\n",
    "- find see/ can you see/ verify that you can see\n",
    "- go to location\n",
    "- go to pose \n",
    "- search \n",
    "- mount \n",
    "- align \n",
    "- assemble* \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8d128075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "import json\n",
    "\n",
    "# actions\n",
    "with open('../data/actions_short.json') as f:\n",
    "    actions = json.load(f)\n",
    "    \n",
    "with open('../data/properties.json') as f:\n",
    "    properties = json.load(f)\n",
    "    \n",
    "types = [\"physobj\", \"agent\", \"location\", \"pose\", \"action\", \"number\", \"direction\"]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf3ed761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dev Dataset\n",
    "dev = []\n",
    "with open('../data/dev.txt') as f:\n",
    "    for line in f:\n",
    "        dev.append(line.replace(\"\\n\",\"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e09518d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['that screw belongs to Evan',\n",
       " 'pose screw feeder',\n",
       " 'first verify that you can see the hole',\n",
       " 'then mount the screw',\n",
       " 'then align with the hole',\n",
       " 'Then run the screwdriver job of the screw',\n",
       " 'first go to pose conveyor',\n",
       " 'then verify that you can see the NFSV',\n",
       " 'Then get the NFSV on the work area',\n",
       " 'then search for 2 m3 holes',\n",
       " 'screw a M3 screw into the left M3 hole',\n",
       " 'then go to pose work area',\n",
       " 'screw a M3 screw into the right M3 hole',\n",
       " 'then get the NFSV on the conveyor',\n",
       " 'then advance the conveyor belt',\n",
       " 'assemble a NFSV',\n",
       " 'replace search for 2 m3 holes with search for 2 deep m3 holes',\n",
       " 'replace screw an M3 screw into the left M3 hole with screw an M3 screw into the bottom deep M3 hole',\n",
       " 'replace screw an M3 screw into the right M3 hole with screw an M3 screw into the top deep M3 hole']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1d5fb0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\r\n"
     ]
    }
   ],
   "source": [
    "!echo $OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42ed162a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI,ChatAnthropic\n",
    "from langchain.chains import LLMChain\n",
    "import anthropic\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b543c0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LLM \n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.0)\n",
    "#llm = OpenAI(temperature=0.0)\n",
    "#llm = Anthropic(model=\"claude-instant-1.1-100k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "37086b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## (1) Speech Act Classification \n",
    "\n",
    "template_speech_act= \"\"\"\n",
    "Decide whether the utterance below from a speaker to a listener is one of \"want\", \"wantBel\", \"itk\"\n",
    "A \"want\" is an imperative statement or a request by the speaker to have the listener do an action or stop doing an action.\n",
    "An \"itk\" is a 'wh' or 'yes/no' query (what, why, when, where, who) or request from a speaker for more information from the listener about the listeners knowledge, beliefs or perceptions\n",
    "A \"wantBel\" is a statement of fact or opinion that the speaker conveys to a listener and  expects to listener to come to believe. \n",
    "\n",
    "\n",
    "\n",
    "utterance: \\n{utterance}\\n\n",
    "act:\n",
    "\"\"\"\n",
    "\n",
    "prompt_speech_act = PromptTemplate(\n",
    "    input_variables=[\"utterance\"],\n",
    "    template=template_speech_act\n",
    ")\n",
    "\n",
    "chain_speech_act = LLMChain(llm=llm, prompt=prompt_speech_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9145543c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## (2) Central Referents \n",
    "\n",
    "template_centralref = \"\"\"\n",
    "What is the central item (which could be a single thing or a collection of things) that is being referred to in the below sentence?\n",
    "\n",
    "Remember, the central referent is a thing or object, not an action or descriptor.It is meant to capture the central real world item being referenced in the utterance. \n",
    "\n",
    "\n",
    "sentence: \\n{utterance}\\n \n",
    "referent:\n",
    "\"\"\"\n",
    "\n",
    "prompt_centralref = PromptTemplate(\n",
    "    input_variables=[\"utterance\"],\n",
    "    template=template_centralref\n",
    ")\n",
    "\n",
    "chain_centralref = LLMChain(llm=llm, prompt=prompt_centralref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e9204930",
   "metadata": {},
   "outputs": [],
   "source": [
    "## (3) Supporting Referents\n",
    "\n",
    "template_suppref = \"\"\"\n",
    "What are some objects (which could be a single thing or a collection of things) that is being referred to in the below sentence not including the central referent? Return as a python list.\n",
    "If none, then return empty list []. Even if only one item, return as a list.  \n",
    "Remember, the supporting referents are things or objects, not actions or descriptors. They are meant to capture the real world items being referenced in the utterance. \n",
    "\n",
    "\n",
    "sentence: \\n{utterance}\\n \n",
    "central referent: \\n{centralref}\\n\n",
    "supporting referents (noun(s) from utterance):\n",
    "\"\"\"\n",
    "\n",
    "prompt_suppref = PromptTemplate(\n",
    "    input_variables=[\"utterance\", \"centralref\"],\n",
    "    template=template_suppref\n",
    ")\n",
    "\n",
    "chain_suppref = LLMChain(llm=llm, prompt=prompt_suppref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc907d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## (4) Getting the type of thing that the referents are \n",
    "\n",
    "template_typeof = \"\"\"\n",
    "Determine whether or not the referent item mentioned below in the context of the provided utterance is one of the types also provided below. To check if the referent is of a type, follow the below procedure\n",
    "1. Iterate through each item mentioned in the list of types. \n",
    "2. For each item X in the list of types expand on the meaning of each item, and then ask if the central referent is of type X given that meaning. \n",
    "3. If the central referent is of type X in the list, return X.\n",
    "\n",
    "\\n\\n EXAMPLE \\n\n",
    "utterance: The lemon is on the table\n",
    "referent: lemon\n",
    "types: ['area', 'physobj', 'location', 'pose']\n",
    "typeOf: Looking through the items in the list of types above. physobj is a physical object. lemon is a type of physical object. So, it is of type physobj\n",
    "\n",
    "Remember, return specifically ONE of the items in the list, or if none apply then return NONE. \n",
    "\n",
    "utterance: \\n{utterance}\\n\n",
    "referent: \\n{ref}\\n\n",
    "types: \\n{types}\\n\n",
    "typeOf:\n",
    "\"\"\"\n",
    "\n",
    "prompt_typeof = PromptTemplate(\n",
    "    input_variables=[\"ref\", \"types\", \"utterance\"],\n",
    "    template=template_typeof\n",
    ")\n",
    "\n",
    "chain_typeof = LLMChain(llm=llm, prompt=prompt_typeof)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dc4ea08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## (5) Extract CPC\n",
    "\n",
    "template_cpc = \"\"\"\n",
    "Determine the core propositional content (cpc) of the utterance below in the context of its central referent and speech act type\n",
    "To do so, use the following procedure\n",
    "\n",
    "1. Determine the type of cpc (\"action\", \"concept\") associated with the utterance.\n",
    "If the speech act is a \"want\" that means the utterance is an imperative and the cpc is an \"action\".\n",
    "If the speech act is a \"wantBel\" (note the capital B) that means the utterance is a statement assertion, and the cpc will be a \"concept\"\n",
    "If the speech act is an \"itk\" that means the utterance contains a question about some concept, so the cpc is a \"concept\"\n",
    "\n",
    "2. If the type of cpc is an \"action\", then the core propositional content (or cpc) is the action that is being performed on the central referent.\n",
    "If the type of cpc is a \"concept\", then the core propositional content (or cpc) is a concept that is being associated with the central referent.\n",
    "\n",
    "3. Convert the cpc into a single representative word that captures its meaning, without any reference to the referents.\n",
    "\n",
    "4. return the converted cpc and its type in the following format \"<CPC>:<TYPE>\" \n",
    "\n",
    "utterance: \\n{utterance}\\n\n",
    "speech act: \\n{speechact}\\n\n",
    "central referent: \\n{centralref}\n",
    "core propositional content and:\n",
    "\"\"\"\n",
    "\n",
    "prompt_cpc = PromptTemplate(\n",
    "    input_variables=[\"centralref\", \"utterance\",\"speechact\"],\n",
    "    template=template_cpc\n",
    ")\n",
    "\n",
    "chain_cpc = LLMChain(llm=llm, prompt=prompt_cpc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9323172f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## (6) Candidate Real Actions \n",
    "## \"Real\" == actions implemented in the robot system. \n",
    "\"\"\"\n",
    "Approach: look to see if there exists an action that captures this.\n",
    "\n",
    "Criteria\n",
    "(1) Semantic similarity of Name \n",
    "(2) The arguments in the robot action exist in the linguistic parse. If not then we are either in the wrong action or we are missing an action\n",
    "\"\"\"\n",
    "\n",
    "template_candidate_realactions =\"\"\"\n",
    "Select a list of candidate actions from the list of available actions that is most relevant to the core action performed on the central referent as understood in the context of the utterance. \n",
    "\n",
    "To decide the list of applicable candidate actions, use the following procedure to systematically filter the list of available actions:\n",
    "1. Compare the name and description (if any) of each action in the available actions to the core action. Narrow the list of actions to include only those with a semantically similar name or description to the central action. \n",
    "2. Return the narrowed list of actions as a python list of string action names. \n",
    "\n",
    "\\n\\n LIST OF AVAILABLE ACTIONS \\n:\n",
    "{actions}\n",
    "\n",
    "utterance: \\n{utterance}\\n\n",
    "central referent: \\n{centralref}\\n\n",
    "core action: \\n{cpc}\\n\n",
    "candidate actions:\n",
    "\"\"\"\n",
    "\n",
    "prompt_candidate_realactions = PromptTemplate(\n",
    "    input_variables=[\"centralref\", \"utterance\",\"cpc\", \"actions\"],\n",
    "    template=template_candidate_realactions\n",
    ")\n",
    "\n",
    "chain_candidate_realactions = LLMChain(llm=llm, prompt=prompt_candidate_realactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "61086150",
   "metadata": {},
   "outputs": [],
   "source": [
    "## (7) Tether Real Action\n",
    "# provided a list of realarguments, bind referents to them. \n",
    "\n",
    "template_bound_action = \"\"\"\n",
    "Try to bind each candidate action's arguments to the central and supplementary referents. Use the following procedure:\n",
    "For each candidate action: \n",
    "1. Look at its arguments in order written as \"VAR<NUM>:<TYPE>\". If the first argument is of TYPE \"agent\", then bind that to \"self\".\n",
    "2. For the second argument (if it exists), if the central referent is an object of  type TYPE in the argument, then bind the central referent to the TYPE. If not, bind to NONE. \n",
    "3. For  any subsequent arguments, attempt to bind the supplementary referents in the same way. \n",
    "4. Return output as a list of dicts, each with the name of the action, and bindings. \n",
    "\n",
    "utterance: \\n{utterance}\\n\n",
    "central referent: \\n{centralref}\\n\n",
    "supplementary referents: \\n{supprefs}\\n\n",
    "candidate actions: \\n{candidaterealactions}\\n\n",
    "bound actions:\n",
    "\"\"\"\n",
    "\n",
    "prompt_bound_action = PromptTemplate(\n",
    "    input_variables=[\"centralref\", \"supprefs\", \"utterance\",\"candidaterealactions\"],\n",
    "    template=template_bound_action\n",
    ")\n",
    "\n",
    "chain_bound_action = LLMChain(llm=llm, prompt=prompt_bound_action)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82498f3",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8670acd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import string\n",
    "\n",
    "def linguistic_parse(utterance):\n",
    "    speech_act = chain_speech_act.run(utterance=utterance).lower()\n",
    "    \n",
    "    # 2. Central Referent Extraction\n",
    "    centralref = chain_centralref.run(utterance=utterance).lower()\n",
    "    \n",
    "    centralreftype = chain_typeof.run(ref=centralref, types=types, utterance=utterance ).split(\" \")[-1]\n",
    "    centralreftype = centralreftype.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # 3. Supporting Referents Extraction\n",
    "    supprefs = chain_suppref.run(utterance=utterance, centralref=centralref).lower()\n",
    "    supprefs = ast.literal_eval(supprefs)\n",
    "    \n",
    "    supprefs_full = [] #with type info\n",
    "    if supprefs:\n",
    "        for suppref in supprefs:\n",
    "            ref_type = chain_typeof.run(ref=suppref, types=types, utterance=utterance ).split(\" \")[-1]\n",
    "            supprefs_full.append(f\"{suppref}:{ref_type}\")\n",
    "            \n",
    "\n",
    "    cpc = chain_cpc.run(utterance=utterance, speechact=speech_act, centralref=centralref)\n",
    "    \n",
    "    candidates = []\n",
    "    bound_candidates = []\n",
    "    if \":action\" in cpc:\n",
    "        candidates = chain_candidate_realactions.run(utterance=utterance, \n",
    "                                                       centralref=centralref,\n",
    "                                                       cpc=cpc,\n",
    "                                                       actions=actions) \n",
    "        candidates = ast.literal_eval(candidates)\n",
    "        \n",
    "        ## need to pass in for each candidate\n",
    "        \n",
    "        bound_candidates = chain_bound_action.run(utterance=utterance,\n",
    "                                              centralref=centralref,\n",
    "                                              supprefs=supprefs_full,\n",
    "                                              candidaterealactions=find_dict_in_list(actions, \n",
    "                                                                                     \"name\", \n",
    "                                                                                     candidates[0]))\n",
    "        \n",
    "    else: \n",
    "        # this is concept to be asserted into belief\n",
    "        pass\n",
    "    \n",
    "    output = {\n",
    "        \"utterance\": utterance,\n",
    "        \"speech_act\": speech_act,\n",
    "        \"centralref\": f\"{centralref}:{centralreftype}\",\n",
    "        \"supprefs\": supprefs_full,\n",
    "        \"cpc\": cpc,\n",
    "        \"candidates\": candidates,\n",
    "        \"bound_candidates\": bound_candidates\n",
    "    }\n",
    "    \n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "91710b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'utterance': 'then assemble the caddy',\n",
       " 'speech_act': 'want',\n",
       " 'centralref': 'caddy:physobj',\n",
       " 'supprefs': [],\n",
       " 'cpc': 'assemble:action',\n",
       " 'candidates': ['assemble', 'assemblenfsv', 'assemblenvfau', 'modifyAssemble'],\n",
       " 'bound_candidates': \"[{'name': 'assemble', 'bindings': {'VAR0': 'self', 'VAR1': 'caddy'}}]\"}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linguistic_parse(\"then assemble the caddy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f35aec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for text in dev:\n",
    "    print(text)\n",
    "    out = linguistic_parse(text)\n",
    "    print(json.dumps(out, indent=2))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dfe373ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Method\n",
    "# Given a list of dictionaries, and a key, return the entry in the list that matches\n",
    "def find_dict_in_list(lst, key, target):\n",
    "    for item in lst:\n",
    "        if not key in item:\n",
    "            #print(\"Key not in Dict\")\n",
    "            return None\n",
    "        if item[key] == target:\n",
    "            return item\n",
    "    #print(\"Nothing found\")\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "025e8a7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'mountScrew', 'roles': [{'VAR0': 'agent'}, {'VAR1': 'physobj'}]}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_dict_in_list(actions, \"name\", \"mountScrew\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e0ab76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
