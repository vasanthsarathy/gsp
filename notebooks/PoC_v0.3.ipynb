{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44deaadf",
   "metadata": {},
   "source": [
    "# Version 3\n",
    "\n",
    "The basic idea here is to extract the CPC first. This is the `core propositional content` or the the central thing that the speaker is talking about -- Could be an action or concept. In either case, it is the thing that the listener is not exepected to have presupposed. E.g., \"The purple box is open\". There the listener is expected to know about the purple box, but not that it is open. \n",
    "\n",
    "**Algorithm:**\n",
    "\n",
    "Input: utterance U, ActionDb A, ConceptDB C, AvailableTypes T\n",
    "\n",
    "1. speech_act <-- extract_speech_act(U) \n",
    "2. refs <-- extract_referents(U) \n",
    "3. ref_dict <-- extract_referent_types(U, refs, T)\n",
    "4. cpc_name <-- extract_cpc_name(U) \n",
    "5. ling_cpc_signature <-- extract_cpc_sign(U, cpc_name, ref_dict)\n",
    "6. * ling_parse <-- tether(U, ling_cpc_signature, A, C, T)\n",
    "    \n",
    "    \n",
    "For \"INSTRUCT\" speech acts, `tethering` involves:\n",
    "- comparing the linguistically derived parse (i.e., ling_parse) with available action signatures, and generating an association chain between the cpc_name and one or more corresponding actions \n",
    "    - ranked list of name matches. Filter down this list with argument matching. \n",
    "    - Failure here means agent cannot perform action\n",
    "\n",
    "For \"STATEMENT\" speech acts, `tethering` involves:\n",
    "- comparing the linguistically derived parse (i.e., ling_parse) with available concepts.\n",
    "    - Failure here means agent can learn a new fact, but not understand its meaning or be able to recognize the concept in a different setting, without further attempts at tethering. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d128075",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = [\n",
    "    \"pick up the mug\",\n",
    "    \"pick up that mug on the table\",\n",
    "    \"this object is a mug\",\n",
    "    \"that mug belongs to Evan\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42ed162a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b543c0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LLM \n",
    "\n",
    "#llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.0)\n",
    "llm = OpenAI(temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37086b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## (1) Speech Act Classification \n",
    "\n",
    "template_speech_act= \"\"\"\n",
    "Decide whether the utterance below from a speaker to a listener is one of INSTRUCT, STATEMENT, GREETING, QUESTIONWH ('wh', questions), QUESTIONYN ('yes/no' questions), ACK (e.g. \"yes\" or \"ok\"), or UNKNOWN \n",
    "An INSTRUCT is an imperative statement or a request by the speaker to have the listener do an action or stop doing an action.\n",
    "A QUESTIONWH is a 'wh' query (what, why, when, where, who) or request from a speaker for more information from the listener about the listeners knowledge, beliefs or perceptions\n",
    "A QUESTIONYN is a 'yes/no' query or request from a speaker for more information from the listener about the listeners knowledge, beliefs or perceptions, but the speaker expects a yes or no for an answer\n",
    "A STATEMENT is a statement of fact or opinion that the speaker conveys to a listener. \n",
    "A GREETING is an expression of social connection establishing the start of the conversation. E.g., \"Hello\"\n",
    "A ACK is an acknowledgement (either \"yes\" or \"no\").\n",
    "A UNKNOWN is an utterance not one of the above. \n",
    "\n",
    "utterance: \\n{utterance}\\n\n",
    "act:\n",
    "\"\"\"\n",
    "\n",
    "prompt_speech_act = PromptTemplate(\n",
    "    input_variables=[\"utterance\"],\n",
    "    template=template_speech_act\n",
    ")\n",
    "\n",
    "chain_speech_act = LLMChain(llm=llm, prompt=prompt_speech_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9145543c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## (2) Central Referents \n",
    "\n",
    "template_centralref = \"\"\"\n",
    "What is the central item (which could be a single thing or a collection of things) that is being referred to in the below sentence?\n",
    "\n",
    "sentence: \\n{utterance}\\n \n",
    "referent:\n",
    "\"\"\"\n",
    "\n",
    "prompt_centralref = PromptTemplate(\n",
    "    input_variables=[\"utterance\"],\n",
    "    template=template_centralref\n",
    ")\n",
    "\n",
    "chain_centralref = LLMChain(llm=llm, prompt=prompt_centralref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e9204930",
   "metadata": {},
   "outputs": [],
   "source": [
    "## (3) Supporting Referents\n",
    "\n",
    "template_suppref = \"\"\"\n",
    "What are some objects/referents (which could be a single thing or a collection of things) that is being referred to in the below sentence not including the central referent? Return as a python list.\n",
    "If none, then return empty list []. Even if only one item, return as a list. \n",
    "\n",
    "sentence: \\n{utterance}\\n \n",
    "central referent: \\n{centralref}\\n\n",
    "supporting referents:\n",
    "\"\"\"\n",
    "\n",
    "prompt_suppref = PromptTemplate(\n",
    "    input_variables=[\"utterance\", \"centralref\"],\n",
    "    template=template_suppref\n",
    ")\n",
    "\n",
    "chain_suppref = LLMChain(llm=llm, prompt=prompt_suppref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc907d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## (4) Getting the type of thing that the referents are \n",
    "\n",
    "template_typeof = \"\"\"\n",
    "Determine whether or not the referent item mentioned below in the context of the provided utterance is one of the types also provided below. To check if the referent is of a type, follow the below procedure\n",
    "1. Iterate through each item mentioned in the list of types. \n",
    "2. For each item X in the list of types expand on the meaning of each item, and then ask if the central referent is of type X given that meaning. \n",
    "3. If the central referent is of type X in the list, return X.\n",
    "\n",
    "\\n\\n EXAMPLE \\n\n",
    "utterance: The lemon is on the table\n",
    "referent: lemon\n",
    "types: ['area', 'physobj', 'location']\n",
    "typeOf: Looking through the items in the list of types above. physobj is a physical object. lemon is a type of physical object. So, it is of type physobj\n",
    "\n",
    "Remember, return specifically ONE of the items in the list, or if none apply then return NONE. \n",
    "\n",
    "utterance: \\n{utterance}\\n\n",
    "referent: \\n{ref}\\n\n",
    "types: \\n{types}\\n\n",
    "typeOf:\n",
    "\"\"\"\n",
    "\n",
    "prompt_typeof = PromptTemplate(\n",
    "    input_variables=[\"ref\", \"types\", \"utterance\"],\n",
    "    template=template_typeof\n",
    ")\n",
    "\n",
    "chain_typeof = LLMChain(llm=llm, prompt=prompt_typeof)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30454cb",
   "metadata": {},
   "source": [
    "# Robot Capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa327e26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e82498f3",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8670acd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def linguistic_parse(utterance):\n",
    "    speech_act = chain_speech_act.run(utterance=utterance).lower()\n",
    "    \n",
    "    # 2. Central Referent Extraction\n",
    "    centralref = chain_centralref.run(utterance=utterance).lower()\n",
    "    \n",
    "    # 3. Supporting Referents Extraction\n",
    "    supprefs = chain_suppref.run(utterance=utterance, centralref=centralref).lower()\n",
    "    supprefs = ast.literal_eval(supprefs)\n",
    "    \n",
    "    reftypes = []\n",
    "    for suppref in supprefs:\n",
    "        ref_type = chain_typeof(utterance=utterance, types=types, ref=suppref)\n",
    "    \n",
    "    output = {\n",
    "        \"utterance\": utterance,\n",
    "        \"speech_act\": speech_act,\n",
    "        \"centralref\": centralref,\n",
    "        \"supprefs\": supprefs    \n",
    "    }\n",
    "    \n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "18f35aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'utterance': 'pick up the mug', 'speech_act': 'instruct', 'centralref': 'mug', 'supprefs': []}\n",
      "{'utterance': 'pick up that mug on the table', 'speech_act': 'instruct', 'centralref': 'mug', 'supprefs': ['table']}\n",
      "{'utterance': 'this object is a mug', 'speech_act': 'statement', 'centralref': 'mug', 'supprefs': []}\n",
      "{'utterance': 'that mug belongs to Evan', 'speech_act': 'statement', 'centralref': 'mug', 'supprefs': ['evan']}\n"
     ]
    }
   ],
   "source": [
    "for text in dev:\n",
    "    out = linguistic_parse(text)\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a553a355",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91710b35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
