{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9704ddfa-42b0-413c-9676-8a52dc9bbf61",
   "metadata": {},
   "source": [
    "## Evaluate\n",
    "\n",
    "Create an evaluator class and associated subclasses for my custom evaluators\n",
    "- \"CPC name checker\" - is_same_pred_name()\n",
    "- Supps name checker: \n",
    "- cog status checker \n",
    "- variable binding checker \n",
    "- valid json checker\n",
    "- valid cpc checker\n",
    "- valid supplemental semantics checker\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a74723-d4d0-4a85-b277-b14dbb4aed59",
   "metadata": {},
   "source": [
    "## Evaluate\n",
    "\n",
    "- for each item in the dataset\n",
    "  \n",
    "    - run the model to produce a json_semantics_predicted\n",
    "    - check if valid json\n",
    "    - check intent (t/f)\n",
    "    - check cpc name (t/f)\n",
    "    - if an INSTRUCT, was the CPC selected from action repertoire? (t/f)\n",
    "    - What number of supps are present in the properties repertoire \n",
    "    - check supps precision/recall\n",
    "    - check cpc args length (t/f)\n",
    "    - variable asignment check: check if variables are present in the right descriptors\n",
    "      - there is a prec and recall aspect here. there are two lists for each variable\n",
    "      - For each variable, there is predicted and truth set of supps that it is associated with\n",
    "      - For each variable there is a cpc position it is associated with\n",
    "      - E.g., VAR0: {blue, ball, on}, pickup(),   \"Pick up the blue ball on the table.\"\n",
    "    - variable ordering : on(VAR0, VAR1), table(VAR1), ball(VAR0). pickup(_, VAR0)\n",
    "    - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8705c509-68a1-4774-bc27-0219270b96bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "import json\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx.algorithms.isomorphism as iso\n",
    "import ast\n",
    "\n",
    "def evaluate(predicted, truth):\n",
    "    \"\"\"\n",
    "    Returns an evaluation json that contains various metrics \n",
    "    input: strings obtained from the language model\n",
    "    input: json of the ground truth\n",
    "    \"\"\"\n",
    "    item = {}\n",
    "    item['truth'] = truth\n",
    "    if isinstance(predicted, str):\n",
    "        # Validate json \n",
    "        predicted_json = {}\n",
    "        try:\n",
    "            predicted_json = ast.rom langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "import json\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx.algorithms.isomorphism as iso\n",
    "import ast\n",
    "\n",
    "def evaluate(predicted, truth):\n",
    "    \"\"\"\n",
    "    Returns an evaluation json that contains various metrics \n",
    "    input: strings obtained from the language model\n",
    "    input: json of the ground truth\n",
    "    \"\"\"\n",
    "    item = {}\n",
    "    item['truth'] = truth\n",
    "    if isinstance(predicted, str):\n",
    "        # Validate json \n",
    "        predicted_json = {}\n",
    "        try:\n",
    "            predicted_json = ast.literal_eval(predicted_json_str)\n",
    "            item['valid_json'] = True\n",
    "            item['prediction'] = predicted_json\n",
    "        except:\n",
    "            item['valid_json'] = False\n",
    "            pass\n",
    "    \n",
    "        # try to fix the json with gpt\n",
    "        if not item['valid_json']:\n",
    "            # try to fix it.\n",
    "            new_json_str = fix_json(predicted)\n",
    "            \n",
    "            try: \n",
    "                predicted_json = ast.literal_eval(new_json_str)\n",
    "                item['prediction'] = predicted_json\n",
    "            except e:\n",
    "                print(e)\n",
    "                print(\"ERROR: Could not fix input json\")\n",
    "                return item\n",
    "    else:\n",
    "        item['prediction'] = predicted\n",
    "        item['valid_json'] = True\n",
    "\n",
    "    # check intent\n",
    "    if item['prediction']['intent'] == truth['intent']:\n",
    "        item['intent_correct'] = True\n",
    "    else:\n",
    "        item['intent_correct'] = False\n",
    "\n",
    "    # check cpc name\n",
    "    if  is_same_pred_name(item['prediction']['central_proposition'], truth['central_proposition']):\n",
    "        item['cpc_name_correct'] = True\n",
    "    else:\n",
    "        item['cpc_name_correct'] = False\n",
    "\n",
    "    # check if correct number of sups\n",
    "    spc_name_prediction = [pred_name(i) for i in item['prediction']['supplemental_semantics']]\n",
    "    spc_name_truth = [pred_name(i) for i in truth['supplemental_semantics']]\n",
    "\n",
    "    if len(spc_name_prediction) == len(spc_name_truth):\n",
    "        item['spc_length_correct'] = True\n",
    "    else:\n",
    "        item['spc_length_correct'] = False\n",
    "\n",
    "    # Evaluate accuracy of spc\n",
    "    item['spc_accuracy'] = {}\n",
    "    spc_intersection = set(spc_name_prediction).intersection(set(spc_name_truth))\n",
    "    item['spc_accuracy']['precision'] = len(spc_intersection)/len(spc_name_prediction)\n",
    "    item['spc_accuracy']['recall'] = len(spc_intersection)/len(spc_name_truth)\n",
    "\n",
    "    # check for variable assignment and mapping. \n",
    "    if is_isomorphic(item['prediction'],truth):\n",
    "        item['is_isomorphic'] = True\n",
    "    else:\n",
    "        item['is_isomorphic'] = False\n",
    "\n",
    "    if is_matched(item['prediction'], truth):\n",
    "        item['is_matched'] = True\n",
    "    else:\n",
    "        item['is_matched'] = False\n",
    "\n",
    "    return item\n",
    "\n",
    "#### graph matching\n",
    "\n",
    "def build_semantic_graph(parse):\n",
    "    \"\"\"\n",
    "    builds up a graph \n",
    "    \"\"\"\n",
    "\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    # let's first do the \"intent\"\n",
    "    cpc_name = pred_name(parse['central_proposition'])\n",
    "    cpc_args = pred_args(parse['central_proposition'])\n",
    "    \n",
    "    G.add_node(cpc_name, name=cpc_name, source='cpc', type='pred_name')\n",
    "    for idx,arg in enumerate(cpc_args):\n",
    "        G.add_node(arg, name=arg, source='args', type='pred_arg')\n",
    "        G.add_edge(arg,cpc_name,pos=idx)\n",
    "\n",
    "    for spc in parse['supplemental_semantics']:\n",
    "        spc_name = pred_name(spc)\n",
    "        spc_args = pred_args(spc)\n",
    "        G.add_node(spc_name, name=spc_name, source='spc', type='pred_name')\n",
    "        for idx, arg in enumerate(spc_args):\n",
    "            G.add_node(arg, name=arg, source='args', type='pred_arg')\n",
    "            G.add_edge(arg,spc_name,pos=idx)\n",
    "    return G\n",
    "\n",
    "def is_isomorphic(predicted, truth):\n",
    "    \"\"\"\n",
    "    Checks if all the right variables are positioned correctly in the CPC and SPC\n",
    "    \"\"\"\n",
    "    G_predicted = build_semantic_graph(predicted)\n",
    "    G_truth = build_semantic_graph(truth)\n",
    "    em = iso.categorical_edge_match(\"pos\", 1)\n",
    "    return nx.is_isomorphic(G_truth, G_predicted, edge_match=em)\n",
    "\n",
    "def is_matched(predicted, truth):\n",
    "    \"\"\"\n",
    "    Checks if each variable is correctly connected to exactly the same set of cpc and spcs. \n",
    "    \"\"\"\n",
    "    G_predicted = build_semantic_graph(predicted)\n",
    "    G_truth = build_semantic_graph(truth)\n",
    "\n",
    "    # get all the nodes that are variables\n",
    "    args_predicted = [x for x,y in G_predicted.nodes(data=True) if y['type']=='pred_arg']\n",
    "    args_truth = [x for x,y in G_truth.nodes(data=True) if y['type']=='pred_arg']\n",
    "\n",
    "    for p,t in zip(args_predicted, args_truth):\n",
    "        successors_predicted = G_predicted.successors(p)\n",
    "        successors_truth = G_truth.successors(t)\n",
    "        s1 = set(successors_predicted)\n",
    "        s2 = set(successors_truth)\n",
    "        if not s1 == s2: \n",
    "            return False\n",
    "    return True\n",
    "    \n",
    "\n",
    "### UTILITIES ####\n",
    "\n",
    "def fix_json(json_str):\n",
    "    llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.0)\n",
    "    template = \"\"\"\n",
    "        Fix the input json string to produce an output that has a valid json format. Only change things like the parenthesis, commas etc.\n",
    "        \n",
    "        json_input: \\n{json_str}\\n\n",
    "        rewritten valid json:\n",
    "        \"\"\"\n",
    "    prompt = PromptTemplate(input_variables=[\"json_str\"],template=template)\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    output = chain.run(json_str=json_str)\n",
    "    return output\n",
    "\n",
    "def is_same_pred_name(predicted_pred, truth_pred):\n",
    "    if predicted_pred.split(\"(\")[0] == truth_pred.split(\"(\")[0]:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def pred_name(pred):\n",
    "    return pred.split(\"(\")[0].lower()\n",
    "\n",
    "def pred_args(pred):\n",
    "    return pred.split(\"(\")[1].split(\")\")[0].split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f32299aa-f200-4009-a8b5-2340251f5b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = {\n",
    "  \"intent\": \"INSTRUCT\",\n",
    "  \"central_proposition\": \"putleftof(self:agent,VAR0,VAR1)\",\n",
    "  \"supplemental_semantics\": [\n",
    "    \"hammer(VAR0)\",\n",
    "    \"diningtable(VAR1)\",\n",
    "    \"INDEFINITE(VAR0)\"\n",
    "  ]\n",
    "}\n",
    "\n",
    "predicted_str = \"\"\"\n",
    "{\n",
    "  \"intent\": \"INSTRUCT\",\n",
    "  \"central_proposition\": \"putleftof(self:agent,VAR0,VAR1)\",\n",
    "  \"supplemental_semantics\": [\n",
    "    \"hammer(VAR0)\",\n",
    "    \"diningtable(VAR1)\",\n",
    "    \"INDEFINITE(VAR0)\"\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "bad_predicted_str = \"\"\"\n",
    "{\n",
    "  \"intent\": \"INSTRUCT\",\n",
    "  \"central_proposition\": \"putleftof(self:agent,VAR0,VAR1)\",\n",
    "  \"supplemental_semantics\": [\n",
    "    \"hammer(VAR0)\"\n",
    "    \"diningtable(VAR1)\",\n",
    "    \"INDEFINITE(VAR0)\"\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "truth = {\n",
    "  \"intent\": \"INSTRUCT\",\n",
    "  \"central_proposition\": \"putleftof(self:agent,X,D)\",\n",
    "  \"supplemental_semantics\": [\n",
    "    \"hammer(X)\",\n",
    "    \"diningtable(D)\",\n",
    "    \"INDEFINITE(X)\"\n",
    "  ]\n",
    "}\n",
    "\n",
    "bad_predicted = {\n",
    "  \"intent\": \"INSTRUCT\",\n",
    "  \"central_proposition\": \"putleftof(self:agent,K,W)\",\n",
    "  \"supplemental_semantics\": [\n",
    "    \"hammer(W)\",\n",
    "    \"diningtable(K)\",\n",
    "    \"INDEFINITE(K)\"\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5b14c02e-9100-46d6-9f96-a2327cd3f1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = evaluate(bad_predicted, truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "50d22e6d-3aee-41c5-9d00-7894667cdc79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'truth': {'intent': 'INSTRUCT',\n",
       "  'central_proposition': 'putleftof(self:agent,X,D)',\n",
       "  'supplemental_semantics': ['hammer(X)', 'diningtable(D)', 'INDEFINITE(X)']},\n",
       " 'prediction': {'intent': 'INSTRUCT',\n",
       "  'central_proposition': 'putleftof(self:agent,K,W)',\n",
       "  'supplemental_semantics': ['hammer(W)', 'diningtable(K)', 'INDEFINITE(K)']},\n",
       " 'valid_json': True,\n",
       " 'intent_correct': True,\n",
       " 'cpc_name_correct': True,\n",
       " 'spc_length_correct': True,\n",
       " 'spc_accuracy': {'precision': 1.0, 'recall': 1.0},\n",
       " 'is_isomorphic': True,\n",
       " 'is_matched': False}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9629ad-a2a3-420d-957e-5a13ae7f83b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
