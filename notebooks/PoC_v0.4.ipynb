{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be2c88d9",
   "metadata": {},
   "source": [
    "# Version 4\n",
    "6/22/2023\n",
    "\n",
    "New  data structure for the parsing. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8426730",
   "metadata": {},
   "source": [
    "```\n",
    "        referents = [\n",
    "            {\"text\": \"m3 screw\", \n",
    "            \"type\": \"physobj\",\n",
    "            \"variable_name\": \"VAR0\",\n",
    "            \"cognitive status\": \"ACTIVATED\",\n",
    "            \"role\": \"central\"},\n",
    "            \n",
    "            {\"text\": \"evan\", \n",
    "            \"type\": \"agent\",\n",
    "            \"variable_name\": \"VAR1\",\n",
    "            \"cognitive status\": \"FAMILIAR\",\n",
    "            \"role\": \"supplemental\"}\n",
    "            ]\n",
    "            \n",
    "        descriptors = [\n",
    "            {\"text\": \"m3 screw\", \n",
    "            \"name\": \"m3\",\n",
    "            \"arguments\": [\"VAR0\"] },\n",
    "            \n",
    "            {\"text\": \"evan\", \n",
    "            \"name\": \"NONE\",\n",
    "            \"arguments\": [] }\n",
    "            ]\n",
    "        \n",
    "        intention: {\n",
    "            \"speech_act\": \"wantBel\",\n",
    "            \"proposition\":\n",
    "                {\"text\": belonging\",\n",
    "                \"type\": \"concept\",\n",
    "                \"arguments\": [\"VAR0\", \"VAR1\"]}\n",
    "            }\n",
    "               \n",
    "            \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40f4a32",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b09c865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\r\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI,ChatAnthropic\n",
    "from langchain.chains import LLMChain\n",
    "import json\n",
    "\n",
    "!echo $OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652c69d8",
   "metadata": {},
   "source": [
    "# Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "382f737a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a list of dictionaries, and a key, return the entry in the list that matches\n",
    "def find_dict_in_list(lst, key, target):\n",
    "    for item in lst:\n",
    "        if not key in item:\n",
    "            #print(\"Key not in Dict\")\n",
    "            return None\n",
    "        if item[key] == target:\n",
    "            return item\n",
    "    #print(\"Nothing found\")\n",
    "    return None\n",
    "\n",
    "def find_all_dicts_in_list(lst, key, target):\n",
    "    output = []\n",
    "    for item in lst:\n",
    "        if not key in item:\n",
    "            return output\n",
    "        if item[key] == target:\n",
    "            output.append(item)\n",
    "    #print(\"Nothing found\")\n",
    "    return output\n",
    "    \n",
    "\n",
    "def clean_candidates(candidates):\n",
    "    \"\"\"\n",
    "    Cleans the list of candidates to extract a list of names and a list of scores of the candidates\n",
    "    \"\"\"\n",
    "    names = []\n",
    "    scores = []\n",
    "    for candidate in candidates:\n",
    "        name = candidate.split(\":\")[0]\n",
    "        score = float(candidate.split(\":\")[1])\n",
    "        names.append(name)\n",
    "        scores.append(score)\n",
    "        \n",
    "    return names, scores\n",
    "\n",
    "\n",
    "def prune_candidates(names, scores, threshold=0.75):\n",
    "    return [(x,y) for x,y in zip(names,scores) if y > threshold ]\n",
    "\n",
    "def select_best_candidate(names, scores, threshold=0.75):\n",
    "    \"\"\"\n",
    "    Selects best name and score above a threshold. \n",
    "    \"\"\"\n",
    "    pruned_names = []\n",
    "    pruned_scores = []\n",
    "    for n,s in zip(names,scores):\n",
    "        if s>threshold:\n",
    "            pruned_names.append(n)\n",
    "            pruned_scores.append(s)\n",
    "    \n",
    "    if pruned_names:\n",
    "        return pruned_names[pruned_scores.index(max(pruned_scores))]\n",
    "    return \"NONE\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae2ef044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More helper functions GMR\n",
    "\n",
    "def central_referent(gmr):\n",
    "    return find_dict_in_list(gmr['referents'], \"role\", \"central\")\n",
    "\n",
    "def supp_referents(gmr):\n",
    "    return find_all_dicts_in_list(gmr['referents'], \"role\", \"supplemental\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca542a0c",
   "metadata": {},
   "source": [
    "# Initialize LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7b3cdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.0)\n",
    "#llm = OpenAI(temperature=0.0)\n",
    "#llm = Anthropic(model=\"claude-instant-1.1-100k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1079388a",
   "metadata": {},
   "source": [
    "# Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "212e7678",
   "metadata": {},
   "outputs": [],
   "source": [
    "## (1) Speech Act Classification \n",
    "\n",
    "template_speech_act= \"\"\"\n",
    "Decide whether the utterance below from a speaker to a listener is one of \"want\", \"wantBel\", \"itk\"\n",
    "A \"want\" is an imperative statement or a request by the speaker to have the listener do an action or stop doing an action.\n",
    "An \"itk\" is a 'wh' or 'yes/no' query (what, why, when, where, who) or request from a speaker for more information from the listener about the listeners knowledge, beliefs or perceptions\n",
    "A \"wantBel\" (note the uppercase B) is a statement of fact or opinion that the speaker conveys to a listener and  expects to listener to come to believe. \n",
    "\n",
    "\n",
    "\n",
    "utterance: \\n{utterance}\\n\n",
    "act:\n",
    "\"\"\"\n",
    "\n",
    "prompt_speech_act = PromptTemplate(\n",
    "    input_variables=[\"utterance\"],\n",
    "    template=template_speech_act\n",
    ")\n",
    "\n",
    "chain_speech_act = LLMChain(llm=llm, prompt=prompt_speech_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be062373",
   "metadata": {},
   "outputs": [],
   "source": [
    "## (2) Central Referents \n",
    "\n",
    "template_centralref = \"\"\"\n",
    "What is the central item (which could be a single thing or a collection of things) that is being referred to in the below sentence?\n",
    "\n",
    "Remember, the central referent is a thing or object, not an action or descriptor.It is meant to capture the central real world item being referenced in the utterance. \n",
    "\n",
    "\n",
    "sentence: \\n{utterance}\\n \n",
    "referent:\n",
    "\"\"\"\n",
    "\n",
    "prompt_centralref = PromptTemplate(\n",
    "    input_variables=[\"utterance\"],\n",
    "    template=template_centralref\n",
    ")\n",
    "\n",
    "chain_centralref = LLMChain(llm=llm, prompt=prompt_centralref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f731b719",
   "metadata": {},
   "outputs": [],
   "source": [
    "## (3) Supporting Referents\n",
    "\n",
    "template_suppref = \"\"\"\n",
    "What are some objects (which could be a single thing or a collection of things) that is being referred to in the below sentence not including the central referent? Return as a python list.\n",
    "If none, then return empty list []. Even if only one item, return as a list.  \n",
    "Remember, the supporting referents are things or objects, not actions or descriptors. They are meant to capture the real world items being referenced in the utterance. \n",
    "\n",
    "Do NOT include objects or collections that have already been covered in the central referent. \n",
    "\n",
    "sentence: \\n{utterance}\\n \n",
    "central referent: \\n{centralref}\\n\n",
    "supporting referents (noun(s) from utterance):\n",
    "\"\"\"\n",
    "\n",
    "prompt_suppref = PromptTemplate(\n",
    "    input_variables=[\"utterance\", \"centralref\"],\n",
    "    template=template_suppref\n",
    ")\n",
    "\n",
    "chain_suppref = LLMChain(llm=llm, prompt=prompt_suppref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b95d451",
   "metadata": {},
   "outputs": [],
   "source": [
    "## (4) Getting the type of thing that the referents are \n",
    "\n",
    "template_typeof = \"\"\"\n",
    "Determine whether or not the referent item mentioned below in the context of the provided utterance is one of the types also provided below. To check if the referent is of a type, follow the below procedure\n",
    "1. Iterate through each item mentioned in the list of types. \n",
    "2. For each item X in the list of types expand on the meaning of each item, and then ask if the central referent is of type X given that meaning. \n",
    "3. If the central referent is of type X in the list, return X.\n",
    "\n",
    "\\n\\n EXAMPLE \\n\n",
    "utterance: The lemon is on the table\n",
    "referent: lemon\n",
    "types: ['area', 'physobj', 'location', 'pose']\n",
    "typeOf: Looking through the items in the list of types above. physobj is a physical object. lemon is a type of physical object. So, it is of type physobj\n",
    "\n",
    "Remember, return specifically ONE of the items in the list, or if none apply then return NONE. \n",
    "\n",
    "utterance: \\n{utterance}\\n\n",
    "referent: \\n{ref}\\n\n",
    "types: \\n{types}\\n\n",
    "typeOf:\n",
    "\"\"\"\n",
    "\n",
    "prompt_typeof = PromptTemplate(\n",
    "    input_variables=[\"ref\", \"types\", \"utterance\"],\n",
    "    template=template_typeof\n",
    ")\n",
    "\n",
    "chain_typeof = LLMChain(llm=llm, prompt=prompt_typeof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2261958",
   "metadata": {},
   "outputs": [],
   "source": [
    "## (5) Extract CPC\n",
    "\n",
    "template_cpc = \"\"\"\n",
    "Determine the core propositional content (cpc) of the utterance below in the context of its central referent and speech act type\n",
    "To do so, use the following procedure\n",
    "\n",
    "1. Determine the type of cpc (\"action\", \"concept\") associated with the utterance.\n",
    "If the speech act is a \"want\" that means the utterance is an imperative and the cpc is an \"action\".\n",
    "If the speech act is a \"wantBel\" (note the capital B) that means the utterance is a statement assertion, and the cpc will be a \"concept\"\n",
    "If the speech act is an \"itk\" that means the utterance contains a question about some concept, so the cpc is a \"concept\"\n",
    "\n",
    "2. If the type of cpc is an \"action\", then the core propositional content (or cpc) is the action that is being performed on the central referent.\n",
    "If the type of cpc is a \"concept\", then the core propositional content (or cpc) is a concept that is being associated with the central referent.\n",
    "\n",
    "3. Convert the cpc into a single representative word that captures its meaning, without any reference to the referents.\n",
    "\n",
    "4. return the converted cpc and its type in the following format \"<CPC>:<TYPE>\" \n",
    "\n",
    "utterance: \\n{utterance}\\n\n",
    "speech act: \\n{speechact}\\n\n",
    "central referent: \\n{centralref}\n",
    "core propositional content and:\n",
    "\"\"\"\n",
    "\n",
    "prompt_cpc = PromptTemplate(\n",
    "    input_variables=[\"centralref\", \"utterance\",\"speechact\"],\n",
    "    template=template_cpc\n",
    ")\n",
    "\n",
    "chain_cpc = LLMChain(llm=llm, prompt=prompt_cpc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce026e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## (6) Candidate Real Actions \n",
    "## \"Real\" == actions implemented in the robot system. \n",
    "\"\"\"\n",
    "Approach: look to see if there exists an action that captures this.\n",
    "\n",
    "Criteria\n",
    "(1) Semantic similarity of Name \n",
    "(2) The arguments in the robot action exist in the linguistic parse. If not then we are either in the wrong action or we are missing an action\n",
    "\"\"\"\n",
    "\n",
    "template_candidate_realactions =\"\"\"\n",
    "Select a list of 5 candidate actions from the list of available actions that is most relevant to the core action performed on the central referent as understood in the context of the utterance. \n",
    "\n",
    "To decide the list of applicable candidate actions, use the following procedure to systematically filter the list of available actions:\n",
    "1. Compare the name and description (if any) of each action in the available actions to the core action. Narrow the list of actions to include only those with a semantically similar name or description to the central action. \n",
    "2. Return the narrowed list of actions as a python list of string action names followed by a colon and then a numeric score between 0 and 1 signifying the semantic similarity between the name or description and the central action.\n",
    "For example \"move:0.5\" where \"move\" is the action name and 0.5 is the similarity score. \n",
    "\n",
    "\\n\\n LIST OF AVAILABLE ACTIONS \\n:\n",
    "{actions}\n",
    "\n",
    "utterance: \\n{utterance}\\n\n",
    "central referent: \\n{centralref}\\n\n",
    "core action: \\n{cpc}\\n\n",
    "candidate actions:\n",
    "\"\"\"\n",
    "\n",
    "prompt_candidate_realactions = PromptTemplate(\n",
    "    input_variables=[\"centralref\", \"utterance\",\"cpc\", \"actions\"],\n",
    "    template=template_candidate_realactions\n",
    ")\n",
    "\n",
    "chain_candidate_realactions = LLMChain(llm=llm, prompt=prompt_candidate_realactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "986ae067",
   "metadata": {},
   "outputs": [],
   "source": [
    "## (7) Tether Real Action\n",
    "# provided a list of realarguments, bind referents to them. \n",
    "\n",
    "template_bound_action = \"\"\"\n",
    "Try to bind the candidate action's arguments to the central and supplementary referents. Use the following procedure:\n",
    "1. Look at the candidate action's arguments in order written as \"VAR<NUM>:<TYPE>\". If the first argument is of TYPE \"agent\", then bind that to \"self\".\n",
    "2. For the second argument (if it exists), if the central referent is an object of  type TYPE in the argument, then bind the central referent to the TYPE. If not, bind to NONE. \n",
    "3. For  any subsequent arguments, attempt to bind the supplementary referents in the same way. \n",
    "4. Return output as a python dictionary, with following format (Do NOT include any special characters like newlines):\n",
    "\"name\": \"<NAME OF THE ACTION>\",\"bindings\": [{{\"<VARIABLE NAME (E.g.VAR0)>\": \"<REFERENT>\"}}, ...]\n",
    "\n",
    "\n",
    "utterance: \\n{utterance}\\n\n",
    "central referent: \\n{centralref}\\n\n",
    "supplementary referents: \\n{supprefs}\\n\n",
    "candidate action: \\n{candidate_full_info}\\n\n",
    "bound action:\n",
    "\"\"\"\n",
    "\n",
    "prompt_bound_action = PromptTemplate(\n",
    "    input_variables=[\"centralref\", \"supprefs\", \"utterance\",\"candidate_full_info\"],\n",
    "    template=template_bound_action\n",
    ")\n",
    "\n",
    "chain_bound_action = LLMChain(llm=llm, prompt=prompt_bound_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f16d7de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## (6b) Candidate Real Concepts\n",
    "## \"Real\" == concepts understandable to a robotic system (some consultant exists for it)\n",
    "\"\"\"\n",
    "Approach: look to see if there exists an action that captures this.\n",
    "\n",
    "Criteria\n",
    "(1) Semantic similarity of Name \n",
    "(2) The arguments in the concept exist in the linguistic parse. If not then we are either in the wrong action or we are missing an action\n",
    "\"\"\"\n",
    "\n",
    "template_candidate_realconcepts=\"\"\"\n",
    "Select a list of 5 candidate concept from the list of available concepts that is most relevant to the core concept associated with the central referent as understood in the context of the utterance. \n",
    "\n",
    "To decide the list of applicable candidate concepts, use the following procedure to systematically filter the list of available concepts:\n",
    "1. Compare the name and description (if any) of each concept in the available concepts to the core concepts. Narrow the list of concepts to include only those with a semantically similar name or description to ONLY the core concept. \n",
    "2. Return the narrowed list of concepts as a python list of string concept names followed by a colon and then a numeric score between 0 and 1 signifying the semantic similarity between the name or description of the available concepts and the core concept. Do NOT return this as a dictionary\n",
    "\n",
    "\\n\\n LIST OF AVAILABLE CONCEPTS \\n:\n",
    "{concepts}\n",
    "\n",
    "utterance: \\n{utterance}\\n\n",
    "central referent: \\n{centralref}\\n\n",
    "core concept: \\n{cpc}\\n\n",
    "candidate concepts:\n",
    "\"\"\"\n",
    "\n",
    "prompt_candidate_realconcepts = PromptTemplate(\n",
    "    input_variables=[\"centralref\", \"utterance\",\"cpc\", \"concepts\"],\n",
    "    template=template_candidate_realconcepts\n",
    ")\n",
    "\n",
    "chain_candidate_realconcepts = LLMChain(llm=llm, prompt=prompt_candidate_realconcepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29e8d37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## (7b) Tether Real Concept, if available\n",
    "# provided a list of realarguments, bind referents to them. \n",
    "\n",
    "template_bound_concept = \"\"\"\n",
    "Try to bind each candidate concept's arguments to the central and supplementary referents. Use the following procedure:\n",
    "For each candidate concept: \n",
    "1. Look at its arguments in order written as \"VAR<NUM>:<TYPE>\". If the first argument is of TYPE \"agent\", then bind that to \"self\".\n",
    "2. For the second argument (if it exists), if the central referent is an object of  type TYPE in the argument, then bind the central referent to the TYPE. If not, bind to NONE. \n",
    "3. For  any subsequent arguments, attempt to bind the supplementary referents in the same way. \n",
    "4. Return output as a python dictionary, with following format (Do NOT include any special characters like newlines):\n",
    "\"name\": \"<NAME OF THE CONCEPT>\",\"bindings\": [{{\"<VARIABLE NAME (E.g.VAR0)>\": \"<REFERENT>\"}}, ...]\n",
    "\n",
    "utterance: \\n{utterance}\\n\n",
    "central referent: \\n{centralref}\\n\n",
    "supplementary referents: \\n{supprefs}\\n\n",
    "candidate concepts: \\n{candidate_full_info}\\n\n",
    "bound concept:\n",
    "\"\"\"\n",
    "\n",
    "prompt_bound_concept = PromptTemplate(\n",
    "    input_variables=[\"centralref\", \"supprefs\", \"utterance\",\"candidate_full_info\"],\n",
    "    template=template_bound_concept\n",
    ")\n",
    "\n",
    "chain_bound_concept = LLMChain(llm=llm, prompt=prompt_bound_concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "caa8ca34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (8) Novel concept induction\n",
    "\n",
    "template_novel_concept = \"\"\"\n",
    "Generate a concept template for the core concept within the context of the utterance. Use the following procedure:\n",
    "\n",
    "1. Extract a concept name. The name can be from the core concept itself. \n",
    "2. Generate a list of arguments, where each argument states the type of argument that can be bound to the concept.\n",
    "Here, we want to make sure that each argument type makes sense for the concept, and also can be bound to the central referent and zero or more of the supplemental references.\n",
    "\n",
    "Return output as a python dictionary, with following format (Do NOT include any special characters like newlines):\n",
    "\"name\": \"<NAME OF THE CORE CONCEPT>\",\"roles\": [{{\"<VARIABLE NAME (E.g.VAR0)>\": \"<TYPE>\"}}, ...]\n",
    "\n",
    "\n",
    "utterance: \\n{utterance}\\n\n",
    "core concept: \\n{cpc}\\n\n",
    "types: \\n{types}\\n\n",
    "central referent: \\n{centralref}\\n\n",
    "supplementary referents: \\n{supprefs}\\n\n",
    "novel concept: \n",
    "\"\"\"\n",
    "\n",
    "prompt_novel_concept = PromptTemplate(\n",
    "    input_variables=[\"centralref\", \"supprefs\", \"utterance\", \"cpc\", \"types\"],\n",
    "    template=template_novel_concept\n",
    ")\n",
    "\n",
    "chain_novel_concept = LLMChain(llm=llm, prompt=prompt_novel_concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7cefa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (9) SPC Property Candidate identification \n",
    "## getting the properties of interest\n",
    "## For each of the referents, we want to find any individual descriptors, we also want to find and apply any given relations between referents\n",
    "\n",
    "template_properties = \"\"\"\n",
    "Determine the properties of the referents. Use the following procedure for each of the referents:\n",
    "1. The names of each of the referents itself should be added as a property to the list.\n",
    "2. From the utterance, extract all the adjectival descriptors used to describe the properties of the referents, and add to list.\n",
    "3. Add to this list, any relations (mentioned in the utterance) between two or more of the referents. Do NOT include any relations that can be reasonably assumed to be already covered by the meaning of the core propositional content. \n",
    "4. Return this list as a list of python dictionaries with the following format:\n",
    "\"text\": <NAME OF PROPERTY/DESCRIPTOR/RELATION>, \"arguments\": <LIST OF VARIABLE NAMES> \n",
    "\n",
    "where the variable names correspond to the variable names associated with each of the referents. Remember, the variable names have to be correct.\n",
    "\n",
    "Remember, DO NOT include in the list anything that is semantically similar to the core propositional content since it would be redundant\n",
    "\n",
    "utterance: \\n{utterance}\\n\n",
    "referents: \\n{referent_info}\\n\n",
    "core propositional content: \\n{cpc}\\n\n",
    "supplemental properties, descriptors and relations not in the core propositional content:\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "prompt_properties = PromptTemplate(\n",
    "    input_variables=[\"referent_info\", \"utterance\", \"cpc\"],\n",
    "    template=template_properties\n",
    ")\n",
    "\n",
    "chain_properties = LLMChain(llm=llm, prompt=prompt_properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87ebc922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (10) Candidate real properties: Find the properties (SPCs) in the consultant properties. THese are things the robot perception/cognition can understand\n",
    "## \"Real\" == concepts understandable to a robotic system (some consultant exists for it)\n",
    "\n",
    "template_candidate_realprops=\"\"\"\n",
    "Select a list of 5 candidate concept from the list of available concepts that is most semantically similar to the property associated with the referent, as understood in the context of the utterance. \n",
    "\n",
    "To decide the list of applicable candidate concepts, use the following procedure to systematically filter the list of available concepts:\n",
    "1. Compare the name and description (if any) of each concept in the available concepts to the properties. Narrow the list of concepts to include only those with a semantically similar name or description to ONLY the property. \n",
    "2. Return the narrowed list of concepts as a python list of string concept names followed by a colon and then a numeric score between 0 and 1 signifying the semantic similarity between the name or description of the available concepts and the property.\n",
    " Do NOT return this as a dictionary\n",
    " \n",
    "\\n\\n LIST OF AVAILABLE CONCEPTS \\n:\n",
    "{concepts}\n",
    "\n",
    "utterance: \\n{utterance}\\n\n",
    "property: \\n{prop}\\n\n",
    "candidate concepts:\n",
    "\"\"\"\n",
    "\n",
    "prompt_candidate_realprops = PromptTemplate(\n",
    "    input_variables=[\"utterance\",\"prop\", \"concepts\"],\n",
    "    template=template_candidate_realprops\n",
    ")\n",
    "\n",
    "chain_candidate_realprops = LLMChain(llm=llm, prompt=prompt_candidate_realprops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b884a191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (11) Cognitive Status\n",
    "\n",
    "template_cognitive_status= \"\"\"\n",
    "Determine the cognitive status of each of the referents mentioned in the bindings. Use the following procedure for each of the referents:\n",
    "\n",
    "1. Decide which ONE (and only one) of the following five cognitive statuses the referents could fall into:\n",
    "statuses: [INFOCUS, ACTIVATED\", FAMILIAR, DEFINITE, INDEFINITE]\n",
    "\n",
    "As shown in the table below, the Givenness Hierarchy is comprised of six hierarchically nested tiers of cognitive status, \n",
    "where information with one cognitive status can be inferred to also have all\n",
    "lower statuses. Each level of the GH is “cued” by a set\n",
    "of linguistic forms, as seen in the table. For example, the second\n",
    "row of the table shows that the definite use of “this” can be\n",
    "used to infer that the speaker assumes the referent to be at\n",
    "least activated to their interlocutor.\n",
    "\\n\\n\n",
    "Cognitive Status | Mnemonic Status | Form |\n",
    "-----------------|-----------------|------|\n",
    "INFOCUS | in the focus of attention | it |\n",
    "ACTIVATED | in short term memory | this,that,this N |\n",
    "FAMILIAR | in long term memory| that N |\n",
    "DEFINITE | in long term memory  or new | the N |\n",
    "INDEFINITE | new or hypothetical | a N |\n",
    "\\n\\n\n",
    "\n",
    "When deciding the one cognitive status for each referent, use the table above and compare the form (pronoun, determiner, article) of the utterance to its status.\n",
    "\n",
    "Return this as a python dictionary using the following format for the dictionary entry. Note it MUST be a python dictionary\n",
    "<VARIABLE NAME> : <COGNITIVE STATUS>\n",
    "\n",
    "where the variable names correspond to the variable names associated with each of the referents. Remember, the variable names have to be correct.\n",
    "\n",
    "\n",
    "utterance: \\n{utterance}\\n\n",
    "referents: \\n{referent_info}\\n\n",
    "cognitive statuses:\n",
    "\"\"\"\n",
    "\n",
    "prompt_cognitive_status = PromptTemplate(\n",
    "    input_variables=[\"referent_info\", \"utterance\"],\n",
    "    template=template_cognitive_status\n",
    ")\n",
    "\n",
    "chain_cognitive_status = LLMChain(llm=llm, prompt=prompt_cognitive_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe7615a",
   "metadata": {},
   "source": [
    "# Overall Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f185e3f",
   "metadata": {},
   "source": [
    "### Extract referents and intentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "719ac1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import string\n",
    "\n",
    "SIMILARITY_THRESHOLD = 0.8\n",
    "\n",
    "def extract_referents_intention(utterance):\n",
    "    \n",
    "    # Initialize the important datastructures\n",
    "    referents = []\n",
    "    intention = {}\n",
    "    descriptors = []\n",
    "    \n",
    "    # 1. Speech Act classification\n",
    "    print(f\"\\nProcessing utterance: {utterance}\")\n",
    "    print(\"[ ] Classifying speech act\", end=\"\\r\")\n",
    "    speech_act = chain_speech_act.run(utterance=utterance).lower() #string name \"want\" or \"wantBel\"\n",
    "    print(\"[X] Classifying speech act\")\n",
    "\n",
    "    intention['speech_act'] = speech_act\n",
    "    \n",
    "    \n",
    "    # 2. Central Referent Extraction\n",
    "    print(\"[ ] Extracting referents\", end=\"\\r\")\n",
    "    centralref = chain_centralref.run(utterance=utterance).lower()\n",
    "    centralref_type = chain_typeof.run(ref=centralref, types=types, utterance=utterance ).split(\" \")[-1]\n",
    "    centralref_type = centralref_type.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    referents.append({\"text\": centralref, \n",
    "                      \"type\":centralref_type, \n",
    "                      \"role\": \"central\"})\n",
    "    \n",
    "    \n",
    "    # 3. Supporting Referents Extraction\n",
    "    supprefs = chain_suppref.run(utterance=utterance, centralref=centralref).lower()\n",
    "    supprefs = ast.literal_eval(supprefs)\n",
    "    \n",
    "    #supprefs_full = [] #with type info\n",
    "    if supprefs:\n",
    "        for suppref in supprefs:\n",
    "            suppref_type = chain_typeof.run(ref=suppref, types=types, utterance=utterance ).split(\" \")[-1]\n",
    "            #supprefs_full.append(f\"{suppref}:{suppref_type}\")\n",
    "            \n",
    "            referents.append({\"text\": suppref, \n",
    "                              \"type\": suppref_type, \n",
    "                              \"role\": \"supplemental\"})\n",
    "            \n",
    "            \n",
    "    print(\"[X] Extracting referents\")\n",
    "    print(f\"Referents: {json.dumps(referents, indent=2)}\")\n",
    "\n",
    "    # 4. CPC extraction \n",
    "    \n",
    "    print(\"[ ] Extracting CPC\", end=\"\\r\")\n",
    "    cpc = chain_cpc.run(utterance=utterance, speechact=speech_act, centralref=centralref)\n",
    "    \n",
    "    intention['proposition'] = {\"text\": cpc.split(\":\")[0], \n",
    "                               \"type\": cpc.split(\":\")[-1]}\n",
    "    \n",
    "    \n",
    "    print(\"[X] Extracting CPC\")\n",
    "    print(f\"Intention: {json.dumps(intention, indent=2)}\")\n",
    "    \n",
    "    # Groundable meaning representation\n",
    "    gmr = {'referents': referents, \n",
    "           'intention': intention,\n",
    "           'descriptors': descriptors}\n",
    "    return gmr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d2cedd",
   "metadata": {},
   "source": [
    "### For requests: bind action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19b93d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bind_action(utterance, gmr, robot_model):\n",
    "    \"\"\"\n",
    "    1. Find candidate actions in robot's model repertoire\n",
    "    2. Select most similar one (based on name and description)\n",
    "    3. Bind the referents to this selected one \n",
    "    4. Update referents list \n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Find Candidates in the robot's action repertoire\n",
    "    print(\"[ ]Finding Candidate actions\", end=\"\\r\")\n",
    "    candidates = chain_candidate_realactions.run(utterance=utterance, \n",
    "                                                   centralref=central_referent(gmr),\n",
    "                                                   cpc=gmr['intention']['proposition']['text'],\n",
    "                                                   actions=robot_model['actions']) \n",
    "    candidates = ast.literal_eval(candidates)\n",
    "    print(\"[X] Finding Candidate actions\")\n",
    "    print(f\"\\tCandidate actions: {candidates}\")\n",
    "    \n",
    "    \n",
    "    # 2. Select best candidate\n",
    "    print(\"[ ] Selecting best candidate\", end=\"\\r\")\n",
    "    names, scores = clean_candidates(candidates)\n",
    "    best_candidate_name = select_best_candidate(names=names, scores=scores, threshold=SIMILARITY_THRESHOLD)\n",
    "    print(\"[X] Selecting best candidate\")\n",
    "    print(f\"\\tBest candidate action name: {best_candidate_name}\")\n",
    "    \n",
    "    # 3. Bind the referents to the selected best candidate\n",
    "    print(\"[ ] Binding best candidate\", end=\"\\r\")\n",
    "    bound_candidate=None\n",
    "    if not \"NONE\" in best_candidate_name:\n",
    "        # Bind best candidate to a real action   \n",
    "        print(f\"Central ref: {central_referent(gmr)}\")\n",
    "        bound_candidate = chain_bound_action.run(utterance=utterance,\n",
    "                                              centralref=central_referent(gmr),\n",
    "                                              supprefs=supp_referents(gmr),\n",
    "                                              candidate_full_info=find_dict_in_list(robot_model['actions'], \n",
    "                                                                                     \"name\", \n",
    "                                                                                     best_candidate_name))\n",
    "        # check if bound_candidate contains a \"NONE\"\n",
    "        if \"NONE\" in bound_candidate:\n",
    "            print(f\"We have a problem. There is a unbound variable here:\\n{bound_candidate}\")\n",
    "\n",
    "        # eval string\n",
    "        bound_candidate = ast.literal_eval(bound_candidate)\n",
    "        \n",
    "        print(\"[X] Binding best candidate\")\n",
    "        print(f\"\\tBound candidate: {bound_candidate}\")\n",
    "        \n",
    "        \n",
    "        # 4. Update referents and intention object \n",
    "        for referent in gmr['referents']:\n",
    "            for binding in bound_candidate['bindings']:           \n",
    "                if list(binding.values())[0] == referent['text']:\n",
    "                    referent['variable_name'] = list(binding.keys())[0]\n",
    "\n",
    "        # 4b. Update intentions object            \n",
    "        arguments = []    \n",
    "        for binding in bound_candidate['bindings']:  \n",
    "            if list(binding.values())[0] == \"self\":\n",
    "                arguments.append(\"self\") \n",
    "            else:\n",
    "                arguments.append(list(binding.keys())[0])        \n",
    "\n",
    "        gmr['intention']['proposition']['arguments'] = arguments\n",
    "        gmr['intention']['proposition']['name'] = bound_candidate['name']\n",
    "        \n",
    "    \n",
    "    return gmr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd37e052",
   "metadata": {},
   "source": [
    "### For statements/assertions: bind concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d31fde9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bind_concept(utterance, gmr, robot_model):\n",
    "    \"\"\"\n",
    "    1. Find candidate concepts in robot's model repertoire together with similarity scores\n",
    "    2. Choose the best found one \n",
    "    3. if the best one is below the similarity threshold, then create a novel concept\n",
    "    4. Bind the referents to either found concept or novel concept candidate\n",
    "    5. Update referent list and intention\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Find candidates in the robot's conceptual and perceptual repertoire \n",
    "    ## (look up consultant properties and belief rules, unless Belief is also a consultant)\n",
    "    print(\"[ ] Finding Candidate concepts\", end=\"\\r\")\n",
    "    candidates = chain_candidate_realconcepts.run(utterance=utterance, \n",
    "                                                   centralref=central_referent(gmr),\n",
    "                                                   cpc=gmr['intention']['proposition']['text'],\n",
    "                                                   concepts=robot_model['concepts']) \n",
    "    candidates = ast.literal_eval(candidates)\n",
    "    print(\"[X] Finding Candidate concepts\")\n",
    "    print(f\"\\tCandidates: {candidates}\")\n",
    "    \n",
    "    \n",
    "    # 2. Select best candidate above a threshold\n",
    "    print(f\"[ ] Selecting best candidate above similarity of {SIMILARITY_THRESHOLD}\", end=\"\\r\")\n",
    "    names, scores = clean_candidates(candidates)\n",
    "    best_candidate_name = select_best_candidate(names=names, scores=scores, threshold=SIMILARITY_THRESHOLD)\n",
    "    print(f\"[X] Selecting best candidate above similarity of {SIMILARITY_THRESHOLD}\")\n",
    "    print(f\"\\tBest candidate concept name: {best_candidate_name}\")\n",
    "    \n",
    "\n",
    "    bound_candidate = None\n",
    "    if not \"none\" in best_candidate_name.lower(): #Case where a property detector exists in the consultants\n",
    "        # Bind best candidate to a real concept\n",
    "        print(\"[ ] Binding best candidate concept\", end=\"\\r\")\n",
    "        bound_candidate = chain_bound_concept.run(utterance=utterance,\n",
    "                                              centralref=central_referent(gmr),\n",
    "                                              supprefs=supp_referents(gmr),\n",
    "                                              candidate_full_info=find_dict_in_list(robot_model['concepts'], \n",
    "                                                                                     \"name\", \n",
    "                                                                                     best_candidate_name))\n",
    "        \n",
    "        # check if bound_candidate contains a \"NONE\"\n",
    "        if \"NONE\" in bound_candidate:\n",
    "            print(f\"We have a problem. There is a unbound variable here:\\n{bound_candidate}\")\n",
    "\n",
    "        # eval string\n",
    "        bound_candidate = ast.literal_eval(bound_candidate)\n",
    "        print(\"[X] Binding best candidate\")\n",
    "        print(f\"\\tBound candidate: {bound_candidate}\")\n",
    "        \n",
    "    else: # Case of novel concept\n",
    "        \n",
    "        # need to hypothesize a name and arguments. \n",
    "        print(\"[ ] Instantiating novel concept\", end=\"\\r\")\n",
    "        new_concept = chain_novel_concept.run(utterance=utterance,\n",
    "                                             types=robot_model['types'],\n",
    "                                             centralref=central_referent(gmr),\n",
    "                                             supprefs=supp_referents(gmr),\n",
    "                                             cpc=gmr['intention']['proposition']['text'])\n",
    "\n",
    "        new_concept = ast.literal_eval(new_concept)\n",
    "        print(\"[X] Instantiating novel concept\")\n",
    "\n",
    "        print(\"[ ] Binding novel concept\", end=\"\\r\")\n",
    "        bound_candidate = chain_bound_concept.run(utterance=utterance,\n",
    "                                              centralref=central_referent(gmr),\n",
    "                                              supprefs=supp_referents(gmr),\n",
    "                                              candidate_full_info=find_dict_in_list([new_concept], \n",
    "                                                                                     \"name\", \n",
    "                                                                                     new_concept['name']))\n",
    "\n",
    "        print(\"[X] Binding novel concept\")\n",
    "\n",
    "        # check if bound_candidate contains a \"NONE\"\n",
    "        if \"NONE\" in bound_candidate:\n",
    "            print(f\"We have a problem. There is a unbound variable here:\\n{bound_candidate}\")\n",
    "\n",
    "        bound_candidate = ast.literal_eval(bound_candidate)\n",
    "    \n",
    "    if not bound_candidate:\n",
    "        print(\"\\nERROR!!!\\n\")\n",
    "        return gmr\n",
    "    \n",
    "    # 4. Update referents and intention object \n",
    "    for referent in gmr['referents']:\n",
    "        for binding in bound_candidate['bindings']:           \n",
    "            if list(binding.values())[0] == referent['text']:\n",
    "                referent['variable_name'] = list(binding.keys())[0]\n",
    "    \n",
    "    # 4b. Update intentions object            \n",
    "    arguments = []    \n",
    "    for binding in bound_candidate['bindings']:  \n",
    "        if list(binding.values())[0] == \"self\":\n",
    "            arguments.append(\"self\") \n",
    "        else:\n",
    "            arguments.append(list(binding.keys())[0])        \n",
    "    \n",
    "    gmr['intention']['proposition']['arguments'] = arguments\n",
    "    gmr['intention']['proposition']['name'] = bound_candidate['name']\n",
    "    \n",
    "    return gmr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596ef28c",
   "metadata": {},
   "source": [
    "### Extract descriptors and referential properties and relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9cc2278a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_supplementals(utterance, gmr, robot_model):\n",
    "\n",
    "    # 1. Getting candidate properties from language\n",
    "    print(\"[ ] Extracting Properties\", end=\"\\r\")\n",
    "    spc = chain_properties.run(utterance=utterance,\n",
    "                                     referent_info=gmr['referents'],\n",
    "                              cpc=gmr['intention']['proposition'])\n",
    "    descriptors = ast.literal_eval(spc)\n",
    "    print(\"[X] Extracting Properties\")\n",
    "    print(f\"\\tDescriptors: {descriptors}\")\n",
    "    \n",
    "    # 2. Finding consultant properties that match the identified spc \n",
    "    print(\"[ ] Finding Consultant properties similar to each of the Descriptors\", end=\"\\r\")\n",
    "    props_all = []\n",
    "    for descriptor in descriptors:\n",
    "    \n",
    "        ## 2.a. Get some candidate matches from the robot's perceptual/conceptual repertoire (Concepts)\n",
    "        candidates = chain_candidate_realprops.run(utterance=utterance,\n",
    "                                                                   concepts=robot_model['concepts'],\n",
    "                                                                   prop=descriptor )\n",
    "        candidates = ast.literal_eval(candidates)\n",
    "        print(f\"Debug: candidates: {candidates}\")\n",
    "        # 2.b. Pick the best one that is also above a threshold\n",
    "        names, scores = clean_candidates(candidates)\n",
    "        best_candidate_name = select_best_candidate(names=names, scores=scores, threshold=SIMILARITY_THRESHOLD)\n",
    "\n",
    "            \n",
    "        descriptor['name'] = best_candidate_name\n",
    "        \n",
    "    print(\"[X] Finding Consultants properties similar to SPC\")    \n",
    "    \n",
    "    gmr['descriptors'] = descriptors\n",
    "    \n",
    "    return gmr\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de61aa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_cognitive_status(utterance, gmr, robot_model):\n",
    "    print(\"[ ] Classifying cognitive status\", end=\"\\r\")\n",
    "    cognitive_statuses = chain_cognitive_status.run(utterance=utterance,\n",
    "                                                   referent_info=gmr['referents'])\n",
    "    \n",
    "    cognitive_statuses = ast.literal_eval(cognitive_statuses)\n",
    "    print(\"[X] Classifying cognitive status\")\n",
    "    print(f\"\\tCognitive Status: {cognitive_statuses}\")\n",
    "    \n",
    "    \n",
    "    for ref in gmr['referents']:\n",
    "        if \"variable_name\" in ref:\n",
    "            varname = ref['variable_name']\n",
    "            status = cognitive_statuses[varname]\n",
    "            ref['cognitive_status'] = status\n",
    "    \n",
    "    return gmr\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c22a37b",
   "metadata": {},
   "source": [
    "### Generate the actual parse from the GMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47abc5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_parse(gmr, speaker):\n",
    "    \n",
    "    # Build the CPC\n",
    "    if 'name' in gmr['intention']['proposition']:\n",
    "        cpc_template = \"{cpc_name}({cpc_variables})\"\n",
    "        cpc = cpc_template.format(cpc_name=gmr['intention']['proposition']['name'],\n",
    "                                 cpc_variables=\",\".join(gmr['intention']['proposition']['arguments']))\n",
    "    else:\n",
    "        cpc = \"NONE\"\n",
    "    \n",
    "                              \n",
    "    # Build the SPC\n",
    "    spcs = []\n",
    "    spc_template = \"{spc_name}({spc_variables})\"\n",
    "    for descriptor in gmr['descriptors']:\n",
    "        spc_predicate = spc_template.format(spc_name=descriptor['name'],\n",
    "                                     spc_variables=\",\".join(descriptor['arguments']))\n",
    "        spcs.append(spc_predicate)\n",
    "    \n",
    "    for ref in gmr['referents']:\n",
    "        if 'variable_name' in ref and 'cognitive_status' in ref:\n",
    "            spc_predicate = spc_template.format(spc_name=ref['cognitive_status'],\n",
    "                                         spc_variables=ref['variable_name'])\n",
    "            spcs.append(spc_predicate)\n",
    "                      \n",
    "    spc_all = \",\".join(spcs)                        \n",
    "                              \n",
    "    \n",
    "    final_template = \"{speech_act}({speaker},{cpc},{{{spcs}}})\"\n",
    "    parsed = final_template.format(speech_act=gmr['intention']['speech_act'],\n",
    "                                  speaker=speaker,\n",
    "                                  cpc=cpc,\n",
    "                                  spcs=spc_all)\n",
    "    \n",
    "    return parsed\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d713892b",
   "metadata": {},
   "source": [
    "### Overall Parsing Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6956592a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall Algorithm\n",
    "def parse(utterance, robot_model):\n",
    "    \n",
    "    gmr = extract_referents_intention(utterance)\n",
    "    if gmr['intention']['proposition']['type'] == \"action\":\n",
    "        gmr = bind_action(utterance, gmr, robot_model)\n",
    "    elif gmr['intention']['proposition']['type'] == \"concept\":\n",
    "        gmr = bind_concept(utterance, gmr, robot_model)\n",
    "    gmr = extract_supplementals(utterance, gmr, robot_model)\n",
    "    \n",
    "    gmr = classify_cognitive_status(utterance, gmr, robot_model)\n",
    "    \n",
    "    parsed = generate_parse(gmr, \"brad\")\n",
    "    output = {\"utterance\": utterance,\n",
    "                   \"robot_model\": robot_model,                  \n",
    "                   \"parse\": parsed,\n",
    "                   \"gmr\": gmr}\n",
    "    \n",
    "    print(f\"Utterance: {utterance}\")\n",
    "    print(f\"PARSE: {parsed}\")\n",
    "    \n",
    "    return output\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66264c3c",
   "metadata": {},
   "source": [
    "# Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "babe67c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available utterances: ['then assemble the screw feeder', 'that m3 screw belongs to Evan', 'screw the m3 into that bottle on the conveyor', 'that m3 screw can couple with the conveyor']\n"
     ]
    }
   ],
   "source": [
    "# Construct Sample dev dataset \n",
    "import json \n",
    "\n",
    "with open(\"../data/actions_short.json\", \"r\") as f:\n",
    "    actions_dev = json.load(f)\n",
    "with open(\"../data/properties.json\", \"r\") as f:\n",
    "    concepts_dev = json.load(f)\n",
    "types = [\"physobj\", \"agent\", \"location\", \"pose\", \"action\", \"number\", \"direction\", \"name\", \"string\"]\n",
    "\n",
    "utterances = [\"then assemble the screw feeder\",\n",
    "             \"that m3 screw belongs to Evan\",\n",
    "             \"screw the m3 into that bottle on the conveyor\",\n",
    "             \"that m3 screw can couple with the conveyor\"]\n",
    "\n",
    "dataset = []\n",
    "for utt in utterances:\n",
    "    item = {\"utterance\": utt,\n",
    "            \"robot_model\": {\n",
    "                \"actions\": actions_dev,\n",
    "                \"concepts\": concepts_dev,\n",
    "                \"types\": types}\n",
    "           }\n",
    "    dataset.append(item)\n",
    "\n",
    "print(f\"Available utterances: {utterances}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cdff3d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing utterance: that m3 screw belongs to Evan\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"m3 screw\",\n",
      "    \"type\": \"physobj\",\n",
      "    \"role\": \"central\"\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"evan\",\n",
      "    \"type\": \"agent.\",\n",
      "    \"role\": \"supplemental\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"wantbel\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"belonging\",\n",
      "    \"type\": \"concept\"\n",
      "  }\n",
      "}\n",
      "[X] Finding Candidate concepts\n",
      "\tCandidates: ['prop: 0.6', 'bottle: 0.5', 'nfsv: 0.4', 'nvfau: 0.4', 'conveyor: 0.5']\n",
      "[X] Selecting best candidate above similarity of 0.8\n",
      "\tBest candidate concept name: NONE\n",
      "[X] Instantiating novel concept\n",
      "[X] Binding novel concept\n",
      "[X] Extracting Properties\n",
      "\tDescriptors: [{'text': 'm3 screw', 'arguments': ['VAR0']}, {'text': 'evan', 'arguments': ['VAR1']}]\n",
      "Debug: candidates: ['m3: 1', 'deepM3: 0.8', 'screw feeder: 0.6', 'prop: 0.4', 'bottle: 0.2']\n",
      "Debug: candidates: ['m3: 0.8', 'deepM3: 0.7', 'prop: 0.6', 'bottle: 0.5', 'nfsv: 0.4']\n",
      "[X] Finding Consultants properties similar to SPC\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'VAR0': 'FAMILIAR', 'VAR1': 'DEFINITE'}\n",
      "Utterance: that m3 screw belongs to Evan\n",
      "PARSE: wantbel(brad,belonging(VAR0,VAR1),{m3(VAR0),NONE(VAR1),FAMILIAR(VAR0),DEFINITE(VAR1)})\n"
     ]
    }
   ],
   "source": [
    "idx = 1\n",
    "output = parse(utterance=dataset[idx]['utterance'],robot_model=dataset[idx]['robot_model'])\n",
    "#print(json.dumps(out, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e8cd1699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'referents': [{'text': 'm3 screw',\n",
       "   'type': 'physobj',\n",
       "   'role': 'central',\n",
       "   'variable_name': 'VAR0',\n",
       "   'cognitive_status': 'FAMILIAR'},\n",
       "  {'text': 'evan',\n",
       "   'type': 'agent.',\n",
       "   'role': 'supplemental',\n",
       "   'variable_name': 'VAR1',\n",
       "   'cognitive_status': 'DEFINITE'}],\n",
       " 'intention': {'speech_act': 'wantbel',\n",
       "  'proposition': {'text': 'belonging',\n",
       "   'type': 'concept',\n",
       "   'arguments': ['VAR0', 'VAR1'],\n",
       "   'name': 'belonging'}},\n",
       " 'descriptors': [{'text': 'm3 screw', 'arguments': ['VAR0'], 'name': 'm3'},\n",
       "  {'text': 'evan', 'arguments': ['VAR1'], 'name': 'NONE'}]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['gmr']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007ecbd3",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485dae40",
   "metadata": {},
   "source": [
    "### Evaluation Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc60514d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data processing classes and functions\n",
    "import json\n",
    "\n",
    "def process_data_item(json_item):\n",
    "    actions = json_item['promptInfo']['actions']\n",
    "    concepts = json_item['promptInfo']['properties']\n",
    "    return actions, concepts\n",
    "\n",
    "class DIARCDataset:\n",
    "    def __init__(self, annotations_file, types=None):\n",
    "        with open(annotations_file, \"r\") as f:\n",
    "            self.data = json.load(f)\n",
    "        if not self.data:\n",
    "            print(\"Dataset did not load because .json file could not be opened\")\n",
    "            return\n",
    "        \n",
    "        # initialize dataset \n",
    "        self.types = types\n",
    "        if not self.types:\n",
    "            # default types\n",
    "            self.types = [\"physobj\", \"agent\", \"location\", \"pose\", \"action\", \"number\", \"direction\", \"name\", \"string\"]\n",
    "        self.initialize()\n",
    "    \n",
    "    def initialize(self):\n",
    "        \"\"\"\n",
    "        updates self.data into this nice list of items amenable for later processing. \n",
    "        \"\"\"\n",
    "        data = []\n",
    "        for item in self.data['utterances']:\n",
    "            actions = item['promptInfo']['actions']\n",
    "            concepts = item['promptInfo']['properties']\n",
    "            utterance = item['utteranceText']\n",
    "            desired_semantics= item['desiredSemantics']\n",
    "            \n",
    "            datum = {\"utterance\": utterance,\n",
    "                     'desired_semantics': desired_semantics,\n",
    "                     \"robot_model\": {\n",
    "                         \"actions\": actions,\n",
    "                         \"concepts\": concepts,\n",
    "                         \"types\": self.types}\n",
    "                    }\n",
    "            \n",
    "            data.append(datum)\n",
    "        self.data = data\n",
    "        \n",
    "    \n",
    "    def stats(self):\n",
    "        num_items = len(self.data)\n",
    "        print(f\"Number of utterances: {num_items}\")\n",
    "            \n",
    "    def xy(self):\n",
    "        \"\"\"\n",
    "        returns all the utterances and desired semantics\n",
    "        \"\"\"\n",
    "        utterances = []\n",
    "        desired_semantics = []\n",
    "        for item in self.data:\n",
    "            utt = item['utterance']\n",
    "            des = item['desired_semantics']\n",
    "            utterances.append(utt)\n",
    "            desired_semantics.append(des)\n",
    "        return utterances, desired_semantics\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc50781f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'utterance': 'define new screw type m3',\n",
       " 'desired_semantics': 'INSTRUCT(brad,self:agent,want(brad,defineScrewType(self:agent,m3)),{})',\n",
       " 'robot_model': {'actions': [{'name': 'gotoCamerapose',\n",
       "    'roles': ['?actor', '?pose'],\n",
       "    'description': 'goes to pose at camera height'},\n",
       "   {'name': 'getGripper',\n",
       "    'roles': ['?actor', '?gripperType'],\n",
       "    'description': ''},\n",
       "   {'name': 'goToPose',\n",
       "    'roles': ['?actor', '?pose'],\n",
       "    'description': 'goes to pose without adjustment'},\n",
       "   {'name': 'mountScrew',\n",
       "    'roles': ['?actor', '?screwType'],\n",
       "    'description': 'goes to the source of the given screw type and mounts one to the screwdriver'},\n",
       "   {'name': 'defineScrewType',\n",
       "    'roles': ['?actor', '?screwType'],\n",
       "    'description': 'defines new type of screw for screw, and asks for relevant parameters'},\n",
       "   {'name': 'assemble',\n",
       "    'roles': ['?actor', '?modelID'],\n",
       "    'description': 'assembles model for ?modelID from belief'},\n",
       "   {'name': 'defineItem',\n",
       "    'roles': ['?actor', '?item'],\n",
       "    'description': 'defines new item, and asks for relevant parameters'},\n",
       "   {'name': 'getCurrGoals',\n",
       "    'roles': ['?actor'],\n",
       "    'description': 'get list of current goals and assert it to belief'},\n",
       "   {'name': 'getTime',\n",
       "    'roles': ['?actor'],\n",
       "    'description': 'get the system time and assert it to belief'},\n",
       "   {'name': 'getRefForJob',\n",
       "    'roles': ['?actor', '?descriptor'],\n",
       "    'description': 'runs a job for the given ?descriptor and saves and returns the first result'},\n",
       "   {'name': 'goToPoseLong',\n",
       "    'roles': ['?actor', '?pose', '?cameraHeight'],\n",
       "    'description': 'goes to pose with adjustment to the given cameraHeight the long way around'},\n",
       "   {'name': 'recordCameraPoseAsk',\n",
       "    'roles': ['?actor', '?poseName'],\n",
       "    'description': 'records current pose and asks for an off set'},\n",
       "   {'name': 'putDown',\n",
       "    'roles': ['?actor'],\n",
       "    'description': 'drops an object held by the robot grippers'},\n",
       "   {'name': 'runScrewdriverJob',\n",
       "    'roles': ['?actor', '?screwType'],\n",
       "    'description': 'screws in a screw once aligned'},\n",
       "   {'name': 'rotateToEE',\n",
       "    'roles': ['?actor', '?gripperType'],\n",
       "    'description': 'changes TCP of robot to refer to a new EE attached to the cuff at a different offset'},\n",
       "   {'name': 'moveConveyorBackward',\n",
       "    'roles': ['?actor'],\n",
       "    'description': 'Moves the conveyor belt backward'},\n",
       "   {'name': 'grab',\n",
       "    'roles': ['?actor', '?physobj', '?pose'],\n",
       "    'description': '?actor grabs ?physobj'},\n",
       "   {'name': 'moveToObjectHeight',\n",
       "    'roles': ['?actor'],\n",
       "    'description': 'moves down by a camera z height as defined by an inline constant'},\n",
       "   {'name': 'goToPoseLong',\n",
       "    'roles': ['?actor', '?pose'],\n",
       "    'description': 'goes to pose without adjustment the long way around'},\n",
       "   {'name': 'alignWith',\n",
       "    'roles': ['?actor', '?holeRef'],\n",
       "    'description': 'aligns above a screw hole by reference id'},\n",
       "   {'name': 'handleGreeting',\n",
       "    'roles': ['?actor',\n",
       "     '?speaker',\n",
       "     '?addressee',\n",
       "     '?greeting',\n",
       "     '?semanticType'],\n",
       "    'description': 'Handle greeting semantics'},\n",
       "   {'name': 'assembleVision',\n",
       "    'roles': ['?actor'],\n",
       "    'description': 'classifies model in front of itself and calls relevant assemble script'},\n",
       "   {'name': 'perceiveEntityFromSymbol',\n",
       "    'roles': ['?actor', '?refId'],\n",
       "    'description': 'runs a job for a given pre-existing ?refId and binds the relevant result to that reference'},\n",
       "   {'name': 'endLearningAssembleScript',\n",
       "    'roles': ['?actor', '?modelName'],\n",
       "    'description': 'ends learning of assemble?modelName()'},\n",
       "   {'name': 'startLearningAssembleScript',\n",
       "    'roles': ['?actor', '?modelName'],\n",
       "    'description': 'assembles model for ?modelID from belief'},\n",
       "   {'name': 'gotocamerapose',\n",
       "    'roles': ['?actor', '?pose1', '?pose2'],\n",
       "    'description': 'moves to ?pose1, from ?pose2'},\n",
       "   {'name': 'putdown',\n",
       "    'roles': ['?actor', '?physobj', '?pose'],\n",
       "    'description': '?actor releases ?physobj'},\n",
       "   {'name': 'perceiveEntity',\n",
       "    'roles': ['?actor', '?refId'],\n",
       "    'description': 'Looks for an entity at the current location'},\n",
       "   {'name': 'getOn',\n",
       "    'roles': ['?actor', '?object', '?destination'],\n",
       "    'description': 'gets ?object on to the surface beneath ?destination'},\n",
       "   {'name': 'moveToCameraHeight',\n",
       "    'roles': ['?actor'],\n",
       "    'description': 'moves up by a camera z height as defined by an inline constant'},\n",
       "   {'name': 'setupPoses', 'roles': ['?actor'], 'description': ''},\n",
       "   {'name': 'handleAck',\n",
       "    'roles': ['?actor', '?speaker', '?addressee', '?semanticType'],\n",
       "    'description': 'Handle ack semantics'},\n",
       "   {'name': 'mountSingleScrew',\n",
       "    'roles': ['?actor'],\n",
       "    'description': 'finds and mounts a single screw to the kolver screwdriver'},\n",
       "   {'name': 'goToPose',\n",
       "    'roles': ['?actor', '?pose', '?cameraHeight'],\n",
       "    'description': 'goes to pose with adjustment to the given cameraHeight'},\n",
       "   {'name': 'putAwayGripper',\n",
       "    'roles': ['?actor', '?gripperType'],\n",
       "    'description': ''},\n",
       "   {'name': 'pickUp',\n",
       "    'roles': ['?actor', '?objectRef'],\n",
       "    'description': 'finds and moves above a flange of the given modelType'},\n",
       "   {'name': 'translateLastGoal', 'roles': ['?actor'], 'description': ''},\n",
       "   {'name': 'moveConveyorForward',\n",
       "    'roles': ['?actor'],\n",
       "    'description': 'Moves the conveyor belt forward'},\n",
       "   {'name': 'screwScrew',\n",
       "    'roles': ['?actor', '?screwType'],\n",
       "    'description': 'screws in a single hole identified by the cognex using the kolver screwdriver'},\n",
       "   {'name': 'init',\n",
       "    'roles': ['?actor'],\n",
       "    'description': 'workaround for not being able to retract facts from belief init files'}],\n",
       "  'concepts': [{'name': 'this', 'roles': ['X:context']},\n",
       "   {'name': 'it', 'roles': ['X:context']},\n",
       "   {'name': 'that', 'roles': ['X:context']},\n",
       "   {'name': 'thing', 'roles': ['X:context']},\n",
       "   {'name': 'those', 'roles': ['X:context']},\n",
       "   {'name': 'they', 'roles': ['X:context']},\n",
       "   {'name': 'these', 'roles': ['X:context']},\n",
       "   {'name': 'doit', 'roles': ['X:dialog']},\n",
       "   {'name': 'dothis', 'roles': ['Xdialog:dialog']},\n",
       "   {'name': 'dothat', 'roles': ['Xdialog:dialog']},\n",
       "   {'name': 'that', 'roles': ['Xdialog:dialog']},\n",
       "   {'name': 'this', 'roles': ['X:physobj']},\n",
       "   {'name': 'hole', 'roles': ['X:physobj']},\n",
       "   {'name': 'm3', 'roles': ['X:physobj']},\n",
       "   {'name': 'deepM3', 'roles': ['X:physobj']},\n",
       "   {'name': 'left', 'roles': ['X:physobj']},\n",
       "   {'name': 'right', 'roles': ['X:physobj']},\n",
       "   {'name': 'top', 'roles': ['X:physobj']},\n",
       "   {'name': 'bottom', 'roles': ['X:physobj']},\n",
       "   {'name': 'prop', 'roles': ['X:physobj']},\n",
       "   {'name': 'bottle', 'roles': ['X:physobj']},\n",
       "   {'name': 'it', 'roles': ['X:physobj']},\n",
       "   {'name': 'that', 'roles': ['X:physobj']},\n",
       "   {'name': 'thing', 'roles': ['X:physobj']},\n",
       "   {'name': 'those', 'roles': ['X:physobj']},\n",
       "   {'name': 'they', 'roles': ['X:physobj']},\n",
       "   {'name': 'these', 'roles': ['X:physobj']},\n",
       "   {'name': 'this', 'roles': ['X:pose']},\n",
       "   {'name': 'conveyor', 'roles': ['X:pose']},\n",
       "   {'name': 'work area', 'roles': ['X:pose']},\n",
       "   {'name': 'screw feeder', 'roles': ['X:pose']},\n",
       "   {'name': 'it', 'roles': ['X:pose']},\n",
       "   {'name': 'that', 'roles': ['X:pose']},\n",
       "   {'name': 'thing', 'roles': ['X:pose']},\n",
       "   {'name': 'those', 'roles': ['X:pose']},\n",
       "   {'name': 'they', 'roles': ['X:pose']},\n",
       "   {'name': 'these', 'roles': ['X:pose']}],\n",
       "  'types': ['physobj',\n",
       "   'agent',\n",
       "   'location',\n",
       "   'pose',\n",
       "   'action',\n",
       "   'number',\n",
       "   'direction',\n",
       "   'name',\n",
       "   'string']}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = DIARCDataset(annotations_file=\"../data/tasks/dev/screwingActionModificationTestOrdered.json\")\n",
    "dataset.data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970d7bec",
   "metadata": {},
   "source": [
    "### Spot Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5ad821f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'utterance': 'replace screw an m3 screw into the right m3 hole with screw an m3 screw into the top deep m3 hole',\n",
       " 'desired_semantics': 'UNKNOWN(brad,self:agent,mod(replace(screwIn(self:agent,m3,VAR1),screwIn(self:agent,m3,VAR0))),{m3(VAR0),right(VAR0),deepM3(VAR1),top(VAR1),DEFINITE(VAR0),DEFINITE(VAR1)})',\n",
       " 'robot_model': {'actions': [{'name': 'gotoCamerapose',\n",
       "    'roles': ['?actor', '?pose'],\n",
       "    'description': 'goes to pose at camera height'},\n",
       "   {'name': 'getGripper',\n",
       "    'roles': ['?actor', '?gripperType'],\n",
       "    'description': ''},\n",
       "   {'name': 'goToPose',\n",
       "    'roles': ['?actor', '?pose'],\n",
       "    'description': 'goes to pose without adjustment'},\n",
       "   {'name': 'mountScrew',\n",
       "    'roles': ['?actor', '?screwType'],\n",
       "    'description': 'goes to the source of the given screw type and mounts one to the screwdriver'},\n",
       "   {'name': 'defineScrewType',\n",
       "    'roles': ['?actor', '?screwType'],\n",
       "    'description': 'defines new type of screw for screw, and asks for relevant parameters'},\n",
       "   {'name': 'assemble',\n",
       "    'roles': ['?actor', '?modelID'],\n",
       "    'description': 'assembles model for ?modelID from belief'},\n",
       "   {'name': 'defineItem',\n",
       "    'roles': ['?actor', '?item'],\n",
       "    'description': 'defines new item, and asks for relevant parameters'},\n",
       "   {'name': 'getCurrGoals',\n",
       "    'roles': ['?actor'],\n",
       "    'description': 'get list of current goals and assert it to belief'},\n",
       "   {'name': 'getTime',\n",
       "    'roles': ['?actor'],\n",
       "    'description': 'get the system time and assert it to belief'},\n",
       "   {'name': 'getRefForJob',\n",
       "    'roles': ['?actor', '?descriptor'],\n",
       "    'description': 'runs a job for the given ?descriptor and saves and returns the first result'},\n",
       "   {'name': 'goToPoseLong',\n",
       "    'roles': ['?actor', '?pose', '?cameraHeight'],\n",
       "    'description': 'goes to pose with adjustment to the given cameraHeight the long way around'},\n",
       "   {'name': 'recordCameraPoseAsk',\n",
       "    'roles': ['?actor', '?poseName'],\n",
       "    'description': 'records current pose and asks for an off set'},\n",
       "   {'name': 'putDown',\n",
       "    'roles': ['?actor'],\n",
       "    'description': 'drops an object held by the robot grippers'},\n",
       "   {'name': 'runScrewdriverJob',\n",
       "    'roles': ['?actor', '?screwType'],\n",
       "    'description': 'screws in a screw once aligned'},\n",
       "   {'name': 'rotateToEE',\n",
       "    'roles': ['?actor', '?gripperType'],\n",
       "    'description': 'changes TCP of robot to refer to a new EE attached to the cuff at a different offset'},\n",
       "   {'name': 'moveConveyorBackward',\n",
       "    'roles': ['?actor'],\n",
       "    'description': 'Moves the conveyor belt backward'},\n",
       "   {'name': 'grab',\n",
       "    'roles': ['?actor', '?physobj', '?pose'],\n",
       "    'description': '?actor grabs ?physobj'},\n",
       "   {'name': 'moveToObjectHeight',\n",
       "    'roles': ['?actor'],\n",
       "    'description': 'moves down by a camera z height as defined by an inline constant'},\n",
       "   {'name': 'goToPoseLong',\n",
       "    'roles': ['?actor', '?pose'],\n",
       "    'description': 'goes to pose without adjustment the long way around'},\n",
       "   {'name': 'alignWith',\n",
       "    'roles': ['?actor', '?holeRef'],\n",
       "    'description': 'aligns above a screw hole by reference id'},\n",
       "   {'name': 'handleGreeting',\n",
       "    'roles': ['?actor',\n",
       "     '?speaker',\n",
       "     '?addressee',\n",
       "     '?greeting',\n",
       "     '?semanticType'],\n",
       "    'description': 'Handle greeting semantics'},\n",
       "   {'name': 'assembleVision',\n",
       "    'roles': ['?actor'],\n",
       "    'description': 'classifies model in front of itself and calls relevant assemble script'},\n",
       "   {'name': 'perceiveEntityFromSymbol',\n",
       "    'roles': ['?actor', '?refId'],\n",
       "    'description': 'runs a job for a given pre-existing ?refId and binds the relevant result to that reference'},\n",
       "   {'name': 'endLearningAssembleScript',\n",
       "    'roles': ['?actor', '?modelName'],\n",
       "    'description': 'ends learning of assemble?modelName()'},\n",
       "   {'name': 'startLearningAssembleScript',\n",
       "    'roles': ['?actor', '?modelName'],\n",
       "    'description': 'assembles model for ?modelID from belief'},\n",
       "   {'name': 'gotocamerapose',\n",
       "    'roles': ['?actor', '?pose1', '?pose2'],\n",
       "    'description': 'moves to ?pose1, from ?pose2'},\n",
       "   {'name': 'putdown',\n",
       "    'roles': ['?actor', '?physobj', '?pose'],\n",
       "    'description': '?actor releases ?physobj'},\n",
       "   {'name': 'perceiveEntity',\n",
       "    'roles': ['?actor', '?refId'],\n",
       "    'description': 'Looks for an entity at the current location'},\n",
       "   {'name': 'getOn',\n",
       "    'roles': ['?actor', '?object', '?destination'],\n",
       "    'description': 'gets ?object on to the surface beneath ?destination'},\n",
       "   {'name': 'moveToCameraHeight',\n",
       "    'roles': ['?actor'],\n",
       "    'description': 'moves up by a camera z height as defined by an inline constant'},\n",
       "   {'name': 'setupPoses', 'roles': ['?actor'], 'description': ''},\n",
       "   {'name': 'handleAck',\n",
       "    'roles': ['?actor', '?speaker', '?addressee', '?semanticType'],\n",
       "    'description': 'Handle ack semantics'},\n",
       "   {'name': 'mountSingleScrew',\n",
       "    'roles': ['?actor'],\n",
       "    'description': 'finds and mounts a single screw to the kolver screwdriver'},\n",
       "   {'name': 'goToPose',\n",
       "    'roles': ['?actor', '?pose', '?cameraHeight'],\n",
       "    'description': 'goes to pose with adjustment to the given cameraHeight'},\n",
       "   {'name': 'putAwayGripper',\n",
       "    'roles': ['?actor', '?gripperType'],\n",
       "    'description': ''},\n",
       "   {'name': 'screwIn',\n",
       "    'roles': ['?actor', '?var_1', '?var_0'],\n",
       "    'description': ''},\n",
       "   {'name': 'pickUp',\n",
       "    'roles': ['?actor', '?objectRef'],\n",
       "    'description': 'finds and moves above a flange of the given modelType'},\n",
       "   {'name': 'translateLastGoal', 'roles': ['?actor'], 'description': ''},\n",
       "   {'name': 'moveConveyorForward',\n",
       "    'roles': ['?actor'],\n",
       "    'description': 'Moves the conveyor belt forward'},\n",
       "   {'name': 'screwScrew',\n",
       "    'roles': ['?actor', '?screwType'],\n",
       "    'description': 'screws in a single hole identified by the cognex using the kolver screwdriver'},\n",
       "   {'name': 'init',\n",
       "    'roles': ['?actor'],\n",
       "    'description': 'workaround for not being able to retract facts from belief init files'}],\n",
       "  'concepts': [{'name': 'this', 'roles': ['X:context']},\n",
       "   {'name': 'it', 'roles': ['X:context']},\n",
       "   {'name': 'that', 'roles': ['X:context']},\n",
       "   {'name': 'thing', 'roles': ['X:context']},\n",
       "   {'name': 'those', 'roles': ['X:context']},\n",
       "   {'name': 'they', 'roles': ['X:context']},\n",
       "   {'name': 'these', 'roles': ['X:context']},\n",
       "   {'name': 'doit', 'roles': ['X:dialog']},\n",
       "   {'name': 'dothis', 'roles': ['Xdialog:dialog']},\n",
       "   {'name': 'dothat', 'roles': ['Xdialog:dialog']},\n",
       "   {'name': 'that', 'roles': ['Xdialog:dialog']},\n",
       "   {'name': 'this', 'roles': ['X:physobj']},\n",
       "   {'name': 'hole', 'roles': ['X:physobj']},\n",
       "   {'name': 'm3', 'roles': ['X:physobj']},\n",
       "   {'name': 'deepM3', 'roles': ['X:physobj']},\n",
       "   {'name': 'left', 'roles': ['X:physobj']},\n",
       "   {'name': 'right', 'roles': ['X:physobj']},\n",
       "   {'name': 'top', 'roles': ['X:physobj']},\n",
       "   {'name': 'bottom', 'roles': ['X:physobj']},\n",
       "   {'name': 'prop', 'roles': ['X:physobj']},\n",
       "   {'name': 'bottle', 'roles': ['X:physobj']},\n",
       "   {'name': 'nfsv', 'roles': ['X:physobj']},\n",
       "   {'name': 'it', 'roles': ['X:physobj']},\n",
       "   {'name': 'that', 'roles': ['X:physobj']},\n",
       "   {'name': 'thing', 'roles': ['X:physobj']},\n",
       "   {'name': 'those', 'roles': ['X:physobj']},\n",
       "   {'name': 'they', 'roles': ['X:physobj']},\n",
       "   {'name': 'these', 'roles': ['X:physobj']},\n",
       "   {'name': 'this', 'roles': ['X:pose']},\n",
       "   {'name': 'conveyor', 'roles': ['X:pose']},\n",
       "   {'name': 'work area', 'roles': ['X:pose']},\n",
       "   {'name': 'screw feeder', 'roles': ['X:pose']},\n",
       "   {'name': 'it', 'roles': ['X:pose']},\n",
       "   {'name': 'that', 'roles': ['X:pose']},\n",
       "   {'name': 'thing', 'roles': ['X:pose']},\n",
       "   {'name': 'those', 'roles': ['X:pose']},\n",
       "   {'name': 'they', 'roles': ['X:pose']},\n",
       "   {'name': 'these', 'roles': ['X:pose']}],\n",
       "  'types': ['physobj',\n",
       "   'agent',\n",
       "   'location',\n",
       "   'pose',\n",
       "   'action',\n",
       "   'number',\n",
       "   'direction',\n",
       "   'name',\n",
       "   'string']}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 31\n",
    "dataset.data[31]\n",
    "#output = parse(utterance=dataset.data[idx]['utterance'],robot_model=dataset.data[idx]['robot_model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01f7d6f",
   "metadata": {},
   "source": [
    "### Run Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a1939233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== ITEM 0 ============\n",
      "Utterance: setup poses\n",
      "DesiredSemantics: INSTRUCT(brad,self:agent,want(brad,setupPoses(self:agent)),{})\n",
      "\n",
      "Processing utterance: setup poses\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"poses\",\n",
      "    \"type\": \"pose\",\n",
      "    \"role\": \"central\"\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"setup\",\n",
      "    \"type\": \"action\",\n",
      "    \"role\": \"supplemental\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"\\\"want\\\"\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"\\\"setup\",\n",
      "    \"type\": \"action\\\"\"\n",
      "  }\n",
      "}\n",
      "[X] Extracting Properties\n",
      "\tDescriptors: [{'text': 'poses', 'arguments': ['poses']}, {'text': 'setup', 'arguments': ['setup']}]\n",
      "Debug: candidates: ['this:0.2', 'it:0.2', 'that:0.2', 'thing:0.2', 'these:0.2']\n",
      "Debug: candidates: ['this:0.1', 'it:0.1', 'that:0.1', 'thing:0.1', 'those:0.1']\n",
      "[X] Finding Consultants properties similar to SPC\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'poses': 'INDEFINITE', 'setup': 'INDEFINITE'}\n",
      "Utterance: setup poses\n",
      "PARSE: \"want\"(brad,NONE,{NONE(poses),NONE(setup)})\n",
      "==================================\n",
      "\n",
      "======== ITEM 1 ============\n",
      "Utterance: define new screw type m3\n",
      "DesiredSemantics: INSTRUCT(brad,self:agent,want(brad,defineScrewType(self:agent,m3)),{})\n",
      "\n",
      "Processing utterance: define new screw type m3\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"new screw type m3\",\n",
      "    \"type\": \"physobj\",\n",
      "    \"role\": \"central\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"\\\"want\\\"\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"define\",\n",
      "    \"type\": \"action\"\n",
      "  }\n",
      "}\n",
      "[X] Finding Candidate actions\n",
      "\tCandidate actions: ['defineScrewType:0.9', 'defineItem:0.7', 'assemble:0.5', 'assembleVision:0.5', 'startLearningAssembleScript:0.5']\n",
      "[X] Selecting best candidate\n",
      "\tBest candidate action name: defineScrewType\n",
      "Central ref: {'text': 'new screw type m3', 'type': 'physobj', 'role': 'central'}\n",
      "[X] Binding best candidate\n",
      "\tBound candidate: {'name': 'defineScrewType', 'bindings': [{'VAR0': 'self'}, {'VAR1': 'new screw type m3'}]}\n",
      "[X] Extracting Properties\n",
      "\tDescriptors: [{'text': 'new', 'arguments': ['VAR1']}, {'text': 'screw type', 'arguments': ['VAR1']}, {'text': 'm3', 'arguments': ['VAR1']}]\n",
      "Debug: candidates: ['this:0.2', 'it:0.2', 'that:0.2', 'thing:0.2', 'those:0.2']\n",
      "Debug: candidates: ['m3: 1', 'deepM3: 0.8', 'hole: 0.6', 'prop: 0.5', 'bottle: 0.4']\n",
      "Debug: candidates: ['m3:1', 'deepM3:0.8', 'this:0.2', 'it:0.2', 'that:0.2']\n",
      "[X] Finding Consultants properties similar to SPC\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'VAR1': 'INDEFINITE'}\n",
      "Utterance: define new screw type m3\n",
      "PARSE: \"want\"(brad,defineScrewType(self,VAR1),{NONE(VAR1),m3(VAR1),m3(VAR1),INDEFINITE(VAR1)})\n",
      "==================================\n",
      "\n",
      "======== ITEM 2 ============\n",
      "Utterance: 150 millinewton meters\n",
      "DesiredSemantics: UNKNOWN(brad,self:agent,val(150,mNm),{})\n",
      "\n",
      "Processing utterance: 150 millinewton meters\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"150 millinewton meters\",\n",
      "    \"type\": \"number\",\n",
      "    \"role\": \"central\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"this utterance does not fit into any of the categories \\\"want\\\", \\\"wantbel\\\", or \\\"itk\\\". it's simply a statement of a measurement, not a request, query, or statement of fact or opinion that the speaker expects the listener to believe.\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"measurement\",\n",
      "    \"type\": \"concept\"\n",
      "  }\n",
      "}\n",
      "[X] Finding Candidate concepts\n",
      "\tCandidates: ['m3: 0.7', 'deepM3: 0.8', 'this: 0.5', 'it: 0.5', 'that: 0.5']\n",
      "[X] Selecting best candidate above similarity of 0.8\n",
      "\tBest candidate concept name: NONE\n",
      "[X] Instantiating novel concept\n",
      "[X] Binding novel concept\n",
      "[X] Extracting Properties\n",
      "\tDescriptors: []\n",
      "[X] Finding Consultants properties similar to SPC of the Descriptors\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'VAR0': 'INDEFINITE'}\n",
      "Utterance: 150 millinewton meters\n",
      "PARSE: this utterance does not fit into any of the categories \"want\", \"wantbel\", or \"itk\". it's simply a statement of a measurement, not a request, query, or statement of fact or opinion that the speaker expects the listener to believe.(brad,measurement(VAR0),{INDEFINITE(VAR0)})\n",
      "==================================\n",
      "\n",
      "======== ITEM 3 ============\n",
      "Utterance: 300 millinewton meters\n",
      "DesiredSemantics: UNKNOWN(brad,self:agent,val(300,mNm),{})\n",
      "\n",
      "Processing utterance: 300 millinewton meters\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"300 millinewton meters\",\n",
      "    \"type\": \"number\",\n",
      "    \"role\": \"central\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"this utterance does not fit into any of the categories \\\"want\\\", \\\"wantbel\\\", or \\\"itk\\\". it's simply a statement of a measurement, not a request, query, or statement of belief.\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"measurement\",\n",
      "    \"type\": \"concept\"\n",
      "  }\n",
      "}\n",
      "[X] Finding Candidate concepts\n",
      "\tCandidates: ['m3: 0.8', 'deepM3: 0.7', 'this: 0.5', 'it: 0.5', 'that: 0.5']\n",
      "[X] Selecting best candidate above similarity of 0.8\n",
      "\tBest candidate concept name: NONE\n",
      "[X] Instantiating novel concept\n",
      "[X] Binding novel concept\n",
      "[X] Extracting Properties\n",
      "\tDescriptors: []\n",
      "[X] Finding Consultants properties similar to SPC of the Descriptors\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'VAR0': 'INDEFINITE'}\n",
      "Utterance: 300 millinewton meters\n",
      "PARSE: this utterance does not fit into any of the categories \"want\", \"wantbel\", or \"itk\". it's simply a statement of a measurement, not a request, query, or statement of belief.(brad,measurement(VAR0),{INDEFINITE(VAR0)})\n",
      "==================================\n",
      "\n",
      "======== ITEM 4 ============\n",
      "Utterance: 6500 degrees\n",
      "DesiredSemantics: UNKNOWN(brad,self:agent,val(6500,deg),{})\n",
      "\n",
      "Processing utterance: 6500 degrees\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"6500 degrees\",\n",
      "    \"type\": \"number\",\n",
      "    \"role\": \"central\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"this utterance does not fit into any of the categories \\\"want\\\", \\\"wantbel\\\", \\\"itk\\\". it's just a statement of a fact or a number without any context.\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"This utterance does not provide enough context to determine a core propositional content.\",\n",
      "    \"type\": \"This utterance does not provide enough context to determine a core propositional content.\"\n",
      "  }\n",
      "}\n",
      "[X] Extracting Properties\n",
      "\tDescriptors: []\n",
      "[X] Finding Consultants properties similar to SPC of the Descriptors\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'6500 degrees': 'INDEFINITE'}\n",
      "Utterance: 6500 degrees\n",
      "PARSE: this utterance does not fit into any of the categories \"want\", \"wantbel\", \"itk\". it's just a statement of a fact or a number without any context.(brad,NONE,{})\n",
      "==================================\n",
      "\n",
      "======== ITEM 5 ============\n",
      "Utterance: pose screw feeder\n",
      "DesiredSemantics: UNKNOWN(brad,self:agent,pose(VAR0),{screw feeder(VAR0),DEFINITE(VAR0)})\n",
      "\n",
      "Processing utterance: pose screw feeder\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"screw feeder\",\n",
      "    \"type\": \"physobj\",\n",
      "    \"role\": \"central\"\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"pose\",\n",
      "    \"type\": \"pose\",\n",
      "    \"role\": \"supplemental\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"\\\"want\\\"\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"pose\",\n",
      "    \"type\": \"action\"\n",
      "  }\n",
      "}\n",
      "[X] Finding Candidate actions\n",
      "\tCandidate actions: ['gotoCamerapose:0.7', 'goToPose:0.9', 'goToPoseLong:0.8', 'gotocamerapose:0.7', 'goToPose:0.8']\n",
      "[X] Selecting best candidate\n",
      "\tBest candidate action name: goToPose\n",
      "Central ref: {'text': 'screw feeder', 'type': 'physobj', 'role': 'central'}\n",
      "[X] Binding best candidate\n",
      "\tBound candidate: {'name': 'goToPose', 'bindings': [{'VAR0': 'self'}, {'VAR1': 'pose'}]}\n",
      "[X] Extracting Properties\n",
      "\tDescriptors: [{'text': 'screw feeder', 'arguments': ['VAR1']}, {'text': 'pose', 'arguments': ['VAR1']}]\n",
      "Debug: candidates: ['screw feeder:1', 'conveyor:0.5', 'work area:0.5', 'this:0.2', 'that:0.2']\n",
      "Debug: candidates: ['this:0.1', 'it:0.1', 'that:0.1', 'thing:0.1', 'those:0.1']\n",
      "[X] Finding Consultants properties similar to SPC\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'VAR1': 'INDEFINITE', 'screw feeder': 'INDEFINITE'}\n",
      "Utterance: pose screw feeder\n",
      "PARSE: \"want\"(brad,goToPose(self,VAR1),{screw feeder(VAR1),NONE(VAR1),INDEFINITE(VAR1)})\n",
      "==================================\n",
      "\n",
      "======== ITEM 6 ============\n",
      "Utterance: i will teach you how to screw a screw into a hole\n",
      "DesiredSemantics: STATEMENT(brad,self:agent,want(brad,updateActionLearning(self:agent,screwIn(self:agent,screw,VAR0),start)),{hole(VAR0),DEFINITE(VAR0)})\n",
      "\n",
      "Processing utterance: i will teach you how to screw a screw into a hole\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"screw\",\n",
      "    \"type\": \"physobj\",\n",
      "    \"role\": \"central\"\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"hole\",\n",
      "    \"type\": \"location.\",\n",
      "    \"role\": \"supplemental\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"\\\"want\\\"\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"teaching\",\n",
      "    \"type\": \"action\"\n",
      "  }\n",
      "}\n",
      "[X] Finding Candidate actions\n",
      "\tCandidate actions: ['mountScrew:0.7', 'runScrewdriverJob:0.6', 'screwScrew:0.8', 'defineScrewType:0.5', 'alignWith:0.4']\n",
      "[X] Selecting best candidate\n",
      "\tBest candidate action name: NONE\n",
      "[X] Extracting Propertiese\n",
      "\tDescriptors: [{'text': 'screw', 'arguments': ['screw']}, {'text': 'hole', 'arguments': ['hole']}]\n",
      "Debug: candidates: ['this:0.1', 'it:0.1', 'that:0.1', 'thing:0.1', 'those:0.1']\n",
      "Debug: candidates: ['hole:1', 'this:0.2', 'that:0.2', 'thing:0.2', 'it:0.2']\n",
      "[X] Finding Consultants properties similar to SPC\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'screw': 'INDEFINITE', 'hole': 'INDEFINITE'}\n",
      "Utterance: i will teach you how to screw a screw into a hole\n",
      "PARSE: \"want\"(brad,NONE,{NONE(screw),hole(hole)})\n",
      "==================================\n",
      "\n",
      "======== ITEM 7 ============\n",
      "Utterance: first verify that you can see the hole\n",
      "DesiredSemantics: INSTRUCT(brad,self:agent,want(brad,perceiveEntity(self:agent,VAR0)),{hole(VAR0),DEFINITE(VAR0)})\n",
      "\n",
      "Processing utterance: first verify that you can see the hole\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"the hole\",\n",
      "    \"type\": \"physobj\",\n",
      "    \"role\": \"central\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"\\\"want\\\"\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"verify\",\n",
      "    \"type\": \"action\"\n",
      "  }\n",
      "}\n",
      "[X] Finding Candidate actions\n",
      "\tCandidate actions: ['perceiveEntity:0.7', 'perceiveEntityFromSymbol:0.7', 'alignWith:0.6', 'assembleVision:0.5', 'getRefForJob:0.5']\n",
      "[X] Selecting best candidate\n",
      "\tBest candidate action name: NONE\n",
      "[X] Extracting Propertiese\n",
      "\tDescriptors: [{'text': 'the hole', 'arguments': ['the hole']}, {'text': 'see', 'arguments': ['the hole']}]\n",
      "Debug: candidates: ['hole:1', 'this:0.2', 'it:0.2', 'that:0.2', 'thing:0.2']\n",
      "Debug: candidates: ['hole:1', 'this:0.5', 'it:0.5', 'that:0.5', 'thing:0.5']\n",
      "[X] Finding Consultants properties similar to SPC\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'the hole': 'DEFINITE'}\n",
      "Utterance: first verify that you can see the hole\n",
      "PARSE: \"want\"(brad,NONE,{hole(the hole),hole(the hole)})\n",
      "==================================\n",
      "\n",
      "======== ITEM 8 ============\n",
      "Utterance: then mount the screw\n",
      "DesiredSemantics: INSTRUCT(brad,self:agent,want(brad,mountScrew(self:agent,screw)),{})\n",
      "\n",
      "Processing utterance: then mount the screw\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"screw\",\n",
      "    \"type\": \"physobj\",\n",
      "    \"role\": \"central\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"\\\"want\\\"\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"mount\",\n",
      "    \"type\": \"action\"\n",
      "  }\n",
      "}\n",
      "[X] Finding Candidate actions\n",
      "\tCandidate actions: ['mountScrew:1', 'runScrewdriverJob:0.5', 'screwScrew:0.5', 'assemble:0.2', 'assembleVision:0.2']\n",
      "[X] Selecting best candidate\n",
      "\tBest candidate action name: mountScrew\n",
      "Central ref: {'text': 'screw', 'type': 'physobj', 'role': 'central'}\n",
      "[X] Binding best candidate\n",
      "\tBound candidate: {'name': 'mountScrew', 'bindings': [{'VAR0': 'self'}, {'VAR1': 'screw'}]}\n",
      "[X] Extracting Properties\n",
      "\tDescriptors: []\n",
      "[X] Finding Consultants properties similar to SPC of the Descriptors\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'VAR1': 'INDEFINITE'}\n",
      "Utterance: then mount the screw\n",
      "PARSE: \"want\"(brad,mountScrew(self,VAR1),{INDEFINITE(VAR1)})\n",
      "==================================\n",
      "\n",
      "======== ITEM 9 ============\n",
      "Utterance: then align with the hole\n",
      "DesiredSemantics: INSTRUCT(brad,self:agent,want(brad,alignWith(self:agent,VAR0)),{hole(VAR0),DEFINITE(VAR0)})\n",
      "\n",
      "Processing utterance: then align with the hole\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"the hole\",\n",
      "    \"type\": \"physobj\",\n",
      "    \"role\": \"central\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"\\\"want\\\"\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"align\",\n",
      "    \"type\": \"action\"\n",
      "  }\n",
      "}\n",
      "[X] Finding Candidate actions\n",
      "\tCandidate actions: ['alignWith:1', 'goToPose:0.5', 'goToPoseLong:0.5', 'gotoCamerapose:0.3', 'moveToObjectHeight:0.2']\n",
      "[X] Selecting best candidate\n",
      "\tBest candidate action name: alignWith\n",
      "Central ref: {'text': 'the hole', 'type': 'physobj', 'role': 'central'}\n",
      "[X] Binding best candidate\n",
      "\tBound candidate: {'name': 'alignWith', 'bindings': [{'VAR0': 'self'}, {'VAR1': 'the hole'}]}\n",
      "[X] Extracting Properties\n",
      "\tDescriptors: []\n",
      "[X] Finding Consultants properties similar to SPC of the Descriptors\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'VAR1': 'DEFINITE'}\n",
      "Utterance: then align with the hole\n",
      "PARSE: \"want\"(brad,alignWith(self,VAR1),{DEFINITE(VAR1)})\n",
      "==================================\n",
      "\n",
      "======== ITEM 10 ============\n",
      "Utterance: then run the screwdriver job of the screw\n",
      "DesiredSemantics: INSTRUCT(brad,self:agent,want(brad,runScrewdriverJob(self:agent,screw)),{})\n",
      "\n",
      "Processing utterance: then run the screwdriver job of the screw\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"screwdriver job of the screw\",\n",
      "    \"type\": \"action\",\n",
      "    \"role\": \"central\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"\\\"want\\\"\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"run\",\n",
      "    \"type\": \"action\"\n",
      "  }\n",
      "}\n",
      "[X] Finding Candidate actions\n",
      "\tCandidate actions: ['runScrewdriverJob:0.9', 'mountScrew:0.6', 'screwScrew:0.6', 'defineScrewType:0.5', 'assemble:0.4']\n",
      "[X] Selecting best candidate\n",
      "\tBest candidate action name: runScrewdriverJob\n",
      "Central ref: {'text': 'screwdriver job of the screw', 'type': 'action', 'role': 'central'}\n",
      "[X] Binding best candidate\n",
      "\tBound candidate: {'name': 'runScrewdriverJob', 'bindings': [{'VAR0': 'self'}, {'VAR1': 'screw'}]}\n",
      "[X] Extracting Properties\n",
      "\tDescriptors: []\n",
      "[X] Finding Consultants properties similar to SPC of the Descriptors\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'screwdriver job of the screw': 'INDEFINITE'}\n",
      "Utterance: then run the screwdriver job of the screw\n",
      "PARSE: \"want\"(brad,runScrewdriverJob(self,VAR1),{})\n",
      "==================================\n",
      "\n",
      "======== ITEM 11 ============\n",
      "Utterance: that is how you screw a screw into a hole\n",
      "DesiredSemantics: STATEMENT(brad,self:agent,want(brad,updateActionLearning(self:agent,screwIn(self:agent,screw,VAR0),end)),{hole(VAR0),DEFINITE(VAR0)})\n",
      "\n",
      "Processing utterance: that is how you screw a screw into a hole\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"screw\",\n",
      "    \"type\": \"physobj\",\n",
      "    \"role\": \"central\"\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"hole\",\n",
      "    \"type\": \"location.\",\n",
      "    \"role\": \"supplemental\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"\\\"wantbel\\\"\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"\\\"screwing\",\n",
      "    \"type\": \"action\\\"\"\n",
      "  }\n",
      "}\n",
      "[X] Extracting Properties\n",
      "\tDescriptors: [{'text': 'screw', 'arguments': ['screw']}, {'text': 'hole', 'arguments': ['hole']}]\n",
      "Debug: candidates: ['this:0.2', 'it:0.2', 'that:0.2', 'thing:0.2', 'those:0.2']\n",
      "Debug: candidates: ['hole:1', 'this:0.2', 'that:0.2', 'thing:0.2', 'it:0.2']\n",
      "[X] Finding Consultants properties similar to SPC\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'screw': 'ACTIVATED', 'hole': 'INDEFINITE'}\n",
      "Utterance: that is how you screw a screw into a hole\n",
      "PARSE: \"wantbel\"(brad,NONE,{NONE(screw),hole(hole)})\n",
      "==================================\n",
      "\n",
      "======== ITEM 12 ============\n",
      "Utterance: define new item nfsv\n",
      "DesiredSemantics: INSTRUCT(brad,self:agent,want(brad,defineItem(self:agent,nfsv)),{})\n",
      "\n",
      "Processing utterance: define new item nfsv\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"new item nfsv\",\n",
      "    \"type\": \"string\",\n",
      "    \"role\": \"central\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"\\\"want\\\"\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"define\",\n",
      "    \"type\": \"action\"\n",
      "  }\n",
      "}\n",
      "[X] Finding Candidate actions\n",
      "\tCandidate actions: ['defineScrewType:0.8', 'defineItem:0.9', 'assemble:0.5', 'getRefForJob:0.4', 'startLearningAssembleScript:0.5']\n",
      "[X] Selecting best candidate\n",
      "\tBest candidate action name: defineItem\n",
      "Central ref: {'text': 'new item nfsv', 'type': 'string', 'role': 'central'}\n",
      "[X] Binding best candidate\n",
      "\tBound candidate: {'name': 'defineItem', 'bindings': [{'VAR0': 'self'}, {'VAR1': 'new item nfsv'}]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[X] Extracting Properties\n",
      "\tDescriptors: []\n",
      "[X] Finding Consultants properties similar to SPC of the Descriptors\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'VAR1': 'INDEFINITE'}\n",
      "Utterance: define new item nfsv\n",
      "PARSE: \"want\"(brad,defineItem(self,VAR1),{INDEFINITE(VAR1)})\n",
      "==================================\n",
      "\n",
      "======== ITEM 13 ============\n",
      "Utterance: job circuit breaker face\n",
      "DesiredSemantics: UNKNOWN(brad,self:agent,job(cbDet),{})\n",
      "\n",
      "Processing utterance: job circuit breaker face\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"circuit breaker\",\n",
      "    \"type\": \"physobj\",\n",
      "    \"role\": \"central\"\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"job\",\n",
      "    \"type\": \"action\",\n",
      "    \"role\": \"supplemental\"\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"face\",\n",
      "    \"type\": \"physobj\",\n",
      "    \"role\": \"supplemental\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"the utterance is not clear and does not fit into any of the categories \\\"want\\\", \\\"wantbel\\\", \\\"itk\\\".\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"The utterance is unclear and does not provide enough context to determine the core propositional content.\",\n",
      "    \"type\": \"The utterance is unclear and does not provide enough context to determine the core propositional content.\"\n",
      "  }\n",
      "}\n",
      "[X] Extracting Properties\n",
      "\tDescriptors: [{'text': 'circuit breaker', 'arguments': ['circuit breaker']}, {'text': 'job', 'arguments': ['job']}, {'text': 'face', 'arguments': ['face']}]\n",
      "Debug: candidates: ['this:0.2', 'it:0.2', 'that:0.2', 'thing:0.2', 'those:0.2']\n",
      "Debug: candidates: ['this:0.1', 'it:0.1', 'that:0.1', 'thing:0.1', 'those:0.1']\n",
      "Debug: candidates: ['this:0.1', 'it:0.1', 'that:0.1', 'thing:0.1', 'those:0.1']\n",
      "[X] Finding Consultants properties similar to SPC\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'circuit breaker': 'INDEFINITE', 'job': 'INDEFINITE', 'face': 'INDEFINITE'}\n",
      "Utterance: job circuit breaker face\n",
      "PARSE: the utterance is not clear and does not fit into any of the categories \"want\", \"wantbel\", \"itk\".(brad,NONE,{NONE(circuit breaker),NONE(job),NONE(face)})\n",
      "==================================\n",
      "\n",
      "======== ITEM 14 ============\n",
      "Utterance: i will teach you how to assemble a nfsv\n",
      "DesiredSemantics: INSTRUCT(brad,self:agent,want(brad,startLearningAssembleScript(self:agent,VAR0)),{nfsv(VAR0),DEFINITE(VAR0)})\n",
      "\n",
      "Processing utterance: i will teach you how to assemble a nfsv\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"a nfsv\",\n",
      "    \"type\": \"physobj\",\n",
      "    \"role\": \"central\"\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"i\",\n",
      "    \"type\": \"agent\",\n",
      "    \"role\": \"supplemental\"\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"you\",\n",
      "    \"type\": \"agent.\",\n",
      "    \"role\": \"supplemental\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"\\\"want\\\"\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"assemble\",\n",
      "    \"type\": \"action\"\n",
      "  }\n",
      "}\n",
      "[X] Finding Candidate actions\n",
      "\tCandidate actions: ['assemble:1', 'assembleVision:0.7', 'startLearningAssembleScript:0.8', 'endLearningAssembleScript:0.8', 'defineItem:0.5']\n",
      "[X] Selecting best candidate\n",
      "\tBest candidate action name: assemble\n",
      "Central ref: {'text': 'a nfsv', 'type': 'physobj', 'role': 'central'}\n",
      "[X] Binding best candidate\n",
      "\tBound candidate: {'name': 'assemble', 'bindings': [{'VAR0': 'self'}, {'VAR1': 'a nfsv'}]}\n",
      "[X] Extracting Properties\n",
      "\tDescriptors: [{'text': 'a nfsv', 'arguments': ['VAR1']}, {'text': 'i', 'arguments': ['self']}, {'text': 'you', 'arguments': ['you']}, {'text': 'teach', 'arguments': ['self', 'you']}]\n",
      "Debug: candidates: ['nfsv:1', 'it:0.2', 'that:0.2', 'thing:0.2', 'these:0.2']\n",
      "Debug: candidates: ['this:0.1', 'it:0.1', 'that:0.1', 'thing:0.1', 'those:0.1']\n",
      "Debug: candidates: ['it:0.2', 'they:0.2', 'these:0.2', 'that:0.2', 'those:0.2']\n",
      "Debug: candidates: ['doit: 0.6', 'dothis: 0.6', 'dothat: 0.6', 'that: 0.5', 'this: 0.5']\n",
      "[X] Finding Consultants properties similar to SPC\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'VAR1': 'INDEFINITE', 'i': 'INFOCUS', 'you': 'INFOCUS'}\n",
      "Utterance: i will teach you how to assemble a nfsv\n",
      "PARSE: \"want\"(brad,assemble(self,VAR1),{nfsv(VAR1),NONE(self),NONE(you),NONE(self,you),INDEFINITE(VAR1)})\n",
      "==================================\n",
      "\n",
      "======== ITEM 15 ============\n",
      "Utterance: first go to pose conveyor\n",
      "DesiredSemantics: INSTRUCT(brad,self:agent,want(brad,gotoCamerapose(self:agent,VAR0)),{conveyor(VAR0),DEFINITE(VAR0)})\n",
      "\n",
      "Processing utterance: first go to pose conveyor\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"pose conveyor\",\n",
      "    \"type\": \"location\",\n",
      "    \"role\": \"central\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"\\\"want\\\"\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"\\\"go\",\n",
      "    \"type\": \"action\\\"\"\n",
      "  }\n",
      "}\n",
      "[X] Extracting Properties\n",
      "\tDescriptors: [{'text': 'first', 'arguments': ['pose conveyor']}]\n",
      "Debug: candidates: ['this:0.1', 'it:0.1', 'that:0.1', 'thing:0.1', 'those:0.1']\n",
      "[X] Finding Consultants properties similar to SPC\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'pose conveyor': 'INDEFINITE'}\n",
      "Utterance: first go to pose conveyor\n",
      "PARSE: \"want\"(brad,NONE,{NONE(pose conveyor)})\n",
      "==================================\n",
      "\n",
      "======== ITEM 16 ============\n",
      "Utterance: then verify that you can see the nfsv\n",
      "DesiredSemantics: INSTRUCT(brad,self:agent,want(brad,perceiveEntity(self:agent,VAR0)),{nfsv(VAR0),DEFINITE(VAR0)})\n",
      "\n",
      "Processing utterance: then verify that you can see the nfsv\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"the nfsv\",\n",
      "    \"type\": \"string\",\n",
      "    \"role\": \"central\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"\\\"want\\\"\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"verify\",\n",
      "    \"type\": \"action\"\n",
      "  }\n",
      "}\n",
      "[X] Finding Candidate actions\n",
      "\tCandidate actions: ['perceiveEntityFromSymbol:0.7', 'perceiveEntity:0.7', 'assembleVision:0.6', 'getRefForJob:0.5', 'getCurrGoals:0.4']\n",
      "[X] Selecting best candidate\n",
      "\tBest candidate action name: NONE\n",
      "[X] Extracting Propertiese\n",
      "\tDescriptors: [{'text': 'the nfsv', 'arguments': ['the nfsv']}, {'text': 'can see', 'arguments': ['the nfsv']}]\n",
      "Debug: candidates: ['nfsv:1', 'it:0.5', 'that:0.5', 'thing:0.5', 'these:0.5']\n",
      "Debug: candidates: ['nfsv:1', 'it:0.8', 'that:0.8', 'thing:0.8', 'these:0.8']\n",
      "[X] Finding Consultants properties similar to SPC\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'the nfsv': 'DEFINITE'}\n",
      "Utterance: then verify that you can see the nfsv\n",
      "PARSE: \"want\"(brad,NONE,{nfsv(the nfsv),nfsv(the nfsv)})\n",
      "==================================\n",
      "\n",
      "======== ITEM 17 ============\n",
      "Utterance: then get the nfsv on the work area\n",
      "DesiredSemantics: INSTRUCT(brad,self:agent,want(brad,getOn(self:agent,VAR0,VAR1)),{nfsv(VAR0),work area(VAR1),DEFINITE(VAR0),DEFINITE(VAR1)})\n",
      "\n",
      "Processing utterance: then get the nfsv on the work area\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"nfsv\",\n",
      "    \"type\": \"NONE\",\n",
      "    \"role\": \"central\"\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"work area\",\n",
      "    \"type\": \"location\",\n",
      "    \"role\": \"supplemental\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"\\\"want\\\"\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"get\",\n",
      "    \"type\": \"action\"\n",
      "  }\n",
      "}\n",
      "[X] Finding Candidate actions\n",
      "\tCandidate actions: ['getGripper:0.7', 'getCurrGoals:0.6', 'getTime:0.6', 'getRefForJob:0.7', 'getOn:0.6']\n",
      "[X] Selecting best candidate\n",
      "\tBest candidate action name: NONE\n",
      "[X] Extracting Propertiese\n",
      "\tDescriptors: [{'text': 'nfsv', 'arguments': ['nfsv']}, {'text': 'work area', 'arguments': ['work area']}]\n",
      "Debug: candidates: ['nfsv:1', 'this:0.2', 'it:0.2', 'that:0.2', 'thing:0.2']\n",
      "Debug: candidates: ['work area:1', 'conveyor:0.7', 'screw feeder:0.7', 'this:0.5', 'that:0.5']\n",
      "[X] Finding Consultants properties similar to SPC\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'nfsv': 'INDEFINITE', 'work area': 'DEFINITE'}\n",
      "Utterance: then get the nfsv on the work area\n",
      "PARSE: \"want\"(brad,NONE,{nfsv(nfsv),work area(work area)})\n",
      "==================================\n",
      "\n",
      "======== ITEM 18 ============\n",
      "Utterance: then search for 2 m3 holes\n",
      "DesiredSemantics: INSTRUCT(brad,self:agent,want(brad,observeDescriptor(self:agent,m3,2)),{})\n",
      "\n",
      "Processing utterance: then search for 2 m3 holes\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"2 m3 holes\",\n",
      "    \"type\": \"physobj\",\n",
      "    \"role\": \"central\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"\\\"want\\\"\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"search\",\n",
      "    \"type\": \"action\"\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[X] Finding Candidate actions\n",
      "\tCandidate actions: ['perceiveEntity:0.7', 'perceiveEntityFromSymbol:0.7', 'getRefForJob:0.6', 'assembleVision:0.5', 'alignWith:0.5']\n",
      "[X] Selecting best candidate\n",
      "\tBest candidate action name: NONE\n",
      "[X] Extracting Propertiese\n",
      "\tDescriptors: [{'text': '2 m3 holes', 'arguments': ['central']}]\n",
      "Debug: candidates: ['m3: 1', 'deepM3: 0.8', 'hole: 0.8', 'this: 0.2', 'that: 0.2']\n",
      "[X] Finding Consultants properties similar to SPC\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'2 m3 holes': 'INDEFINITE'}\n",
      "Utterance: then search for 2 m3 holes\n",
      "PARSE: \"want\"(brad,NONE,{m3(central)})\n",
      "==================================\n",
      "\n",
      "======== ITEM 19 ============\n",
      "Utterance: screw a m3 screw into the left m3 hole\n",
      "DesiredSemantics: INSTRUCT(brad,self:agent,want(brad,screwIn(self:agent,m3,VAR0)),{m3(VAR0),left(VAR0),DEFINITE(VAR0)})\n",
      "\n",
      "Processing utterance: screw a m3 screw into the left m3 hole\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"m3 screw\",\n",
      "    \"type\": \"physobj\",\n",
      "    \"role\": \"central\"\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"left m3 hole\",\n",
      "    \"type\": \"physobj.\",\n",
      "    \"role\": \"supplemental\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"want\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"screwing\",\n",
      "    \"type\": \"action\"\n",
      "  }\n",
      "}\n",
      "[X] Finding Candidate actions\n",
      "\tCandidate actions: ['mountScrew:0.8', 'runScrewdriverJob:0.7', 'screwIn:0.9', 'screwScrew:0.9', 'rotateToEE:0.6']\n",
      "[X] Selecting best candidate\n",
      "\tBest candidate action name: screwIn\n",
      "Central ref: {'text': 'm3 screw', 'type': 'physobj', 'role': 'central'}\n",
      "[X] Binding best candidate\n",
      "\tBound candidate: {'name': 'screwIn', 'bindings': [{'?actor': 'self'}, {'?var_1': 'm3 screw'}, {'?var_0': 'left m3 hole'}]}\n",
      "[X] Extracting Properties\n",
      "\tDescriptors: [{'text': 'm3 screw', 'arguments': ['?var_1']}, {'text': 'left m3 hole', 'arguments': ['?var_0']}]\n",
      "Debug: candidates: ['m3:1', 'deepM3:0.8', 'hole:0.6', 'prop:0.5', 'bottle:0.4']\n",
      "Debug: candidates: ['hole: 0.8', 'm3: 0.9', 'left: 1.0', 'this: 0.6', 'that: 0.6']\n",
      "[X] Finding Consultants properties similar to SPC\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'?var_1': 'INDEFINITE', '?var_0': 'DEFINITE'}\n",
      "Utterance: screw a m3 screw into the left m3 hole\n",
      "PARSE: want(brad,screwIn(self,?var_1,?var_0),{m3(?var_1),left(?var_0),INDEFINITE(?var_1),DEFINITE(?var_0)})\n",
      "==================================\n",
      "\n",
      "======== ITEM 20 ============\n",
      "Utterance: then go to pose work area\n",
      "DesiredSemantics: INSTRUCT(brad,self:agent,want(brad,gotoCamerapose(self:agent,VAR0)),{work area(VAR0),DEFINITE(VAR0)})\n",
      "\n",
      "Processing utterance: then go to pose work area\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"pose work area\",\n",
      "    \"type\": \"location\",\n",
      "    \"role\": \"central\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"\\\"want\\\"\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"\\\"go\",\n",
      "    \"type\": \"action\\\"\"\n",
      "  }\n",
      "}\n",
      "[X] Extracting Properties\n",
      "\tDescriptors: []\n",
      "[X] Finding Consultants properties similar to SPC of the Descriptors\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'pose work area': 'INDEFINITE'}\n",
      "Utterance: then go to pose work area\n",
      "PARSE: \"want\"(brad,NONE,{})\n",
      "==================================\n",
      "\n",
      "======== ITEM 21 ============\n",
      "Utterance: screw a m3 screw into the right m3 hole\n",
      "DesiredSemantics: INSTRUCT(brad,self:agent,want(brad,screwIn(self:agent,m3,VAR0)),{m3(VAR0),right(VAR0),DEFINITE(VAR0)})\n",
      "\n",
      "Processing utterance: screw a m3 screw into the right m3 hole\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"m3 screw\",\n",
      "    \"type\": \"physobj\",\n",
      "    \"role\": \"central\"\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"right m3 hole\",\n",
      "    \"type\": \"physobj.\",\n",
      "    \"role\": \"supplemental\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"want\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"screwing\",\n",
      "    \"type\": \"action\"\n",
      "  }\n",
      "}\n",
      "[X] Finding Candidate actions\n",
      "\tCandidate actions: ['mountScrew:0.8', 'runScrewdriverJob:0.7', 'screwIn:0.9', 'screwScrew:0.9', 'rotateToEE:0.5']\n",
      "[X] Selecting best candidate\n",
      "\tBest candidate action name: screwIn\n",
      "Central ref: {'text': 'm3 screw', 'type': 'physobj', 'role': 'central'}\n",
      "[X] Binding best candidate\n",
      "\tBound candidate: {'name': 'screwIn', 'bindings': [{'?actor': 'self'}, {'?var_1': 'm3 screw'}, {'?var_0': 'right m3 hole'}]}\n",
      "[X] Extracting Properties\n",
      "\tDescriptors: [{'text': 'm3 screw', 'arguments': ['?var_1']}, {'text': 'right m3 hole', 'arguments': ['?var_0']}]\n",
      "Debug: candidates: ['m3: 1', 'deepM3: 0.8', 'prop: 0.6', 'bottle: 0.2', 'nfsv: 0.1']\n",
      "Debug: candidates: ['right:0.9', 'm3:0.8', 'hole:0.8', 'deepM3:0.7', 'prop:0.6']\n",
      "[X] Finding Consultants properties similar to SPC\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'?var_1': 'INDEFINITE', '?var_0': 'DEFINITE'}\n",
      "Utterance: screw a m3 screw into the right m3 hole\n",
      "PARSE: want(brad,screwIn(self,?var_1,?var_0),{m3(?var_1),right(?var_0),INDEFINITE(?var_1),DEFINITE(?var_0)})\n",
      "==================================\n",
      "\n",
      "======== ITEM 22 ============\n",
      "Utterance: then get the nfsv on the conveyor\n",
      "DesiredSemantics: INSTRUCT(brad,self:agent,want(brad,getOn(self:agent,VAR0,VAR1)),{nfsv(VAR0),conveyor(VAR1),DEFINITE(VAR0),DEFINITE(VAR1)})\n",
      "\n",
      "Processing utterance: then get the nfsv on the conveyor\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"nfsv\",\n",
      "    \"type\": \"name\",\n",
      "    \"role\": \"central\"\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"conveyor\",\n",
      "    \"type\": \"physobj.\",\n",
      "    \"role\": \"supplemental\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"\\\"want\\\"\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"get\",\n",
      "    \"type\": \"action\"\n",
      "  }\n",
      "}\n",
      "[X] Finding Candidate actions\n",
      "\tCandidate actions: ['getGripper:0.6', 'getCurrGoals:0.5', 'getRefForJob:0.5', 'getTime:0.5', 'getOn:0.7']\n",
      "[X] Selecting best candidate\n",
      "\tBest candidate action name: NONE\n",
      "[X] Extracting Propertiese\n",
      "\tDescriptors: []\n",
      "[X] Finding Consultants properties similar to SPC of the Descriptors\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'nfsv': 'DEFINITE', 'conveyor': 'DEFINITE'}\n",
      "Utterance: then get the nfsv on the conveyor\n",
      "PARSE: \"want\"(brad,NONE,{})\n",
      "==================================\n",
      "\n",
      "======== ITEM 23 ============\n",
      "Utterance: then advance the conveyor belt\n",
      "DesiredSemantics: INSTRUCT(brad,self:agent,want(brad,moveConveyorForward(self:agent)),{})\n",
      "\n",
      "Processing utterance: then advance the conveyor belt\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"conveyor belt\",\n",
      "    \"type\": \"physobj\",\n",
      "    \"role\": \"central\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"want\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"advance\",\n",
      "    \"type\": \"action\"\n",
      "  }\n",
      "}\n",
      "[X] Finding Candidate actions\n",
      "\tCandidate actions: ['moveConveyorForward:0.8', 'moveConveyorBackward:0.6', 'gotoCamerapose:0.2', 'goToPose:0.2', 'goToPoseLong:0.2']\n",
      "[X] Selecting best candidate\n",
      "\tBest candidate action name: NONE\n",
      "[X] Extracting Propertiese\n",
      "\tDescriptors: []\n",
      "[X] Finding Consultants properties similar to SPC of the Descriptors\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'conveyor belt': 'INDEFINITE'}\n",
      "Utterance: then advance the conveyor belt\n",
      "PARSE: want(brad,NONE,{})\n",
      "==================================\n",
      "\n",
      "======== ITEM 24 ============\n",
      "Utterance: that is how you assemble a nfsv\n",
      "DesiredSemantics: INSTRUCT(brad,self:agent,want(brad,endLearningAssembleScript(self:agent,VAR0))),{nfsv(VAR0),DEFINITE(VAR0)})\n",
      "\n",
      "Processing utterance: that is how you assemble a nfsv\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"a nfsv\",\n",
      "    \"type\": \"physobj\",\n",
      "    \"role\": \"central\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"\\\"wantbel\\\"\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"assemble\",\n",
      "    \"type\": \"action\"\n",
      "  }\n",
      "}\n",
      "[X] Finding Candidate actions\n",
      "\tCandidate actions: ['assemble:1', 'assembleVision:0.7', 'startLearningAssembleScript:0.7', 'endLearningAssembleScript:0.7', 'defineItem:0.5']\n",
      "[X] Selecting best candidate\n",
      "\tBest candidate action name: assemble\n",
      "Central ref: {'text': 'a nfsv', 'type': 'physobj', 'role': 'central'}\n",
      "[X] Binding best candidate\n",
      "\tBound candidate: {'name': 'assemble', 'bindings': [{'VAR0': 'self'}, {'VAR1': 'a nfsv'}]}\n",
      "[X] Extracting Properties\n",
      "\tDescriptors: []\n",
      "[X] Finding Consultants properties similar to SPC of the Descriptors\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'VAR1': 'INDEFINITE'}\n",
      "Utterance: that is how you assemble a nfsv\n",
      "PARSE: \"wantbel\"(brad,assemble(self,VAR1),{INDEFINITE(VAR1)})\n",
      "==================================\n",
      "\n",
      "======== ITEM 25 ============\n",
      "Utterance: assemble a nfsv\n",
      "DesiredSemantics: INSTRUCT(brad,self:agent,want(brad,assemble(self:agent,VAR0)),{nfsv(VAR0),DEFINITE(VAR0)})\n",
      "\n",
      "Processing utterance: assemble a nfsv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"nfsv\",\n",
      "    \"type\": \"string\",\n",
      "    \"role\": \"central\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"\\\"want\\\"\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"assemble\",\n",
      "    \"type\": \"action\"\n",
      "  }\n",
      "}\n",
      "[X] Finding Candidate actions\n",
      "\tCandidate actions: ['assemble:1', 'assembleVision:0.7', 'startLearningAssembleScript:0.6', 'endLearningAssembleScript:0.6', 'defineItem:0.5']\n",
      "[X] Selecting best candidate\n",
      "\tBest candidate action name: assemble\n",
      "Central ref: {'text': 'nfsv', 'type': 'string', 'role': 'central'}\n",
      "[X] Binding best candidate\n",
      "\tBound candidate: {'name': 'assemble', 'bindings': [{'VAR0': 'self'}, {'VAR1': 'nfsv'}]}\n",
      "[X] Extracting Properties\n",
      "\tDescriptors: []\n",
      "[X] Finding Consultants properties similar to SPC of the Descriptors\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'VAR1': 'INDEFINITE'}\n",
      "Utterance: assemble a nfsv\n",
      "PARSE: \"want\"(brad,assemble(self,VAR1),{INDEFINITE(VAR1)})\n",
      "==================================\n",
      "\n",
      "======== ITEM 26 ============\n",
      "Utterance: define new item nvfau\n",
      "DesiredSemantics: INSTRUCT(brad,self:agent,want(brad,defineItem(self:agent,nvfau)),{})\n",
      "\n",
      "Processing utterance: define new item nvfau\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"new item nvfau\",\n",
      "    \"type\": \"string\",\n",
      "    \"role\": \"central\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"\\\"want\\\"\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"defining\",\n",
      "    \"type\": \"action\"\n",
      "  }\n",
      "}\n",
      "[X] Finding Candidate actions\n",
      "\tCandidate actions: ['defineScrewType:0.8', 'defineItem:0.9', 'assemble:0.3', 'getRefForJob:0.2', 'startLearningAssembleScript:0.4']\n",
      "[X] Selecting best candidate\n",
      "\tBest candidate action name: defineItem\n",
      "Central ref: {'text': 'new item nvfau', 'type': 'string', 'role': 'central'}\n",
      "[X] Binding best candidate\n",
      "\tBound candidate: {'name': 'defineItem', 'bindings': [{'VAR0': 'self'}, {'VAR1': 'new item nvfau'}]}\n",
      "[X] Extracting Properties\n",
      "\tDescriptors: []\n",
      "[X] Finding Consultants properties similar to SPC of the Descriptors\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'VAR1': 'INDEFINITE'}\n",
      "Utterance: define new item nvfau\n",
      "PARSE: \"want\"(brad,defineItem(self,VAR1),{INDEFINITE(VAR1)})\n",
      "==================================\n",
      "\n",
      "======== ITEM 27 ============\n",
      "Utterance: job n v face\n",
      "DesiredSemantics: UNKNOWN(brad,self:agent,job(nvDet),{})\n",
      "\n",
      "Processing utterance: job n v face\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"job, face\",\n",
      "    \"type\": \"NONE\",\n",
      "    \"role\": \"central\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"this utterance is not clear and does not fit into any of the categories \\\"want\\\", \\\"wantbel\\\", or \\\"itk\\\".\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"This utterance is unclear and does not provide enough context to determine the core propositional content.\",\n",
      "    \"type\": \"This utterance is unclear and does not provide enough context to determine the core propositional content.\"\n",
      "  }\n",
      "}\n",
      "[X] Extracting Properties\n",
      "\tDescriptors: []\n",
      "[X] Finding Consultants properties similar to SPC of the Descriptors\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'job': 'INDEFINITE', 'face': 'INDEFINITE'}\n",
      "Utterance: job n v face\n",
      "PARSE: this utterance is not clear and does not fit into any of the categories \"want\", \"wantbel\", or \"itk\".(brad,NONE,{})\n",
      "==================================\n",
      "\n",
      "======== ITEM 28 ============\n",
      "Utterance: assemble an nvfau is like assemble an nfsv\n",
      "DesiredSemantics: INSTRUCT(brad,self:agent,want(brad,modifyAssemble(self:agent,assemble(self:agent,VAR0),assemble(self:agent,VAR1))),{nvfau(VAR0),nfsv(VAR1),DEFINITE(VAR0),DEFINITE(VAR1)})\n",
      "\n",
      "Processing utterance: assemble an nvfau is like assemble an nfsv\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"nvfau, nfsv\",\n",
      "    \"type\": \"NONE\",\n",
      "    \"role\": \"central\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"wantbel\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"similarity\",\n",
      "    \"type\": \"concept\"\n",
      "  }\n",
      "}\n",
      "[X] Finding Candidate concepts\n",
      "\tCandidates: ['this:0.1', 'it:0.1', 'that:0.1', 'thing:0.1', 'those:0.1']\n",
      "[X] Selecting best candidate above similarity of 0.8\n",
      "\tBest candidate concept name: NONE\n",
      "[X] Instantiating novel concept\n",
      "[X] Binding novel concept\n",
      "We have a problem. There is a unbound variable here:\n",
      "{\"name\": \"similarity\", \"bindings\": [{\"VAR0\": \"NONE\"}, {\"VAR1\": \"NONE\"}]}\n",
      "[X] Extracting Properties\n",
      "\tDescriptors: [{'text': 'nvfau', 'arguments': ['VAR0']}, {'text': 'nfsv', 'arguments': ['VAR1']}]\n",
      "Debug: candidates: ['nvfau: 1', 'nfsv: 0.9', 'assemble: 0.2', 'it: 0.1', 'that: 0.1']\n",
      "Debug: candidates: ['nfsv:1', 'it:0.2', 'that:0.2', 'thing:0.2', 'these:0.2']\n",
      "[X] Finding Consultants properties similar to SPC\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'nvfau': 'INDEFINITE', 'nfsv': 'INDEFINITE'}\n",
      "Utterance: assemble an nvfau is like assemble an nfsv\n",
      "PARSE: wantbel(brad,similarity(VAR0,VAR1),{nvfau(VAR0),nfsv(VAR1)})\n",
      "==================================\n",
      "\n",
      "======== ITEM 29 ============\n",
      "Utterance: replace search for 2 m3 holes with search for 2 deep m3 holes\n",
      "DesiredSemantics: UNKNOWN(brad,self:agent,mod(replace(observeDescriptor(self:agent,deepM3,2),observeDescriptor(self:agent,m3,2))),{})\n",
      "\n",
      "Processing utterance: replace search for 2 m3 holes with search for 2 deep m3 holes\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"search for 2 m3 holes\",\n",
      "    \"type\": \"action\",\n",
      "    \"role\": \"central\"\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"2 deep m3 holes\",\n",
      "    \"type\": \"physobj\",\n",
      "    \"role\": \"supplemental\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"\\\"want\\\"\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"replace\",\n",
      "    \"type\": \"action\"\n",
      "  }\n",
      "}\n",
      "[X] Finding Candidate actions\n",
      "\tCandidate actions: ['defineScrewType:0.3', 'mountScrew:0.2', 'runScrewdriverJob:0.2', 'screwScrew:0.4', 'assemble:0.1']\n",
      "[X] Selecting best candidate\n",
      "\tBest candidate action name: NONE\n",
      "[X] Extracting Propertiese\n",
      "\tDescriptors: [{'text': 'search for 2 m3 holes', 'arguments': ['search for 2 m3 holes']}, {'text': '2 deep m3 holes', 'arguments': ['2 deep m3 holes']}, {'text': 'deep', 'arguments': ['2 deep m3 holes']}]\n",
      "Debug: candidates: ['m3: 1', 'deepM3: 1', 'hole: 0.8', 'this: 0.2', 'it: 0.2']\n",
      "Debug: candidates: ['deepM3: 1', 'm3: 0.8', 'hole: 0.7', 'this: 0.5', 'it: 0.5']\n",
      "Debug: candidates: ['deepM3: 1', 'hole: 0.5', 'm3: 0.5', 'this: 0.2', 'it: 0.2']\n",
      "[X] Finding Consultants properties similar to SPC\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'search for 2 m3 holes': 'INFOCUS', '2 deep m3 holes': 'INDEFINITE'}\n",
      "Utterance: replace search for 2 m3 holes with search for 2 deep m3 holes\n",
      "PARSE: \"want\"(brad,NONE,{m3(search for 2 m3 holes),deepM3(2 deep m3 holes),deepM3(2 deep m3 holes)})\n",
      "==================================\n",
      "\n",
      "======== ITEM 30 ============\n",
      "Utterance: replace screw an m3 screw into the left m3 hole with screw an m3 screw into the bottom deep m3 hole\n",
      "DesiredSemantics: UNKNOWN(brad,self:agent,mod(replace(screwIn(self:agent,m3,VAR1),screwIn(self:agent,m3,VAR0))),{m3(VAR0),left(VAR0),deepM3(VAR1),bottom(VAR1),DEFINITE(VAR0),DEFINITE(VAR1)})\n",
      "\n",
      "Processing utterance: replace screw an m3 screw into the left m3 hole with screw an m3 screw into the bottom deep m3 hole\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"m3 screw\",\n",
      "    \"type\": \"physobj\",\n",
      "    \"role\": \"central\"\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"left m3 hole\",\n",
      "    \"type\": \"location.\",\n",
      "    \"role\": \"supplemental\"\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"bottom deep m3 hole\",\n",
      "    \"type\": \"physobj.\",\n",
      "    \"role\": \"supplemental\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"want\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"replacing\",\n",
      "    \"type\": \"action\"\n",
      "  }\n",
      "}\n",
      "[X] Finding Candidate actions\n",
      "\tCandidate actions: ['mountScrew:0.7', 'runScrewdriverJob:0.6', 'screwIn:0.6', 'screwScrew:0.7', 'defineScrewType:0.5']\n",
      "[X] Selecting best candidate\n",
      "\tBest candidate action name: NONE\n",
      "[X] Extracting Propertiese\n",
      "\tDescriptors: [{'text': 'm3 screw', 'arguments': ['m3 screw']}, {'text': 'left', 'arguments': ['left m3 hole']}, {'text': 'bottom deep', 'arguments': ['bottom deep m3 hole']}]\n",
      "Debug: candidates: ['m3:1', 'deepM3:0.8', 'prop:0.6', 'bottle:0.5', 'nfsv:0.5']\n",
      "Debug: candidates: ['left: 1', 'right: 0.5', 'top: 0.5', 'bottom: 0.5', 'prop: 0.2']\n",
      "Debug: candidates: ['bottom:1', 'deepM3:0.5', 'left:0.2', 'right:0.2', 'top:0.2']\n",
      "[X] Finding Consultants properties similar to SPC\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'m3 screw': 'DEFINITE', 'left m3 hole': 'DEFINITE', 'bottom deep m3 hole': 'DEFINITE'}\n",
      "Utterance: replace screw an m3 screw into the left m3 hole with screw an m3 screw into the bottom deep m3 hole\n",
      "PARSE: want(brad,NONE,{m3(m3 screw),left(left m3 hole),bottom(bottom deep m3 hole)})\n",
      "==================================\n",
      "\n",
      "======== ITEM 31 ============\n",
      "Utterance: replace screw an m3 screw into the right m3 hole with screw an m3 screw into the top deep m3 hole\n",
      "DesiredSemantics: UNKNOWN(brad,self:agent,mod(replace(screwIn(self:agent,m3,VAR1),screwIn(self:agent,m3,VAR0))),{m3(VAR0),right(VAR0),deepM3(VAR1),top(VAR1),DEFINITE(VAR0),DEFINITE(VAR1)})\n",
      "\n",
      "Processing utterance: replace screw an m3 screw into the right m3 hole with screw an m3 screw into the top deep m3 hole\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"m3 screw, m3 hole\",\n",
      "    \"type\": \"physobj\",\n",
      "    \"role\": \"central\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"\\\"want\\\"\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"replace\",\n",
      "    \"type\": \"action\"\n",
      "  }\n",
      "}\n",
      "[X] Finding Candidate actions\n",
      "\tCandidate actions: ['mountScrew:0.7', 'runScrewdriverJob:0.6', 'screwIn:0.6', 'screwScrew:0.8', 'defineScrewType:0.5']\n",
      "[X] Selecting best candidate\n",
      "\tBest candidate action name: NONE\n",
      "[X] Extracting Propertiese\n",
      "\tDescriptors: [{'text': 'right', 'arguments': ['m3 hole']}, {'text': 'top', 'arguments': ['m3 hole']}, {'text': 'deep', 'arguments': ['m3 hole']}]\n",
      "Debug: candidates: ['right:1', 'left:0.5', 'top:0.5', 'bottom:0.5', 'prop:0']\n",
      "Debug: candidates: ['top:1', 'this:0.2', 'it:0.2', 'that:0.2', 'thing:0.2']\n",
      "Debug: candidates: ['deepM3: 1', 'hole: 0.5', 'm3: 0.5', 'top: 0.2', 'bottom: 0.2']\n",
      "[X] Finding Consultants properties similar to SPC\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'m3 screw, m3 hole': 'DEFINITE'}\n",
      "Utterance: replace screw an m3 screw into the right m3 hole with screw an m3 screw into the top deep m3 hole\n",
      "PARSE: \"want\"(brad,NONE,{right(m3 hole),top(m3 hole),deepM3(m3 hole)})\n",
      "==================================\n",
      "\n",
      "======== ITEM 32 ============\n",
      "Utterance: that is all\n",
      "DesiredSemantics: UNKNOWN(brad,self:agent,mod(none),{})\n",
      "\n",
      "Processing utterance: that is all\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"this sentence is too vague and does not provide enough context to determine a central referent.\",\n",
      "    \"type\": \"NONE\",\n",
      "    \"role\": \"central\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"\\\"wantbel\\\"\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"this sentence is too vague and does not provide enough context to determine a core propositional content.\",\n",
      "    \"type\": \"this sentence is too vague and does not provide enough context to determine a core propositional content.\"\n",
      "  }\n",
      "}\n",
      "[X] Extracting Properties\n",
      "\tDescriptors: []\n",
      "[X] Finding Consultants properties similar to SPC of the Descriptors\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'NONE': 'ACTIVATED'}\n",
      "Utterance: that is all\n",
      "PARSE: \"wantbel\"(brad,NONE,{})\n",
      "==================================\n",
      "\n",
      "======== ITEM 33 ============\n",
      "Utterance: assemble an nvfau\n",
      "DesiredSemantics: INSTRUCT(brad,self:agent,want(brad,assemble(self:agent,VAR0)),{nvfau(VAR0),DEFINITE(VAR0)})\n",
      "\n",
      "Processing utterance: assemble an nvfau\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"an nvfau\",\n",
      "    \"type\": \"NONE\",\n",
      "    \"role\": \"central\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"\\\"want\\\"\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"assemble\",\n",
      "    \"type\": \"action\"\n",
      "  }\n",
      "}\n",
      "[X] Finding Candidate actions\n",
      "\tCandidate actions: ['assemble:1', 'startLearningAssembleScript:0.7', 'endLearningAssembleScript:0.7', 'assembleVision:0.7', 'defineItem:0.5']\n",
      "[X] Selecting best candidate\n",
      "\tBest candidate action name: assemble\n",
      "Central ref: {'text': 'an nvfau', 'type': 'NONE', 'role': 'central'}\n",
      "We have a problem. There is a unbound variable here:\n",
      "{\"name\": \"assemble\", \"bindings\": [{\"VAR0\": \"self\"}, {\"VAR1\": \"NONE\"}]}\n",
      "[X] Binding best candidate\n",
      "\tBound candidate: {'name': 'assemble', 'bindings': [{'VAR0': 'self'}, {'VAR1': 'NONE'}]}\n",
      "[X] Extracting Properties\n",
      "\tDescriptors: []\n",
      "[X] Finding Consultants properties similar to SPC of the Descriptors\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'an nvfau': 'INDEFINITE'}\n",
      "Utterance: assemble an nvfau\n",
      "PARSE: \"want\"(brad,assemble(self,VAR1),{})\n",
      "==================================\n"
     ]
    }
   ],
   "source": [
    "outputs=[]\n",
    "parses = []\n",
    "for idx,item in enumerate(dataset.data):\n",
    "    print(f\"\\n======== ITEM {idx} ============\")\n",
    "    print(f\"Utterance: {item['utterance']}\")\n",
    "    print(f\"DesiredSemantics: {item['desired_semantics']}\")\n",
    "    output = parse(utterance=item['utterance'],robot_model=item['robot_model'])\n",
    "    output['desired_semantics'] = item['desired_semantics']\n",
    "    outputs.append(output)\n",
    "    parses.append(output['parse'])\n",
    "    \n",
    "    # Throw into a file\n",
    "    with open('../data/output/out.json', 'w') as fout:\n",
    "        json.dump(outputs, fout, indent=4, sort_keys=True)\n",
    "    print(\"==================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "323b8855",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/output/out.json\", \"r\") as fin:\n",
    "    results = json.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7d827378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "176f7bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_parses = []\n",
    "for r in results:\n",
    "    item  = f\"{r['utterance']}, {r['parse']}, {r['desired_semantics']}\"\n",
    "    result_parses.append(item)\n",
    "\n",
    "with open(\"../data/output/result_parses.csv\", \"w\") as fout:\n",
    "    for line in result_parses:\n",
    "        fout.write(f\"{line}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f51016a",
   "metadata": {},
   "source": [
    "# Next steps\n",
    "\n",
    "- think about how to generalize this for PDDL\n",
    "    \n",
    "- the action/concept repertoire seems to be off here...many utterances are not supported by the underlying model \n",
    "- think about  what the two papers will look like\n",
    "    - constraint understanding --> challenge here is for formal verifiability? \n",
    "    - parsing --> challenge here is to define an NLP pipeline that can ground human-robot interactions. \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
