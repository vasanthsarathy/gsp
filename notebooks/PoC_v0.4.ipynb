{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be2c88d9",
   "metadata": {},
   "source": [
    "# Version 4\n",
    "6/22/2023\n",
    "\n",
    "New  data structure for the parsing. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8426730",
   "metadata": {},
   "source": [
    "```\n",
    "        referents = [\n",
    "            {\"text\": \"m3 screw\", \n",
    "            \"type\": \"physobj\",\n",
    "            \"variable_name\": \"VAR0\",\n",
    "            \"cognitive status\": \"ACTIVATED\",\n",
    "            \"role\": \"central\"},\n",
    "            \n",
    "            {\"text\": \"evan\", \n",
    "            \"type\": \"agent\",\n",
    "            \"variable_name\": \"VAR1\",\n",
    "            \"cognitive status\": \"FAMILIAR\",\n",
    "            \"role\": \"supplemental\"}\n",
    "            ]\n",
    "            \n",
    "        descriptors = [\n",
    "            {\"text\": \"m3 screw\", \n",
    "            \"name\": \"m3\",\n",
    "            \"arguments\": [\"VAR0\"] },\n",
    "            \n",
    "            {\"text\": \"evan\", \n",
    "            \"name\": \"NONE\",\n",
    "            \"arguments\": [] }\n",
    "            ]\n",
    "        \n",
    "        intention: {\n",
    "            \"speech_act\": \"wantBel\",\n",
    "            \"proposition\":\n",
    "                {\"text\": belonging\",\n",
    "                \"type\": \"concept\",\n",
    "                \"arguments\": [\"VAR0\", \"VAR1\"]}\n",
    "            }\n",
    "               \n",
    "            \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40f4a32",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b09c865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\r\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI,ChatAnthropic\n",
    "from langchain.chains import LLMChain\n",
    "import json\n",
    "\n",
    "!echo $OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652c69d8",
   "metadata": {},
   "source": [
    "# Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "382f737a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a list of dictionaries, and a key, return the entry in the list that matches\n",
    "def find_dict_in_list(lst, key, target):\n",
    "    for item in lst:\n",
    "        if not key in item:\n",
    "            #print(\"Key not in Dict\")\n",
    "            return None\n",
    "        if item[key] == target:\n",
    "            return item\n",
    "    #print(\"Nothing found\")\n",
    "    return None\n",
    "\n",
    "def find_all_dicts_in_list(lst, key, target):\n",
    "    output = []\n",
    "    for item in lst:\n",
    "        if not key in item:\n",
    "            return output\n",
    "        if item[key] == target:\n",
    "            output.append(item)\n",
    "    #print(\"Nothing found\")\n",
    "    return output\n",
    "    \n",
    "\n",
    "def clean_candidates(candidates):\n",
    "    \"\"\"\n",
    "    Cleans the list of candidates to extract a list of names and a list of scores of the candidates\n",
    "    \"\"\"\n",
    "    names = []\n",
    "    scores = []\n",
    "    for candidate in candidates:\n",
    "        name = candidate.split(\":\")[0]\n",
    "        score = float(candidate.split(\":\")[1])\n",
    "        names.append(name)\n",
    "        scores.append(score)\n",
    "        \n",
    "    return names, scores\n",
    "\n",
    "\n",
    "def prune_candidates(names, scores, threshold=0.75):\n",
    "    return [(x,y) for x,y in zip(names,scores) if y > threshold ]\n",
    "\n",
    "def select_best_candidate(names, scores, threshold=0.75):\n",
    "    \"\"\"\n",
    "    Selects best name and score above a threshold. \n",
    "    \"\"\"\n",
    "    pruned_names = []\n",
    "    pruned_scores = []\n",
    "    for n,s in zip(names,scores):\n",
    "        if s>threshold:\n",
    "            pruned_names.append(n)\n",
    "            pruned_scores.append(s)\n",
    "    \n",
    "    if pruned_names:\n",
    "        return pruned_names[pruned_scores.index(max(pruned_scores))]\n",
    "    return \"NONE\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae2ef044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More helper functions GMR\n",
    "\n",
    "def central_referent(gmr):\n",
    "    return find_dict_in_list(gmr['referents'], \"role\", \"central\")\n",
    "\n",
    "def supp_referents(gmr):\n",
    "    return find_all_dicts_in_list(gmr['referents'], \"role\", \"supplemental\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca542a0c",
   "metadata": {},
   "source": [
    "# Initialize LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7b3cdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.0)\n",
    "#llm = OpenAI(temperature=0.0)\n",
    "#llm = Anthropic(model=\"claude-instant-1.1-100k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1079388a",
   "metadata": {},
   "source": [
    "# Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "212e7678",
   "metadata": {},
   "outputs": [],
   "source": [
    "## (1) Speech Act Classification \n",
    "\n",
    "template_speech_act= \"\"\"\n",
    "Decide whether the utterance below from a speaker to a listener is one of \"want\", \"wantBel\", \"itk\"\n",
    "A \"want\" is an imperative statement or a request by the speaker to have the listener do an action or stop doing an action.\n",
    "An \"itk\" is a 'wh' or 'yes/no' query (what, why, when, where, who) or request from a speaker for more information from the listener about the listeners knowledge, beliefs or perceptions\n",
    "A \"wantBel\" (note the uppercase B) is a statement of fact or opinion that the speaker conveys to a listener and  expects to listener to come to believe. \n",
    "\n",
    "\n",
    "\n",
    "utterance: \\n{utterance}\\n\n",
    "act:\n",
    "\"\"\"\n",
    "\n",
    "prompt_speech_act = PromptTemplate(\n",
    "    input_variables=[\"utterance\"],\n",
    "    template=template_speech_act\n",
    ")\n",
    "\n",
    "chain_speech_act = LLMChain(llm=llm, prompt=prompt_speech_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be062373",
   "metadata": {},
   "outputs": [],
   "source": [
    "## (2) Central Referents \n",
    "\n",
    "template_centralref = \"\"\"\n",
    "What is the central item (which could be a single thing or a collection of things) that is being referred to in the below sentence?\n",
    "\n",
    "Remember, the central referent is a thing or object, not an action or descriptor.It is meant to capture the central real world item being referenced in the utterance. \n",
    "\n",
    "\n",
    "sentence: \\n{utterance}\\n \n",
    "referent:\n",
    "\"\"\"\n",
    "\n",
    "prompt_centralref = PromptTemplate(\n",
    "    input_variables=[\"utterance\"],\n",
    "    template=template_centralref\n",
    ")\n",
    "\n",
    "chain_centralref = LLMChain(llm=llm, prompt=prompt_centralref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f731b719",
   "metadata": {},
   "outputs": [],
   "source": [
    "## (3) Supporting Referents\n",
    "\n",
    "template_suppref = \"\"\"\n",
    "What are some objects (which could be a single thing or a collection of things) that is being referred to in the below sentence not including the central referent? Return as a python list.\n",
    "If none, then return empty list []. Even if only one item, return as a list.  \n",
    "Remember, the supporting referents are things or objects, not actions or descriptors. They are meant to capture the real world items being referenced in the utterance. \n",
    "\n",
    "Do NOT include objects or collections that have already been covered in the central referent. \n",
    "\n",
    "sentence: \\n{utterance}\\n \n",
    "central referent: \\n{centralref}\\n\n",
    "supporting referents (noun(s) from utterance):\n",
    "\"\"\"\n",
    "\n",
    "prompt_suppref = PromptTemplate(\n",
    "    input_variables=[\"utterance\", \"centralref\"],\n",
    "    template=template_suppref\n",
    ")\n",
    "\n",
    "chain_suppref = LLMChain(llm=llm, prompt=prompt_suppref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b95d451",
   "metadata": {},
   "outputs": [],
   "source": [
    "## (4) Getting the type of thing that the referents are \n",
    "\n",
    "template_typeof = \"\"\"\n",
    "Determine whether or not the referent item mentioned below in the context of the provided utterance is one of the types also provided below. To check if the referent is of a type, follow the below procedure\n",
    "1. Iterate through each item mentioned in the list of types. \n",
    "2. For each item X in the list of types expand on the meaning of each item, and then ask if the central referent is of type X given that meaning. \n",
    "3. If the central referent is of type X in the list, return X.\n",
    "\n",
    "\\n\\n EXAMPLE \\n\n",
    "utterance: The lemon is on the table\n",
    "referent: lemon\n",
    "types: ['area', 'physobj', 'location', 'pose']\n",
    "typeOf: Looking through the items in the list of types above. physobj is a physical object. lemon is a type of physical object. So, it is of type physobj\n",
    "\n",
    "Remember, return specifically ONE of the items in the list, or if none apply then return NONE. \n",
    "\n",
    "utterance: \\n{utterance}\\n\n",
    "referent: \\n{ref}\\n\n",
    "types: \\n{types}\\n\n",
    "typeOf:\n",
    "\"\"\"\n",
    "\n",
    "prompt_typeof = PromptTemplate(\n",
    "    input_variables=[\"ref\", \"types\", \"utterance\"],\n",
    "    template=template_typeof\n",
    ")\n",
    "\n",
    "chain_typeof = LLMChain(llm=llm, prompt=prompt_typeof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2261958",
   "metadata": {},
   "outputs": [],
   "source": [
    "## (5) Extract CPC\n",
    "\n",
    "template_cpc = \"\"\"\n",
    "Determine the core propositional content (cpc) of the utterance below in the context of its central referent and speech act type\n",
    "To do so, use the following procedure\n",
    "\n",
    "1. Determine the type of cpc (\"action\", \"concept\") associated with the utterance.\n",
    "If the speech act is a \"want\" that means the utterance is an imperative and the cpc is an \"action\".\n",
    "If the speech act is a \"wantBel\" (note the capital B) that means the utterance is a statement assertion, and the cpc will be a \"concept\"\n",
    "If the speech act is an \"itk\" that means the utterance contains a question about some concept, so the cpc is a \"concept\"\n",
    "\n",
    "2. If the type of cpc is an \"action\", then the core propositional content (or cpc) is the action that is being performed on the central referent.\n",
    "If the type of cpc is a \"concept\", then the core propositional content (or cpc) is a concept that is being associated with the central referent.\n",
    "\n",
    "3. Convert the cpc into a single representative word that captures its meaning, without any reference to the referents.\n",
    "\n",
    "4. return the converted cpc and its type in the following format \"<CPC>:<TYPE>\" \n",
    "\n",
    "utterance: \\n{utterance}\\n\n",
    "speech act: \\n{speechact}\\n\n",
    "central referent: \\n{centralref}\n",
    "core propositional content and:\n",
    "\"\"\"\n",
    "\n",
    "prompt_cpc = PromptTemplate(\n",
    "    input_variables=[\"centralref\", \"utterance\",\"speechact\"],\n",
    "    template=template_cpc\n",
    ")\n",
    "\n",
    "chain_cpc = LLMChain(llm=llm, prompt=prompt_cpc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce026e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## (6) Candidate Real Actions \n",
    "## \"Real\" == actions implemented in the robot system. \n",
    "\"\"\"\n",
    "Approach: look to see if there exists an action that captures this.\n",
    "\n",
    "Criteria\n",
    "(1) Semantic similarity of Name \n",
    "(2) The arguments in the robot action exist in the linguistic parse. If not then we are either in the wrong action or we are missing an action\n",
    "\"\"\"\n",
    "\n",
    "template_candidate_realactions =\"\"\"\n",
    "Select a list of 5 candidate actions from the list of available actions that is most relevant to the core action performed on the central referent as understood in the context of the utterance. \n",
    "\n",
    "To decide the list of applicable candidate actions, use the following procedure to systematically filter the list of available actions:\n",
    "1. Compare the name and description (if any) of each action in the available actions to the core action. Narrow the list of actions to include only those with a semantically similar name or description to the central action. \n",
    "2. Return the narrowed list of actions as a python list of string action names followed by a colon and then a numeric score between 0 and 1 signifying the semantic similarity between the name or description and the central action.\n",
    "For example \"move:0.5\" where \"move\" is the action name and 0.5 is the similarity score. \n",
    "\n",
    "\\n\\n LIST OF AVAILABLE ACTIONS \\n:\n",
    "{actions}\n",
    "\n",
    "utterance: \\n{utterance}\\n\n",
    "central referent: \\n{centralref}\\n\n",
    "core action: \\n{cpc}\\n\n",
    "candidate actions:\n",
    "\"\"\"\n",
    "\n",
    "prompt_candidate_realactions = PromptTemplate(\n",
    "    input_variables=[\"centralref\", \"utterance\",\"cpc\", \"actions\"],\n",
    "    template=template_candidate_realactions\n",
    ")\n",
    "\n",
    "chain_candidate_realactions = LLMChain(llm=llm, prompt=prompt_candidate_realactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "986ae067",
   "metadata": {},
   "outputs": [],
   "source": [
    "## (7) Tether Real Action\n",
    "# provided a list of realarguments, bind referents to them. \n",
    "\n",
    "template_bound_action = \"\"\"\n",
    "Try to bind the candidate action's arguments to the central and supplementary referents. Use the following procedure:\n",
    "1. Look at the candidate action's arguments in order written as \"VAR<NUM>:<TYPE>\". If the first argument is of TYPE \"agent\", then bind that to \"self\".\n",
    "2. For the second argument (if it exists), if the central referent is an object of  type TYPE in the argument, then bind the central referent to the TYPE. If not, bind to NONE. \n",
    "3. For  any subsequent arguments, attempt to bind the supplementary referents in the same way. \n",
    "4. Return output as a python dictionary, with following format (Do NOT include any special characters like newlines):\n",
    "\"name\": \"<NAME OF THE ACTION>\",\"bindings\": [{{\"<VARIABLE NAME (E.g.VAR0)>\": \"<REFERENT>\"}}, ...]\n",
    "\n",
    "\n",
    "utterance: \\n{utterance}\\n\n",
    "central referent: \\n{centralref}\\n\n",
    "supplementary referents: \\n{supprefs}\\n\n",
    "candidate action: \\n{candidate_full_info}\\n\n",
    "bound action:\n",
    "\"\"\"\n",
    "\n",
    "prompt_bound_action = PromptTemplate(\n",
    "    input_variables=[\"centralref\", \"supprefs\", \"utterance\",\"candidate_full_info\"],\n",
    "    template=template_bound_action\n",
    ")\n",
    "\n",
    "chain_bound_action = LLMChain(llm=llm, prompt=prompt_bound_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f16d7de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## (6b) Candidate Real Concepts\n",
    "## \"Real\" == concepts understandable to a robotic system (some consultant exists for it)\n",
    "\"\"\"\n",
    "Approach: look to see if there exists an action that captures this.\n",
    "\n",
    "Criteria\n",
    "(1) Semantic similarity of Name \n",
    "(2) The arguments in the concept exist in the linguistic parse. If not then we are either in the wrong action or we are missing an action\n",
    "\"\"\"\n",
    "\n",
    "template_candidate_realconcepts=\"\"\"\n",
    "Select a list of 5 candidate concept from the list of available concepts that is most relevant to the core concept associated with the central referent as understood in the context of the utterance. \n",
    "\n",
    "To decide the list of applicable candidate concepts, use the following procedure to systematically filter the list of available concepts:\n",
    "1. Compare the name and description (if any) of each concept in the available concepts to the core concepts. Narrow the list of concepts to include only those with a semantically similar name or description to ONLY the core concept. \n",
    "2. Return the narrowed list of concepts as a python list of string concept names followed by a colon and then a numeric score between 0 and 1 signifying the semantic similarity between the name or description of the available concepts and the core concept. Do NOT return this as a dictionary\n",
    "\n",
    "\\n\\n LIST OF AVAILABLE CONCEPTS \\n:\n",
    "{concepts}\n",
    "\n",
    "utterance: \\n{utterance}\\n\n",
    "central referent: \\n{centralref}\\n\n",
    "core concept: \\n{cpc}\\n\n",
    "candidate concepts:\n",
    "\"\"\"\n",
    "\n",
    "prompt_candidate_realconcepts = PromptTemplate(\n",
    "    input_variables=[\"centralref\", \"utterance\",\"cpc\", \"concepts\"],\n",
    "    template=template_candidate_realconcepts\n",
    ")\n",
    "\n",
    "chain_candidate_realconcepts = LLMChain(llm=llm, prompt=prompt_candidate_realconcepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29e8d37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## (7b) Tether Real Concept, if available\n",
    "# provided a list of realarguments, bind referents to them. \n",
    "\n",
    "template_bound_concept = \"\"\"\n",
    "Try to bind each candidate concept's arguments to the central and supplementary referents. Use the following procedure:\n",
    "For each candidate concept: \n",
    "1. Look at its arguments in order written as \"VAR<NUM>:<TYPE>\". If the first argument is of TYPE \"agent\", then bind that to \"self\".\n",
    "2. For the second argument (if it exists), if the central referent is an object of  type TYPE in the argument, then bind the central referent to the TYPE. If not, bind to NONE. \n",
    "3. For  any subsequent arguments, attempt to bind the supplementary referents in the same way. \n",
    "4. Return output as a python dictionary, with following format (Do NOT include any special characters like newlines):\n",
    "\"name\": \"<NAME OF THE CONCEPT>\",\"bindings\": [{{\"<VARIABLE NAME (E.g.VAR0)>\": \"<REFERENT>\"}}, ...]\n",
    "\n",
    "utterance: \\n{utterance}\\n\n",
    "central referent: \\n{centralref}\\n\n",
    "supplementary referents: \\n{supprefs}\\n\n",
    "candidate concepts: \\n{candidate_full_info}\\n\n",
    "bound concept:\n",
    "\"\"\"\n",
    "\n",
    "prompt_bound_concept = PromptTemplate(\n",
    "    input_variables=[\"centralref\", \"supprefs\", \"utterance\",\"candidate_full_info\"],\n",
    "    template=template_bound_concept\n",
    ")\n",
    "\n",
    "chain_bound_concept = LLMChain(llm=llm, prompt=prompt_bound_concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "caa8ca34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (8) Novel concept induction\n",
    "\n",
    "template_novel_concept = \"\"\"\n",
    "Generate a concept template for the core concept within the context of the utterance. Use the following procedure:\n",
    "\n",
    "1. Extract a concept name. The name can be from the core concept itself. \n",
    "2. Generate a list of arguments, where each argument states the type of argument that can be bound to the concept.\n",
    "Here, we want to make sure that each argument type makes sense for the concept, and also can be bound to the central referent and zero or more of the supplemental references.\n",
    "\n",
    "Return output as a python dictionary, with following format (Do NOT include any special characters like newlines):\n",
    "\"name\": \"<NAME OF THE CORE CONCEPT>\",\"roles\": [{{\"<VARIABLE NAME (E.g.VAR0)>\": \"<TYPE>\"}}, ...]\n",
    "\n",
    "\n",
    "utterance: \\n{utterance}\\n\n",
    "core concept: \\n{cpc}\\n\n",
    "types: \\n{types}\\n\n",
    "central referent: \\n{centralref}\\n\n",
    "supplementary referents: \\n{supprefs}\\n\n",
    "novel concept: \n",
    "\"\"\"\n",
    "\n",
    "prompt_novel_concept = PromptTemplate(\n",
    "    input_variables=[\"centralref\", \"supprefs\", \"utterance\", \"cpc\", \"types\"],\n",
    "    template=template_novel_concept\n",
    ")\n",
    "\n",
    "chain_novel_concept = LLMChain(llm=llm, prompt=prompt_novel_concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7cefa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (9) SPC Property Candidate identification \n",
    "## getting the properties of interest\n",
    "## For each of the referents, we want to find any individual descriptors, we also want to find and apply any given relations between referents\n",
    "\n",
    "template_properties = \"\"\"\n",
    "Determine the properties of the referents. Use the following procedure for each of the referents:\n",
    "1. The names of each of the referents itself should be added as a property to the list.\n",
    "2. From the utterance, extract all the adjectival descriptors used to describe the properties of the referents, and add to list.\n",
    "3. Add to this list, any relations (mentioned in the utterance) between two or more of the referents. Do NOT include any relations that can be reasonably assumed to be already covered by the meaning of the core propositional content. \n",
    "4. Return this list as a list of python dictionaries with the following format:\n",
    "\"text\": <NAME OF PROPERTY/DESCRIPTOR/RELATION>, \"arguments\": <LIST OF VARIABLE NAMES> \n",
    "\n",
    "where the variable names correspond to the variable names associated with each of the referents. Remember, the variable names have to be correct.\n",
    "\n",
    "Remember, DO NOT include in the list anything that is semantically similar to the core propositional content since it would be redundant\n",
    "\n",
    "utterance: \\n{utterance}\\n\n",
    "referents: \\n{referent_info}\\n\n",
    "core propositional content: \\n{cpc}\\n\n",
    "supplemental properties, descriptors and relations not in the core propositional content:\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "prompt_properties = PromptTemplate(\n",
    "    input_variables=[\"referent_info\", \"utterance\", \"cpc\"],\n",
    "    template=template_properties\n",
    ")\n",
    "\n",
    "chain_properties = LLMChain(llm=llm, prompt=prompt_properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87ebc922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (10) Candidate real properties: Find the properties (SPCs) in the consultant properties. THese are things the robot perception/cognition can understand\n",
    "## \"Real\" == concepts understandable to a robotic system (some consultant exists for it)\n",
    "\n",
    "template_candidate_realprops=\"\"\"\n",
    "Select a list of 5 candidate concept from the list of available concepts that is most semantically similar to the property associated with the referent, as understood in the context of the utterance. \n",
    "\n",
    "To decide the list of applicable candidate concepts, use the following procedure to systematically filter the list of available concepts:\n",
    "1. Compare the name and description (if any) of each concept in the available concepts to the properties. Narrow the list of concepts to include only those with a semantically similar name or description to ONLY the property. \n",
    "2. Return the narrowed list of concepts as a python list of string concept names followed by a colon and then a numeric score between 0 and 1 signifying the semantic similarity between the name or description of the available concepts and the property.\n",
    " Do NOT return this as a dictionary\n",
    " \n",
    "\\n\\n LIST OF AVAILABLE CONCEPTS \\n:\n",
    "{concepts}\n",
    "\n",
    "utterance: \\n{utterance}\\n\n",
    "property: \\n{prop}\\n\n",
    "candidate concepts:\n",
    "\"\"\"\n",
    "\n",
    "prompt_candidate_realprops = PromptTemplate(\n",
    "    input_variables=[\"utterance\",\"prop\", \"concepts\"],\n",
    "    template=template_candidate_realprops\n",
    ")\n",
    "\n",
    "chain_candidate_realprops = LLMChain(llm=llm, prompt=prompt_candidate_realprops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b884a191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (11) Cognitive Status\n",
    "\n",
    "template_cognitive_status= \"\"\"\n",
    "Determine the cognitive status of each of the referents mentioned in the bindings. Use the following procedure for each of the referents:\n",
    "\n",
    "1. Decide which ONE (and only one) of the following five cognitive statuses the referents could fall into:\n",
    "statuses: [INFOCUS, ACTIVATED\", FAMILIAR, DEFINITE, INDEFINITE]\n",
    "\n",
    "As shown in the table below, the Givenness Hierarchy is comprised of six hierarchically nested tiers of cognitive status, \n",
    "where information with one cognitive status can be inferred to also have all\n",
    "lower statuses. Each level of the GH is “cued” by a set\n",
    "of linguistic forms, as seen in the table. For example, the second\n",
    "row of the table shows that the definite use of “this” can be\n",
    "used to infer that the speaker assumes the referent to be at\n",
    "least activated to their interlocutor.\n",
    "\\n\\n\n",
    "Cognitive Status | Mnemonic Status | Form |\n",
    "-----------------|-----------------|------|\n",
    "INFOCUS | in the focus of attention | it |\n",
    "ACTIVATED | in short term memory | this,that,this N |\n",
    "FAMILIAR | in long term memory| that N |\n",
    "DEFINITE | in long term memory  or new | the N |\n",
    "INDEFINITE | new or hypothetical | a N |\n",
    "\\n\\n\n",
    "\n",
    "When deciding the one cognitive status for each referent, use the table above and compare the form (pronoun, determiner, article) of the utterance to its status.\n",
    "\n",
    "Return this as a python dictionary using the following format for the dictionary entry. Note it MUST be a python dictionary\n",
    "<VARIABLE NAME> : <COGNITIVE STATUS>\n",
    "\n",
    "where the variable names correspond to the variable names associated with each of the referents. Remember, the variable names have to be correct.\n",
    "\n",
    "\n",
    "utterance: \\n{utterance}\\n\n",
    "referents: \\n{referent_info}\\n\n",
    "cognitive statuses:\n",
    "\"\"\"\n",
    "\n",
    "prompt_cognitive_status = PromptTemplate(\n",
    "    input_variables=[\"referent_info\", \"utterance\"],\n",
    "    template=template_cognitive_status\n",
    ")\n",
    "\n",
    "chain_cognitive_status = LLMChain(llm=llm, prompt=prompt_cognitive_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe7615a",
   "metadata": {},
   "source": [
    "# Overall Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f185e3f",
   "metadata": {},
   "source": [
    "### Extract referents and intentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "719ac1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import string\n",
    "\n",
    "SIMILARITY_THRESHOLD = 0.8\n",
    "\n",
    "def extract_referents_intention(utterance):\n",
    "    \n",
    "    # Initialize the important datastructures\n",
    "    referents = []\n",
    "    intention = {}\n",
    "    descriptors = []\n",
    "    \n",
    "    # 1. Speech Act classification\n",
    "    print(f\"\\nProcessing utterance: {utterance}\")\n",
    "    print(\"[ ] Classifying speech act\", end=\"\\r\")\n",
    "    speech_act = chain_speech_act.run(utterance=utterance).lower() #string name \"want\" or \"wantBel\"\n",
    "    print(\"[X] Classifying speech act\")\n",
    "\n",
    "    intention['speech_act'] = speech_act\n",
    "    \n",
    "    \n",
    "    # 2. Central Referent Extraction\n",
    "    print(\"[ ] Extracting referents\", end=\"\\r\")\n",
    "    centralref = chain_centralref.run(utterance=utterance).lower()\n",
    "    centralref_type = chain_typeof.run(ref=centralref, types=types, utterance=utterance ).split(\" \")[-1]\n",
    "    centralref_type = centralref_type.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    referents.append({\"text\": centralref, \n",
    "                      \"type\":centralref_type, \n",
    "                      \"role\": \"central\"})\n",
    "    \n",
    "    \n",
    "    # 3. Supporting Referents Extraction\n",
    "    supprefs = chain_suppref.run(utterance=utterance, centralref=centralref).lower()\n",
    "    supprefs = ast.literal_eval(supprefs)\n",
    "    \n",
    "    #supprefs_full = [] #with type info\n",
    "    if supprefs:\n",
    "        for suppref in supprefs:\n",
    "            suppref_type = chain_typeof.run(ref=suppref, types=types, utterance=utterance ).split(\" \")[-1]\n",
    "            #supprefs_full.append(f\"{suppref}:{suppref_type}\")\n",
    "            \n",
    "            referents.append({\"text\": suppref, \n",
    "                              \"type\": suppref_type, \n",
    "                              \"role\": \"supplemental\"})\n",
    "            \n",
    "            \n",
    "    print(\"[X] Extracting referents\")\n",
    "    print(f\"Referents: {json.dumps(referents, indent=2)}\")\n",
    "\n",
    "    # 4. CPC extraction \n",
    "    \n",
    "    print(\"[ ] Extracting CPC\", end=\"\\r\")\n",
    "    cpc = chain_cpc.run(utterance=utterance, speechact=speech_act, centralref=centralref)\n",
    "    \n",
    "    intention['proposition'] = {\"text\": cpc.split(\":\")[0], \n",
    "                               \"type\": cpc.split(\":\")[-1]}\n",
    "    \n",
    "    \n",
    "    print(\"[X] Extracting CPC\")\n",
    "    print(f\"Intention: {json.dumps(intention, indent=2)}\")\n",
    "    \n",
    "    # Groundable meaning representation\n",
    "    gmr = {'referents': referents, \n",
    "           'intention': intention,\n",
    "           'descriptors': descriptors}\n",
    "    return gmr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d2cedd",
   "metadata": {},
   "source": [
    "### For requests: bind action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19b93d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bind_action(utterance, gmr, robot_model):\n",
    "    \"\"\"\n",
    "    1. Find candidate actions in robot's model repertoire\n",
    "    2. Select most similar one (based on name and description)\n",
    "    3. Bind the referents to this selected one \n",
    "    4. Update referents list \n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Find Candidates in the robot's action repertoire\n",
    "    print(\"[ ]Finding Candidate actions\", end=\"\\r\")\n",
    "    candidates = chain_candidate_realactions.run(utterance=utterance, \n",
    "                                                   centralref=central_referent(gmr),\n",
    "                                                   cpc=gmr['intention']['proposition']['text'],\n",
    "                                                   actions=robot_model['actions']) \n",
    "    candidates = ast.literal_eval(candidates)\n",
    "    print(\"[X] Finding Candidate actions\")\n",
    "    print(f\"\\tCandidate actions: {candidates}\")\n",
    "    \n",
    "    \n",
    "    # 2. Select best candidate\n",
    "    print(\"[ ] Selecting best candidate\", end=\"\\r\")\n",
    "    names, scores = clean_candidates(candidates)\n",
    "    best_candidate_name = select_best_candidate(names=names, scores=scores, threshold=SIMILARITY_THRESHOLD)\n",
    "    print(\"[X] Selecting best candidate\")\n",
    "    print(f\"\\tBest candidate action name: {best_candidate_name}\")\n",
    "    \n",
    "    # 3. Bind the referents to the selected best candidate\n",
    "    print(\"[ ] Binding best candidate\", end=\"\\r\")\n",
    "    bound_candidate=None\n",
    "    if not \"NONE\" in best_candidate_name:\n",
    "        # Bind best candidate to a real action   \n",
    "        print(f\"Central ref: {central_referent(gmr)}\")\n",
    "        bound_candidate = chain_bound_action.run(utterance=utterance,\n",
    "                                              centralref=central_referent(gmr),\n",
    "                                              supprefs=supp_referents(gmr),\n",
    "                                              candidate_full_info=find_dict_in_list(robot_model['actions'], \n",
    "                                                                                     \"name\", \n",
    "                                                                                     best_candidate_name))\n",
    "        # check if bound_candidate contains a \"NONE\"\n",
    "        if \"NONE\" in bound_candidate:\n",
    "            print(f\"We have a problem. There is a unbound variable here:\\n{bound_candidate}\")\n",
    "\n",
    "        # eval string\n",
    "        bound_candidate = ast.literal_eval(bound_candidate)\n",
    "        \n",
    "        print(\"[X] Binding best candidate\")\n",
    "        print(f\"\\tBound candidate: {bound_candidate}\")\n",
    "        \n",
    "        \n",
    "        # 4. Update referents and intention object \n",
    "        for referent in gmr['referents']:\n",
    "            for binding in bound_candidate['bindings']:           \n",
    "                if list(binding.values())[0] == referent['text']:\n",
    "                    referent['variable_name'] = list(binding.keys())[0]\n",
    "\n",
    "        # 4b. Update intentions object            \n",
    "        arguments = []    \n",
    "        for binding in bound_candidate['bindings']:  \n",
    "            if list(binding.values())[0] == \"self\":\n",
    "                arguments.append(\"self\") \n",
    "            else:\n",
    "                arguments.append(list(binding.keys())[0])        \n",
    "\n",
    "        gmr['intention']['proposition']['arguments'] = arguments\n",
    "        gmr['intention']['proposition']['name'] = bound_candidate['name']\n",
    "        \n",
    "    \n",
    "    return gmr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd37e052",
   "metadata": {},
   "source": [
    "### For statements/assertions: bind concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d31fde9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bind_concept(utterance, gmr, robot_model):\n",
    "    \"\"\"\n",
    "    1. Find candidate concepts in robot's model repertoire together with similarity scores\n",
    "    2. Choose the best found one \n",
    "    3. if the best one is below the similarity threshold, then create a novel concept\n",
    "    4. Bind the referents to either found concept or novel concept candidate\n",
    "    5. Update referent list and intention\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Find candidates in the robot's conceptual and perceptual repertoire \n",
    "    ## (look up consultant properties and belief rules, unless Belief is also a consultant)\n",
    "    print(\"[ ] Finding Candidate concepts\", end=\"\\r\")\n",
    "    candidates = chain_candidate_realconcepts.run(utterance=utterance, \n",
    "                                                   centralref=central_referent(gmr),\n",
    "                                                   cpc=gmr['intention']['proposition']['text'],\n",
    "                                                   concepts=robot_model['concepts']) \n",
    "    candidates = ast.literal_eval(candidates)\n",
    "    print(\"[X] Finding Candidate concepts\")\n",
    "    print(f\"\\tCandidates: {candidates}\")\n",
    "    \n",
    "    \n",
    "    # 2. Select best candidate above a threshold\n",
    "    print(f\"[ ] Selecting best candidate above similarity of {SIMILARITY_THRESHOLD}\", end=\"\\r\")\n",
    "    names, scores = clean_candidates(candidates)\n",
    "    best_candidate_name = select_best_candidate(names=names, scores=scores, threshold=SIMILARITY_THRESHOLD)\n",
    "    print(f\"[X] Selecting best candidate above similarity of {SIMILARITY_THRESHOLD}\")\n",
    "    print(f\"\\tBest candidate concept name: {best_candidate_name}\")\n",
    "    \n",
    "\n",
    "    bound_candidate = None\n",
    "    if not \"none\" in best_candidate_name.lower(): #Case where a property detector exists in the consultants\n",
    "        # Bind best candidate to a real concept\n",
    "        print(\"[ ] Binding best candidate concept\", end=\"\\r\")\n",
    "        bound_candidate = chain_bound_concept.run(utterance=utterance,\n",
    "                                              centralref=central_referent(gmr),\n",
    "                                              supprefs=supp_referents(gmr),\n",
    "                                              candidate_full_info=find_dict_in_list(robot_model['concepts'], \n",
    "                                                                                     \"name\", \n",
    "                                                                                     best_candidate_name))\n",
    "        \n",
    "        # check if bound_candidate contains a \"NONE\"\n",
    "        if \"NONE\" in bound_candidate:\n",
    "            print(f\"We have a problem. There is a unbound variable here:\\n{bound_candidate}\")\n",
    "\n",
    "        # eval string\n",
    "        bound_candidate = ast.literal_eval(bound_candidate)\n",
    "        print(\"[X] Binding best candidate\")\n",
    "        print(f\"\\tBound candidate: {bound_candidate}\")\n",
    "        \n",
    "    else: # Case of novel concept\n",
    "        \n",
    "        # need to hypothesize a name and arguments. \n",
    "        print(\"[ ] Instantiating novel concept\", end=\"\\r\")\n",
    "        new_concept = chain_novel_concept.run(utterance=utterance,\n",
    "                                             types=robot_model['types'],\n",
    "                                             centralref=central_referent(gmr),\n",
    "                                             supprefs=supp_referents(gmr),\n",
    "                                             cpc=gmr['intention']['proposition']['text'])\n",
    "\n",
    "        new_concept = ast.literal_eval(new_concept)\n",
    "        print(\"[X] Instantiating novel concept\")\n",
    "\n",
    "        print(\"[ ] Binding novel concept\", end=\"\\r\")\n",
    "        bound_candidate = chain_bound_concept.run(utterance=utterance,\n",
    "                                              centralref=central_referent(gmr),\n",
    "                                              supprefs=supp_referents(gmr),\n",
    "                                              candidate_full_info=find_dict_in_list([new_concept], \n",
    "                                                                                     \"name\", \n",
    "                                                                                     new_concept['name']))\n",
    "\n",
    "        print(\"[X] Binding novel concept\")\n",
    "\n",
    "        # check if bound_candidate contains a \"NONE\"\n",
    "        if \"NONE\" in bound_candidate:\n",
    "            print(f\"We have a problem. There is a unbound variable here:\\n{bound_candidate}\")\n",
    "\n",
    "        bound_candidate = ast.literal_eval(bound_candidate)\n",
    "    \n",
    "    if not bound_candidate:\n",
    "        print(\"\\nERROR!!!\\n\")\n",
    "        return gmr\n",
    "    \n",
    "    # 4. Update referents and intention object \n",
    "    for referent in gmr['referents']:\n",
    "        for binding in bound_candidate['bindings']:           \n",
    "            if list(binding.values())[0] == referent['text']:\n",
    "                referent['variable_name'] = list(binding.keys())[0]\n",
    "    \n",
    "    # 4b. Update intentions object            \n",
    "    arguments = []    \n",
    "    for binding in bound_candidate['bindings']:  \n",
    "        if list(binding.values())[0] == \"self\":\n",
    "            arguments.append(\"self\") \n",
    "        else:\n",
    "            arguments.append(list(binding.keys())[0])        \n",
    "    \n",
    "    gmr['intention']['proposition']['arguments'] = arguments\n",
    "    gmr['intention']['proposition']['name'] = bound_candidate['name']\n",
    "    \n",
    "    return gmr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596ef28c",
   "metadata": {},
   "source": [
    "### Extract descriptors and referential properties and relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9cc2278a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_supplementals(utterance, gmr, robot_model):\n",
    "\n",
    "    # 1. Getting candidate properties from language\n",
    "    print(\"[ ] Extracting Properties\", end=\"\\r\")\n",
    "    spc = chain_properties.run(utterance=utterance,\n",
    "                                     referent_info=gmr['referents'],\n",
    "                              cpc=gmr['intention']['proposition'])\n",
    "    descriptors = ast.literal_eval(spc)\n",
    "    print(\"[X] Extracting Properties\")\n",
    "    print(f\"\\tDescriptors: {descriptors}\")\n",
    "    \n",
    "    # 2. Finding consultant properties that match the identified spc \n",
    "    print(\"[ ] Finding Consultant properties similar to each of the Descriptors\", end=\"\\r\")\n",
    "    props_all = []\n",
    "    for descriptor in descriptors:\n",
    "    \n",
    "        ## 2.a. Get some candidate matches from the robot's perceptual/conceptual repertoire (Concepts)\n",
    "        candidates = chain_candidate_realprops.run(utterance=utterance,\n",
    "                                                                   concepts=robot_model['concepts'],\n",
    "                                                                   prop=descriptor )\n",
    "        candidates = ast.literal_eval(candidates)\n",
    "        print(f\"Debug: candidates: {candidates}\")\n",
    "        # 2.b. Pick the best one that is also above a threshold\n",
    "        names, scores = clean_candidates(candidates)\n",
    "        best_candidate_name = select_best_candidate(names=names, scores=scores, threshold=SIMILARITY_THRESHOLD)\n",
    "\n",
    "            \n",
    "        descriptor['name'] = best_candidate_name\n",
    "        \n",
    "    print(\"[X] Finding Consultants properties similar to SPC\")    \n",
    "    \n",
    "    gmr['descriptors'] = descriptors\n",
    "    \n",
    "    return gmr\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "de61aa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_cognitive_status(utterance, gmr, robot_model):\n",
    "    print(\"[ ] Classifying cognitive status\", end=\"\\r\")\n",
    "    cognitive_statuses = chain_cognitive_status.run(utterance=utterance,\n",
    "                                                   referent_info=gmr['referents'])\n",
    "    \n",
    "    cognitive_statuses = ast.literal_eval(cognitive_statuses)\n",
    "    print(\"[X] Classifying cognitive status\")\n",
    "    print(f\"\\tCognitive Status: {cognitive_statuses}\")\n",
    "    \n",
    "    \n",
    "    for ref in gmr['referents']:\n",
    "        if \"variable_name\" in ref:\n",
    "            varname = ref['variable_name']\n",
    "            status = cognitive_statuses[varname]\n",
    "            ref['cognitive_status'] = status\n",
    "    \n",
    "    return gmr\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c22a37b",
   "metadata": {},
   "source": [
    "### Generate the actual parse from the GMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "47abc5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_parse(gmr, speaker):\n",
    "    \n",
    "    # Build the CPC\n",
    "    if 'name' in gmr['intention']['proposition']:\n",
    "        cpc_template = \"{cpc_name}({cpc_variables})\"\n",
    "        cpc = cpc_template.format(cpc_name=gmr['intention']['proposition']['name'],\n",
    "                                 cpc_variables=\",\".join(gmr['intention']['proposition']['arguments']))\n",
    "    else:\n",
    "        cpc = \"NONE\"\n",
    "    \n",
    "                              \n",
    "    # Build the SPC\n",
    "    spcs = []\n",
    "    spc_template = \"{spc_name}({spc_variables})\"\n",
    "    for descriptor in gmr['descriptors']:\n",
    "        spc_predicate = spc_template.format(spc_name=descriptor['name'],\n",
    "                                     spc_variables=\",\".join(descriptor['arguments']))\n",
    "        spcs.append(spc_predicate)\n",
    "    \n",
    "    for ref in gmr['referents']:\n",
    "        if 'variable_name' in ref and 'cognitive_status' in ref:\n",
    "            spc_predicate = spc_template.format(spc_name=ref['cognitive_status'],\n",
    "                                         spc_variables=ref['variable_name'])\n",
    "            spcs.append(spc_predicate)\n",
    "                      \n",
    "    spc_all = \",\".join(spcs)                        \n",
    "                              \n",
    "    \n",
    "    final_template = \"{speech_act}({speaker},{cpc},{{{spcs}}})\"\n",
    "    parsed = final_template.format(speech_act=gmr['intention']['speech_act'],\n",
    "                                  speaker=speaker,\n",
    "                                  cpc=cpc,\n",
    "                                  spcs=spc_all)\n",
    "    \n",
    "    return parsed\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d713892b",
   "metadata": {},
   "source": [
    "### Overall Parsing Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6956592a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall Algorithm\n",
    "def parse(utterance, robot_model):\n",
    "    \n",
    "    gmr = extract_referents_intention(utterance)\n",
    "    if gmr['intention']['proposition']['type'] == \"action\":\n",
    "        gmr = bind_action(utterance, gmr, robot_model)\n",
    "    elif gmr['intention']['proposition']['type'] == \"concept\":\n",
    "        gmr = bind_concept(utterance, gmr, robot_model)\n",
    "    gmr = extract_supplementals(utterance, gmr, robot_model)\n",
    "    \n",
    "    gmr = classify_cognitive_status(utterance, gmr, robot_model)\n",
    "    \n",
    "    parsed = generate_parse(gmr, \"brad\")\n",
    "    output = {\"utterance\": utterance,\n",
    "                   \"robot_model\": robot_model,                  \n",
    "                   \"parse\": parsed,\n",
    "                   \"gmr\": gmr}\n",
    "    \n",
    "    print(f\"Utterance: {utterance}\")\n",
    "    print(f\"PARSE: {parsed}\")\n",
    "    \n",
    "    return output\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66264c3c",
   "metadata": {},
   "source": [
    "# Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "babe67c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available utterances: ['then assemble the screw feeder', 'that m3 screw belongs to Evan', 'screw the m3 into that bottle on the conveyor', 'that m3 screw can couple with the conveyor']\n"
     ]
    }
   ],
   "source": [
    "# Construct Sample dev dataset \n",
    "import json \n",
    "\n",
    "with open(\"../data/actions_short.json\", \"r\") as f:\n",
    "    actions_dev = json.load(f)\n",
    "with open(\"../data/properties.json\", \"r\") as f:\n",
    "    concepts_dev = json.load(f)\n",
    "types = [\"physobj\", \"agent\", \"location\", \"pose\", \"action\", \"number\", \"direction\", \"name\", \"string\"]\n",
    "\n",
    "utterances = [\"then assemble the screw feeder\",\n",
    "             \"that m3 screw belongs to Evan\",\n",
    "             \"screw the m3 into that bottle on the conveyor\",\n",
    "             \"that m3 screw can couple with the conveyor\"]\n",
    "\n",
    "dataset = []\n",
    "for utt in utterances:\n",
    "    item = {\"utterance\": utt,\n",
    "            \"robot_model\": {\n",
    "                \"actions\": actions_dev,\n",
    "                \"concepts\": concepts_dev,\n",
    "                \"types\": types}\n",
    "           }\n",
    "    dataset.append(item)\n",
    "\n",
    "print(f\"Available utterances: {utterances}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cdff3d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing utterance: that m3 screw belongs to Evan\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"m3 screw\",\n",
      "    \"type\": \"physobj\",\n",
      "    \"role\": \"central\"\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"evan\",\n",
      "    \"type\": \"name\",\n",
      "    \"role\": \"supplemental\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"wantbel\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"belonging\",\n",
      "    \"type\": \"concept\"\n",
      "  }\n",
      "}\n",
      "[X] Finding Candidate concepts\n",
      "\tCandidates: ['hole:0.2', 'deepM3:0.6', 'prop:0.3', 'bottle:0.1', 'work area:0.4']\n",
      "[X] Selecting best candidate above similarity of 0.8\n",
      "\tBest candidate concept name: NONE\n",
      "[X] Instantiating novel concept\n",
      "[X] Binding novel concept\n",
      "[X] Extracting Properties\n",
      "\tDescriptors: [{'text': 'm3 screw', 'arguments': ['VAR0']}, {'text': 'Evan', 'arguments': ['VAR1']}]\n",
      "Debug: candidates: ['m3: 1', 'deepM3: 0.8', 'screw feeder: 0.6', 'prop: 0.2', 'bottle: 0.1']\n",
      "Debug: candidates: ['m3: 0.8', 'deepM3: 0.7', 'prop: 0.3', 'bottle: 0.2', 'nfsv: 0.1']\n",
      "[X] Finding Consultants properties similar to SPC\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'VAR0': 'ACTIVATED', 'VAR1': 'FAMILIAR'}\n",
      "Utterance: that m3 screw belongs to Evan\n",
      "PARSE: wantbel(brad,belonging(VAR0,VAR1),{m3(VAR0),NONE(VAR1),ACTIVATED(VAR0),FAMILIAR(VAR1)})\n"
     ]
    }
   ],
   "source": [
    "idx = 1\n",
    "output = parse(utterance=dataset[idx]['utterance'],robot_model=dataset[idx]['robot_model'])\n",
    "#print(json.dumps(out, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e8cd1699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'referents': [{'text': 'm3 screw',\n",
       "   'type': 'physobj',\n",
       "   'role': 'central',\n",
       "   'variable_name': 'VAR0',\n",
       "   'cognitive_status': 'ACTIVATED'},\n",
       "  {'text': 'evan',\n",
       "   'type': 'name',\n",
       "   'role': 'supplemental',\n",
       "   'variable_name': 'VAR1',\n",
       "   'cognitive_status': 'FAMILIAR'}],\n",
       " 'intention': {'speech_act': 'wantbel',\n",
       "  'proposition': {'text': 'belonging',\n",
       "   'type': 'concept',\n",
       "   'arguments': ['VAR0', 'VAR1'],\n",
       "   'name': 'belonging'}},\n",
       " 'descriptors': [{'text': 'm3 screw', 'arguments': ['VAR0'], 'name': 'm3'},\n",
       "  {'text': 'Evan', 'arguments': ['VAR1'], 'name': 'NONE'}]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['gmr']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007ecbd3",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485dae40",
   "metadata": {},
   "source": [
    "### Evaluation Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dc60514d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data processing classes and functions\n",
    "import json\n",
    "\n",
    "def process_data_item(json_item):\n",
    "    actions = json_item['promptInfo']['actions']\n",
    "    concepts = json_item['promptInfo']['properties']\n",
    "    return actions, concepts\n",
    "\n",
    "class DIARCDataset:\n",
    "    def __init__(self, annotations_file, types=None):\n",
    "        with open(annotations_file, \"r\") as f:\n",
    "            self.data = json.load(f)\n",
    "        if not self.data:\n",
    "            print(\"Dataset did not load because .json file could not be opened\")\n",
    "            return\n",
    "        \n",
    "        # initialize dataset \n",
    "        self.types = types\n",
    "        if not self.types:\n",
    "            # default types\n",
    "            self.types = [\"physobj\", \"agent\", \"location\", \"pose\", \"action\", \"number\", \"direction\", \"name\", \"string\"]\n",
    "        self.initialize()\n",
    "    \n",
    "    def initialize(self):\n",
    "        \"\"\"\n",
    "        updates self.data into this nice list of items amenable for later processing. \n",
    "        \"\"\"\n",
    "        data = []\n",
    "        for item in self.data['utterances']:\n",
    "            actions = item['promptInfo']['actions']\n",
    "            concepts = item['promptInfo']['properties']\n",
    "            utterance = item['utteranceText']\n",
    "            desired_semantics= item['desiredSemantics']\n",
    "            \n",
    "            datum = {\"utterance\": utterance,\n",
    "                     'desired_semantics': desired_semantics,\n",
    "                     \"robot_model\": {\n",
    "                         \"actions\": actions,\n",
    "                         \"concepts\": concepts,\n",
    "                         \"types\": self.types}\n",
    "                    }\n",
    "            \n",
    "            data.append(datum)\n",
    "        self.data = data\n",
    "        \n",
    "    \n",
    "    def stats(self):\n",
    "        num_items = len(self.data)\n",
    "        print(f\"Number of utterances: {num_items}\")\n",
    "            \n",
    "    def xy(self):\n",
    "        \"\"\"\n",
    "        returns all the utterances and desired semantics\n",
    "        \"\"\"\n",
    "        utterances = []\n",
    "        desired_semantics = []\n",
    "        for item in self.data:\n",
    "            utt = item['utterance']\n",
    "            des = item['desired_semantics']\n",
    "            utterances.append(utt)\n",
    "            desired_semantics.append(des)\n",
    "        return utterances, desired_semantics\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bc50781f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'utterance': 'define new screw type m3',\n",
       " 'desired_semantics': 'INSTRUCT(brad,self:agent,want(brad,defineScrewType(self:agent,m3)),{})',\n",
       " 'robot_model': {'actions': [{'name': 'getActDesc',\n",
       "    'roles': ['?actor', '?goalPred'],\n",
       "    'description': 'get step by step of action description and assert it to belief '},\n",
       "   {'name': 'getRefForJob',\n",
       "    'roles': ['?actor', '?descriptor'],\n",
       "    'description': 'runs a job for the given ?descriptor and saves and returns the first result'},\n",
       "   {'name': 'achieveState',\n",
       "    'roles': ['?actor',\n",
       "     '?speaker',\n",
       "     '?state',\n",
       "     '?tentativeAcceptSemantics',\n",
       "     '?acceptSemantics',\n",
       "     '?semanticType'],\n",
       "    'description': 'try to achieve desired state'},\n",
       "   {'name': 'grab',\n",
       "    'roles': ['?actor', '?physobj', '?pose'],\n",
       "    'description': '?actor grabs ?physobj'},\n",
       "   {'name': 'defineItem',\n",
       "    'roles': ['?actor', '?item'],\n",
       "    'description': 'defines new item, and asks for relevant parameters'},\n",
       "   {'name': 'putdown',\n",
       "    'roles': ['?actor', '?physobj', '?pose'],\n",
       "    'description': '?actor releases ?physobj'},\n",
       "   {'name': 'modifyAssemble',\n",
       "    'roles': ['?actor', '?scriptID', '?modification', '?location'],\n",
       "    'description': 'creates a new assembly script based on an existing one'},\n",
       "   {'name': 'checkCapableOf',\n",
       "    'roles': ['?actor', '?goal'],\n",
       "    'description': 'checks if post condition is capable of bing reached by ?actor'},\n",
       "   {'name': 'observeDescriptor',\n",
       "    'roles': ['?actor', '?descriptor', '?numResults'],\n",
       "    'description': 'runs a job for the given ?descriptor and saves the results in the cognex consultant'},\n",
       "   {'name': 'bindResultsRecursive',\n",
       "    'roles': ['?actor', '?job', '?cameraResults', '?i'],\n",
       "    'description': 'Recursively iterates through the given ?cameraResults and binds them to references'},\n",
       "   {'name': 'supersedeCurrentGoal',\n",
       "    'roles': ['?actor', '?newGoal'],\n",
       "    'description': 'stops current goal, executes ?newGoal, replans to rexecute the goal that was stopped'},\n",
       "   {'name': 'modifyAssemble',\n",
       "    'roles': ['?actor',\n",
       "     '?newScriptID',\n",
       "     '?oldScriptID',\n",
       "     '?modification',\n",
       "     '?location'],\n",
       "    'description': 'creates a new assembly script based on an existing one'},\n",
       "   {'name': 'undoThenDo',\n",
       "    'roles': ['?actor', '?newGoal'],\n",
       "    'description': \"stops current goal, executes ?newGoal, executes plan to 'undo' the goal that was stopped\"},\n",
       "   {'name': 'perceiveEntityFromSymbol',\n",
       "    'roles': ['?actor', '?refId'],\n",
       "    'description': 'runs a job for a given pre-existing ?refId and binds the relevant result to that reference'},\n",
       "   {'name': 'gotoCamerapose',\n",
       "    'roles': ['?actor', '?pose'],\n",
       "    'description': 'goes to pose at camera height'},\n",
       "   {'name': 'moveConveyorBackward',\n",
       "    'roles': ['?actor'],\n",
       "    'description': 'Moves the conveyor belt backward'},\n",
       "   {'name': 'alignWith',\n",
       "    'roles': ['?actor', '?holeRef'],\n",
       "    'description': 'aligns above a screw hole by reference id'},\n",
       "   {'name': 'handleUtterance',\n",
       "    'roles': ['?actor',\n",
       "     '?speaker',\n",
       "     '?addressee',\n",
       "     '?listeners',\n",
       "     '?semantics',\n",
       "     '?indirectSemantics',\n",
       "     '?suppSemantics'],\n",
       "    'description': 'Handle NLPacket form a response'},\n",
       "   {'name': 'goToPose',\n",
       "    'roles': ['?actor', '?pose', '?cameraHeight'],\n",
       "    'description': 'goes to pose with adjustment to the given cameraHeight'},\n",
       "   {'name': 'goToPose',\n",
       "    'roles': ['?actor', '?pose'],\n",
       "    'description': 'goes to pose without adjustment'},\n",
       "   {'name': 'handleError',\n",
       "    'roles': ['?actor',\n",
       "     '?speaker',\n",
       "     '?addressee',\n",
       "     '?errorSemantics',\n",
       "     '?semanticType'],\n",
       "    'description': 'Handle error semantics'},\n",
       "   {'name': 'mountSingleScrew',\n",
       "    'roles': ['?actor'],\n",
       "    'description': 'finds and mounts a single screw to the kolver screwdriver'},\n",
       "   {'name': 'goToPoseLong',\n",
       "    'roles': ['?actor', '?pose', '?cameraHeight'],\n",
       "    'description': 'goes to pose with adjustment to the given cameraHeight the long way around'},\n",
       "   {'name': 'getTime',\n",
       "    'roles': ['?actor'],\n",
       "    'description': 'get the system time and assert it to belief'},\n",
       "   {'name': 'handleRecovery',\n",
       "    'roles': ['?actor', '?speaker', '?state', '?recovery', '?semanticType'],\n",
       "    'description': 'reply to recovery semantics'},\n",
       "   {'name': 'startLearningAssembleScript',\n",
       "    'roles': ['?actor', '?modelName'],\n",
       "    'description': 'assembles model for ?modelID from belief'},\n",
       "   {'name': 'gotocamerapose',\n",
       "    'roles': ['?actor', '?pose1', '?pose2'],\n",
       "    'description': 'moves to ?pose1, from ?pose2'},\n",
       "   {'name': 'moveConveyorForward',\n",
       "    'roles': ['?actor'],\n",
       "    'description': 'Moves the conveyor belt forward'},\n",
       "   {'name': 'recordCameraPoseAsk',\n",
       "    'roles': ['?actor', '?poseName'],\n",
       "    'description': 'records current pose and asks for an off set'},\n",
       "   {'name': 'believeFact',\n",
       "    'roles': ['?actor',\n",
       "     '?speaker',\n",
       "     '?addressee',\n",
       "     '?fact',\n",
       "     '?semanticType',\n",
       "     '?responseSemantics'],\n",
       "    'description': 'believe that ?fact is true from agent ?speaker'},\n",
       "   {'name': 'init',\n",
       "    'roles': ['?actor'],\n",
       "    'description': 'workaround for not being able to retract facts from belief init files'},\n",
       "   {'name': 'assembleVision',\n",
       "    'roles': ['?actor'],\n",
       "    'description': 'classifies model in front of itself and calls relevant assemble script'},\n",
       "   {'name': 'pickUp',\n",
       "    'roles': ['?actor', '?objectRef'],\n",
       "    'description': 'finds and moves above a flange of the given modelType'},\n",
       "   {'name': 'runScrewdriverJob',\n",
       "    'roles': ['?actor', '?screwType'],\n",
       "    'description': 'screws in a screw once aligned'},\n",
       "   {'name': 'rotateToEE',\n",
       "    'roles': ['?actor', '?gripperType'],\n",
       "    'description': 'changes TCP of robot to refer to a new EE attached to the cuff at a different offset'},\n",
       "   {'name': 'assemble',\n",
       "    'roles': ['?actor', '?modelID'],\n",
       "    'description': 'assembles model for ?modelID from belief'},\n",
       "   {'name': 'handleWantBel',\n",
       "    'roles': ['?actor', '?speaker', '?addressee', '?fact', '?semanticType'],\n",
       "    'description': 'reply to wantBel semantics'},\n",
       "   {'name': 'handleSemantics',\n",
       "    'roles': ['?actor',\n",
       "     '?speaker',\n",
       "     '?addressee',\n",
       "     '?listeners',\n",
       "     '?semantics',\n",
       "     '?suppSemantics',\n",
       "     '?semanticType'],\n",
       "    'description': 'Handle semantics (direct or indirect)'},\n",
       "   {'name': 'updateParam',\n",
       "    'roles': ['?actor', '?paramName', '?newValue'],\n",
       "    'description': 'updates value of ?param to ?newValue'},\n",
       "   {'name': 'modifyAssemble',\n",
       "    'roles': ['?actor', '?newScriptID', '?oldScriptID'],\n",
       "    'description': 'creates a new assembly script based on an existing one'},\n",
       "   {'name': 'moveToCameraHeight',\n",
       "    'roles': ['?actor'],\n",
       "    'description': 'moves up by a camera z height as defined by an inline constant'},\n",
       "   {'name': 'getOn',\n",
       "    'roles': ['?actor', '?object', '?destination'],\n",
       "    'description': 'gets ?object on to the surface beneath ?destination'},\n",
       "   {'name': 'getCurrGoals',\n",
       "    'roles': ['?actor'],\n",
       "    'description': 'get list of current goals and assert it to belief'},\n",
       "   {'name': 'handleAck',\n",
       "    'roles': ['?actor', '?speaker', '?addressee', '?semanticType'],\n",
       "    'description': 'Handle ack semantics'},\n",
       "   {'name': 'perceiveEntity',\n",
       "    'roles': ['?actor', '?refId'],\n",
       "    'description': 'Looks for an entity at the current location'},\n",
       "   {'name': 'defineScrewType',\n",
       "    'roles': ['?actor', '?screwType'],\n",
       "    'description': 'defines new type of screw for screw, and asks for relevant parameters'},\n",
       "   {'name': 'screwScrew',\n",
       "    'roles': ['?actor', '?screwType'],\n",
       "    'description': 'screws in a single hole identified by the cognex using the kolver screwdriver'},\n",
       "   {'name': 'dip',\n",
       "    'roles': ['?actor', '?dist'],\n",
       "    'description': 'moves down and up by the distance given'},\n",
       "   {'name': 'putDown',\n",
       "    'roles': ['?actor'],\n",
       "    'description': 'drops an object held by the robot grippers'},\n",
       "   {'name': 'generateResponse',\n",
       "    'roles': ['?actor', '?listener', '?semantics', '?semanticType'],\n",
       "    'description': 'given a predicate, calls NLG pipeline to get its text from and then submits a say text goal with it'},\n",
       "   {'name': 'supersedeAndUndo',\n",
       "    'roles': ['?actor', '?newGoal'],\n",
       "    'description': \"stops current goal, executes ?newGoal, executes plan to 'undo' the goal that was stopped\"},\n",
       "   {'name': 'goToPoseLong',\n",
       "    'roles': ['?actor', '?pose'],\n",
       "    'description': 'goes to pose without adjustment the long way around'},\n",
       "   {'name': 'moveToObjectHeight',\n",
       "    'roles': ['?actor'],\n",
       "    'description': 'moves down by a camera z height as defined by an inline constant'},\n",
       "   {'name': 'unstickScrewdriver',\n",
       "    'roles': ['?actor', '?returnTo'],\n",
       "    'description': 'unsticks the screwdriver tip from a screwed in screw'},\n",
       "   {'name': 'mountScrew',\n",
       "    'roles': ['?actor', '?screwType'],\n",
       "    'description': 'goes to the source of the given screw type and mounts one to the screwdriver'},\n",
       "   {'name': 'generateResponse',\n",
       "    'roles': ['?actor',\n",
       "     '?listener',\n",
       "     '?semantics',\n",
       "     '?bindings',\n",
       "     '?semanticType'],\n",
       "    'description': 'given a predicate, calls NLG pipeline to get its text from and then calls sayText action'},\n",
       "   {'name': 'believeRule',\n",
       "    'roles': ['?actor',\n",
       "     '?speaker',\n",
       "     '?head',\n",
       "     '?body',\n",
       "     '?semanticType',\n",
       "     '?responseSemantics'],\n",
       "    'description': 'believe that ?rule is true from agent ?speaker'},\n",
       "   {'name': 'handleITK',\n",
       "    'roles': ['?actor', '?speaker', '?addressee', '?query', '?semanticType'],\n",
       "    'description': 'reply to itk semantics'},\n",
       "   {'name': 'handleGreeting',\n",
       "    'roles': ['?actor',\n",
       "     '?speaker',\n",
       "     '?addressee',\n",
       "     '?greeting',\n",
       "     '?semanticType'],\n",
       "    'description': 'Handle greeting semantics'},\n",
       "   {'name': 'endLearningAssembleScript',\n",
       "    'roles': ['?actor', '?modelName'],\n",
       "    'description': 'ends learning of assemble?modelName()'},\n",
       "   {'name': 'getContextDescription',\n",
       "    'roles': ['?actor', '?location'],\n",
       "    'description': 'get description for step of (specified by location) currently executing goal '},\n",
       "   {'name': 'handleWant',\n",
       "    'roles': ['?actor', '?speaker', '?addressee', '?state', '?semanticType'],\n",
       "    'description': 'reply to want semantics'}],\n",
       "  'concepts': [{'name': 'this', 'roles': ['X:pose']},\n",
       "   {'name': 'conveyor', 'roles': ['X:pose']},\n",
       "   {'name': 'work area', 'roles': ['X:pose']},\n",
       "   {'name': 'screw feeder', 'roles': ['X:pose']},\n",
       "   {'name': 'it', 'roles': ['X:pose']},\n",
       "   {'name': 'that', 'roles': ['X:pose']},\n",
       "   {'name': 'thing', 'roles': ['X:pose']},\n",
       "   {'name': 'those', 'roles': ['X:pose']},\n",
       "   {'name': 'they', 'roles': ['X:pose']},\n",
       "   {'name': 'these', 'roles': ['X:pose']},\n",
       "   {'name': 'this', 'roles': ['X:context']},\n",
       "   {'name': 'it', 'roles': ['X:context']},\n",
       "   {'name': 'that', 'roles': ['X:context']},\n",
       "   {'name': 'thing', 'roles': ['X:context']},\n",
       "   {'name': 'those', 'roles': ['X:context']},\n",
       "   {'name': 'they', 'roles': ['X:context']},\n",
       "   {'name': 'these', 'roles': ['X:context']},\n",
       "   {'name': 'doit', 'roles': ['X:dialog']},\n",
       "   {'name': 'dothis', 'roles': ['Xdialog:dialog']},\n",
       "   {'name': 'dothat', 'roles': ['Xdialog:dialog']},\n",
       "   {'name': 'that', 'roles': ['Xdialog:dialog']},\n",
       "   {'name': 'this', 'roles': ['X:physobj']},\n",
       "   {'name': 'hole', 'roles': ['X:physobj']},\n",
       "   {'name': 'm3', 'roles': ['X:physobj']},\n",
       "   {'name': 'deepM3', 'roles': ['X:physobj']},\n",
       "   {'name': 'left', 'roles': ['X:physobj']},\n",
       "   {'name': 'right', 'roles': ['X:physobj']},\n",
       "   {'name': 'top', 'roles': ['X:physobj']},\n",
       "   {'name': 'bottom', 'roles': ['X:physobj']},\n",
       "   {'name': 'prop', 'roles': ['X:physobj']},\n",
       "   {'name': 'bottle', 'roles': ['X:physobj']},\n",
       "   {'name': 'it', 'roles': ['X:physobj']},\n",
       "   {'name': 'that', 'roles': ['X:physobj']},\n",
       "   {'name': 'thing', 'roles': ['X:physobj']},\n",
       "   {'name': 'those', 'roles': ['X:physobj']},\n",
       "   {'name': 'they', 'roles': ['X:physobj']},\n",
       "   {'name': 'these', 'roles': ['X:physobj']}],\n",
       "  'types': ['physobj',\n",
       "   'agent',\n",
       "   'location',\n",
       "   'pose',\n",
       "   'action',\n",
       "   'number',\n",
       "   'direction',\n",
       "   'name',\n",
       "   'string']}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = DIARCDataset(annotations_file=\"../data/tasks/dev/screwingActionModificationTestOrdered.json\")\n",
    "dataset.data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970d7bec",
   "metadata": {},
   "source": [
    "### Spot Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5ad821f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'utterance': 'replace screw an m3 screw into the right m3 hole with screw an m3 screw into the top deep m3 hole',\n",
       " 'desired_semantics': 'UNKNOWN(brad,self:agent,mod(replace(screwIn(self:agent,m3,VAR1),screwIn(self:agent,m3,VAR0))),{m3(VAR0),right(VAR0),deepM3(VAR1),top(VAR1),DEFINITE(VAR0),DEFINITE(VAR1)})',\n",
       " 'robot_model': {'actions': [{'name': 'getActDesc',\n",
       "    'roles': ['?actor', '?goalPred'],\n",
       "    'description': 'get step by step of action description and assert it to belief '},\n",
       "   {'name': 'getRefForJob',\n",
       "    'roles': ['?actor', '?descriptor'],\n",
       "    'description': 'runs a job for the given ?descriptor and saves and returns the first result'},\n",
       "   {'name': 'achieveState',\n",
       "    'roles': ['?actor',\n",
       "     '?speaker',\n",
       "     '?state',\n",
       "     '?tentativeAcceptSemantics',\n",
       "     '?acceptSemantics',\n",
       "     '?semanticType'],\n",
       "    'description': 'try to achieve desired state'},\n",
       "   {'name': 'grab',\n",
       "    'roles': ['?actor', '?physobj', '?pose'],\n",
       "    'description': '?actor grabs ?physobj'},\n",
       "   {'name': 'defineItem',\n",
       "    'roles': ['?actor', '?item'],\n",
       "    'description': 'defines new item, and asks for relevant parameters'},\n",
       "   {'name': 'putdown',\n",
       "    'roles': ['?actor', '?physobj', '?pose'],\n",
       "    'description': '?actor releases ?physobj'},\n",
       "   {'name': 'modifyAssemble',\n",
       "    'roles': ['?actor', '?scriptID', '?modification', '?location'],\n",
       "    'description': 'creates a new assembly script based on an existing one'},\n",
       "   {'name': 'checkCapableOf',\n",
       "    'roles': ['?actor', '?goal'],\n",
       "    'description': 'checks if post condition is capable of bing reached by ?actor'},\n",
       "   {'name': 'observeDescriptor',\n",
       "    'roles': ['?actor', '?descriptor', '?numResults'],\n",
       "    'description': 'runs a job for the given ?descriptor and saves the results in the cognex consultant'},\n",
       "   {'name': 'bindResultsRecursive',\n",
       "    'roles': ['?actor', '?job', '?cameraResults', '?i'],\n",
       "    'description': 'Recursively iterates through the given ?cameraResults and binds them to references'},\n",
       "   {'name': 'supersedeCurrentGoal',\n",
       "    'roles': ['?actor', '?newGoal'],\n",
       "    'description': 'stops current goal, executes ?newGoal, replans to rexecute the goal that was stopped'},\n",
       "   {'name': 'modifyAssemble',\n",
       "    'roles': ['?actor',\n",
       "     '?newScriptID',\n",
       "     '?oldScriptID',\n",
       "     '?modification',\n",
       "     '?location'],\n",
       "    'description': 'creates a new assembly script based on an existing one'},\n",
       "   {'name': 'undoThenDo',\n",
       "    'roles': ['?actor', '?newGoal'],\n",
       "    'description': \"stops current goal, executes ?newGoal, executes plan to 'undo' the goal that was stopped\"},\n",
       "   {'name': 'perceiveEntityFromSymbol',\n",
       "    'roles': ['?actor', '?refId'],\n",
       "    'description': 'runs a job for a given pre-existing ?refId and binds the relevant result to that reference'},\n",
       "   {'name': 'gotoCamerapose',\n",
       "    'roles': ['?actor', '?pose'],\n",
       "    'description': 'goes to pose at camera height'},\n",
       "   {'name': 'moveConveyorBackward',\n",
       "    'roles': ['?actor'],\n",
       "    'description': 'Moves the conveyor belt backward'},\n",
       "   {'name': 'alignWith',\n",
       "    'roles': ['?actor', '?holeRef'],\n",
       "    'description': 'aligns above a screw hole by reference id'},\n",
       "   {'name': 'handleUtterance',\n",
       "    'roles': ['?actor',\n",
       "     '?speaker',\n",
       "     '?addressee',\n",
       "     '?listeners',\n",
       "     '?semantics',\n",
       "     '?indirectSemantics',\n",
       "     '?suppSemantics'],\n",
       "    'description': 'Handle NLPacket form a response'},\n",
       "   {'name': 'goToPose',\n",
       "    'roles': ['?actor', '?pose', '?cameraHeight'],\n",
       "    'description': 'goes to pose with adjustment to the given cameraHeight'},\n",
       "   {'name': 'goToPose',\n",
       "    'roles': ['?actor', '?pose'],\n",
       "    'description': 'goes to pose without adjustment'},\n",
       "   {'name': 'handleError',\n",
       "    'roles': ['?actor',\n",
       "     '?speaker',\n",
       "     '?addressee',\n",
       "     '?errorSemantics',\n",
       "     '?semanticType'],\n",
       "    'description': 'Handle error semantics'},\n",
       "   {'name': 'mountSingleScrew',\n",
       "    'roles': ['?actor'],\n",
       "    'description': 'finds and mounts a single screw to the kolver screwdriver'},\n",
       "   {'name': 'goToPoseLong',\n",
       "    'roles': ['?actor', '?pose', '?cameraHeight'],\n",
       "    'description': 'goes to pose with adjustment to the given cameraHeight the long way around'},\n",
       "   {'name': 'getTime',\n",
       "    'roles': ['?actor'],\n",
       "    'description': 'get the system time and assert it to belief'},\n",
       "   {'name': 'handleRecovery',\n",
       "    'roles': ['?actor', '?speaker', '?state', '?recovery', '?semanticType'],\n",
       "    'description': 'reply to recovery semantics'},\n",
       "   {'name': 'startLearningAssembleScript',\n",
       "    'roles': ['?actor', '?modelName'],\n",
       "    'description': 'assembles model for ?modelID from belief'},\n",
       "   {'name': 'gotocamerapose',\n",
       "    'roles': ['?actor', '?pose1', '?pose2'],\n",
       "    'description': 'moves to ?pose1, from ?pose2'},\n",
       "   {'name': 'moveConveyorForward',\n",
       "    'roles': ['?actor'],\n",
       "    'description': 'Moves the conveyor belt forward'},\n",
       "   {'name': 'recordCameraPoseAsk',\n",
       "    'roles': ['?actor', '?poseName'],\n",
       "    'description': 'records current pose and asks for an off set'},\n",
       "   {'name': 'believeFact',\n",
       "    'roles': ['?actor',\n",
       "     '?speaker',\n",
       "     '?addressee',\n",
       "     '?fact',\n",
       "     '?semanticType',\n",
       "     '?responseSemantics'],\n",
       "    'description': 'believe that ?fact is true from agent ?speaker'},\n",
       "   {'name': 'init',\n",
       "    'roles': ['?actor'],\n",
       "    'description': 'workaround for not being able to retract facts from belief init files'},\n",
       "   {'name': 'assembleVision',\n",
       "    'roles': ['?actor'],\n",
       "    'description': 'classifies model in front of itself and calls relevant assemble script'},\n",
       "   {'name': 'pickUp',\n",
       "    'roles': ['?actor', '?objectRef'],\n",
       "    'description': 'finds and moves above a flange of the given modelType'},\n",
       "   {'name': 'runScrewdriverJob',\n",
       "    'roles': ['?actor', '?screwType'],\n",
       "    'description': 'screws in a screw once aligned'},\n",
       "   {'name': 'rotateToEE',\n",
       "    'roles': ['?actor', '?gripperType'],\n",
       "    'description': 'changes TCP of robot to refer to a new EE attached to the cuff at a different offset'},\n",
       "   {'name': 'assemble',\n",
       "    'roles': ['?actor', '?modelID'],\n",
       "    'description': 'assembles model for ?modelID from belief'},\n",
       "   {'name': 'handleWantBel',\n",
       "    'roles': ['?actor', '?speaker', '?addressee', '?fact', '?semanticType'],\n",
       "    'description': 'reply to wantBel semantics'},\n",
       "   {'name': 'handleSemantics',\n",
       "    'roles': ['?actor',\n",
       "     '?speaker',\n",
       "     '?addressee',\n",
       "     '?listeners',\n",
       "     '?semantics',\n",
       "     '?suppSemantics',\n",
       "     '?semanticType'],\n",
       "    'description': 'Handle semantics (direct or indirect)'},\n",
       "   {'name': 'updateParam',\n",
       "    'roles': ['?actor', '?paramName', '?newValue'],\n",
       "    'description': 'updates value of ?param to ?newValue'},\n",
       "   {'name': 'modifyAssemble',\n",
       "    'roles': ['?actor', '?newScriptID', '?oldScriptID'],\n",
       "    'description': 'creates a new assembly script based on an existing one'},\n",
       "   {'name': 'moveToCameraHeight',\n",
       "    'roles': ['?actor'],\n",
       "    'description': 'moves up by a camera z height as defined by an inline constant'},\n",
       "   {'name': 'getOn',\n",
       "    'roles': ['?actor', '?object', '?destination'],\n",
       "    'description': 'gets ?object on to the surface beneath ?destination'},\n",
       "   {'name': 'getCurrGoals',\n",
       "    'roles': ['?actor'],\n",
       "    'description': 'get list of current goals and assert it to belief'},\n",
       "   {'name': 'handleAck',\n",
       "    'roles': ['?actor', '?speaker', '?addressee', '?semanticType'],\n",
       "    'description': 'Handle ack semantics'},\n",
       "   {'name': 'perceiveEntity',\n",
       "    'roles': ['?actor', '?refId'],\n",
       "    'description': 'Looks for an entity at the current location'},\n",
       "   {'name': 'defineScrewType',\n",
       "    'roles': ['?actor', '?screwType'],\n",
       "    'description': 'defines new type of screw for screw, and asks for relevant parameters'},\n",
       "   {'name': 'screwScrew',\n",
       "    'roles': ['?actor', '?screwType'],\n",
       "    'description': 'screws in a single hole identified by the cognex using the kolver screwdriver'},\n",
       "   {'name': 'dip',\n",
       "    'roles': ['?actor', '?dist'],\n",
       "    'description': 'moves down and up by the distance given'},\n",
       "   {'name': 'putDown',\n",
       "    'roles': ['?actor'],\n",
       "    'description': 'drops an object held by the robot grippers'},\n",
       "   {'name': 'generateResponse',\n",
       "    'roles': ['?actor', '?listener', '?semantics', '?semanticType'],\n",
       "    'description': 'given a predicate, calls NLG pipeline to get its text from and then submits a say text goal with it'},\n",
       "   {'name': 'supersedeAndUndo',\n",
       "    'roles': ['?actor', '?newGoal'],\n",
       "    'description': \"stops current goal, executes ?newGoal, executes plan to 'undo' the goal that was stopped\"},\n",
       "   {'name': 'goToPoseLong',\n",
       "    'roles': ['?actor', '?pose'],\n",
       "    'description': 'goes to pose without adjustment the long way around'},\n",
       "   {'name': 'moveToObjectHeight',\n",
       "    'roles': ['?actor'],\n",
       "    'description': 'moves down by a camera z height as defined by an inline constant'},\n",
       "   {'name': 'unstickScrewdriver',\n",
       "    'roles': ['?actor', '?returnTo'],\n",
       "    'description': 'unsticks the screwdriver tip from a screwed in screw'},\n",
       "   {'name': 'mountScrew',\n",
       "    'roles': ['?actor', '?screwType'],\n",
       "    'description': 'goes to the source of the given screw type and mounts one to the screwdriver'},\n",
       "   {'name': 'generateResponse',\n",
       "    'roles': ['?actor',\n",
       "     '?listener',\n",
       "     '?semantics',\n",
       "     '?bindings',\n",
       "     '?semanticType'],\n",
       "    'description': 'given a predicate, calls NLG pipeline to get its text from and then calls sayText action'},\n",
       "   {'name': 'believeRule',\n",
       "    'roles': ['?actor',\n",
       "     '?speaker',\n",
       "     '?head',\n",
       "     '?body',\n",
       "     '?semanticType',\n",
       "     '?responseSemantics'],\n",
       "    'description': 'believe that ?rule is true from agent ?speaker'},\n",
       "   {'name': 'handleITK',\n",
       "    'roles': ['?actor', '?speaker', '?addressee', '?query', '?semanticType'],\n",
       "    'description': 'reply to itk semantics'},\n",
       "   {'name': 'handleGreeting',\n",
       "    'roles': ['?actor',\n",
       "     '?speaker',\n",
       "     '?addressee',\n",
       "     '?greeting',\n",
       "     '?semanticType'],\n",
       "    'description': 'Handle greeting semantics'},\n",
       "   {'name': 'endLearningAssembleScript',\n",
       "    'roles': ['?actor', '?modelName'],\n",
       "    'description': 'ends learning of assemble?modelName()'},\n",
       "   {'name': 'getContextDescription',\n",
       "    'roles': ['?actor', '?location'],\n",
       "    'description': 'get description for step of (specified by location) currently executing goal '},\n",
       "   {'name': 'handleWant',\n",
       "    'roles': ['?actor', '?speaker', '?addressee', '?state', '?semanticType'],\n",
       "    'description': 'reply to want semantics'}],\n",
       "  'concepts': [{'name': 'this', 'roles': ['X:pose']},\n",
       "   {'name': 'conveyor', 'roles': ['X:pose']},\n",
       "   {'name': 'work area', 'roles': ['X:pose']},\n",
       "   {'name': 'screw feeder', 'roles': ['X:pose']},\n",
       "   {'name': 'it', 'roles': ['X:pose']},\n",
       "   {'name': 'that', 'roles': ['X:pose']},\n",
       "   {'name': 'thing', 'roles': ['X:pose']},\n",
       "   {'name': 'those', 'roles': ['X:pose']},\n",
       "   {'name': 'they', 'roles': ['X:pose']},\n",
       "   {'name': 'these', 'roles': ['X:pose']},\n",
       "   {'name': 'this', 'roles': ['X:context']},\n",
       "   {'name': 'it', 'roles': ['X:context']},\n",
       "   {'name': 'that', 'roles': ['X:context']},\n",
       "   {'name': 'thing', 'roles': ['X:context']},\n",
       "   {'name': 'those', 'roles': ['X:context']},\n",
       "   {'name': 'they', 'roles': ['X:context']},\n",
       "   {'name': 'these', 'roles': ['X:context']},\n",
       "   {'name': 'doit', 'roles': ['X:dialog']},\n",
       "   {'name': 'dothis', 'roles': ['Xdialog:dialog']},\n",
       "   {'name': 'dothat', 'roles': ['Xdialog:dialog']},\n",
       "   {'name': 'that', 'roles': ['Xdialog:dialog']},\n",
       "   {'name': 'this', 'roles': ['X:physobj']},\n",
       "   {'name': 'hole', 'roles': ['X:physobj']},\n",
       "   {'name': 'm3', 'roles': ['X:physobj']},\n",
       "   {'name': 'deepM3', 'roles': ['X:physobj']},\n",
       "   {'name': 'left', 'roles': ['X:physobj']},\n",
       "   {'name': 'right', 'roles': ['X:physobj']},\n",
       "   {'name': 'top', 'roles': ['X:physobj']},\n",
       "   {'name': 'bottom', 'roles': ['X:physobj']},\n",
       "   {'name': 'prop', 'roles': ['X:physobj']},\n",
       "   {'name': 'bottle', 'roles': ['X:physobj']},\n",
       "   {'name': 'nfsv', 'roles': ['X:physobj']},\n",
       "   {'name': 'it', 'roles': ['X:physobj']},\n",
       "   {'name': 'that', 'roles': ['X:physobj']},\n",
       "   {'name': 'thing', 'roles': ['X:physobj']},\n",
       "   {'name': 'those', 'roles': ['X:physobj']},\n",
       "   {'name': 'they', 'roles': ['X:physobj']},\n",
       "   {'name': 'these', 'roles': ['X:physobj']}],\n",
       "  'types': ['physobj',\n",
       "   'agent',\n",
       "   'location',\n",
       "   'pose',\n",
       "   'action',\n",
       "   'number',\n",
       "   'direction',\n",
       "   'name',\n",
       "   'string']}}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 31\n",
    "dataset.data[31]\n",
    "#output = parse(utterance=dataset.data[idx]['utterance'],robot_model=dataset.data[idx]['robot_model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01f7d6f",
   "metadata": {},
   "source": [
    "### Run Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a1939233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== ITEM 0 ============\n",
      "Utterance: setup poses\n",
      "DesiredSemantics: INSTRUCT(brad,self:agent,want(brad,setupPoses(self:agent)),{})\n",
      "\n",
      "Processing utterance: setup poses\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"poses\",\n",
      "    \"type\": \"pose\",\n",
      "    \"role\": \"central\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"want\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"setup\",\n",
      "    \"type\": \"action\"\n",
      "  }\n",
      "}\n",
      "[X] Finding Candidate actions\n",
      "\tCandidate actions: ['defineItem:0.6', 'defineScrewType:0.6', 'startLearningAssembleScript:0.5', 'endLearningAssembleScript:0.5', 'recordCameraPoseAsk:0.7']\n",
      "[X] Selecting best candidate\n",
      "\tBest candidate action name: NONE\n",
      "[X] Extracting Propertiese\n",
      "\tDescriptors: [{'text': 'poses', 'arguments': ['pose']}]\n",
      "Debug: candidates: ['this:0.5', 'it:0.5', 'that:0.5', 'thing:0.5', 'these:0.5']\n",
      "[X] Finding Consultants properties similar to SPC\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'poses': 'INDEFINITE'}\n",
      "Utterance: setup poses\n",
      "PARSE: want(brad,NONE,{NONE(pose)})\n",
      "==================================\n",
      "\n",
      "======== ITEM 1 ============\n",
      "Utterance: define new screw type m3\n",
      "DesiredSemantics: INSTRUCT(brad,self:agent,want(brad,defineScrewType(self:agent,m3)),{})\n",
      "\n",
      "Processing utterance: define new screw type m3\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"new screw type m3\",\n",
      "    \"type\": \"name\",\n",
      "    \"role\": \"central\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"want\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"define\",\n",
      "    \"type\": \"action\"\n",
      "  }\n",
      "}\n",
      "[X] Finding Candidate actions\n",
      "\tCandidate actions: ['defineItem:0.9', 'defineScrewType:0.8', 'believeFact:0.3', 'believeRule:0.3', 'updateParam:0.2']\n",
      "[X] Selecting best candidate\n",
      "\tBest candidate action name: defineItem\n",
      "Central ref: {'text': 'new screw type m3', 'type': 'name', 'role': 'central'}\n",
      "[X] Binding best candidate\n",
      "\tBound candidate: {'name': 'defineItem', 'bindings': [{'VAR0': 'self'}, {'VAR1': 'new screw type m3'}]}\n",
      "[X] Extracting Properties\n",
      "\tDescriptors: [{'text': 'new', 'arguments': ['VAR1']}, {'text': 'screw type', 'arguments': ['VAR1']}, {'text': 'm3', 'arguments': ['VAR1']}]\n",
      "Debug: candidates: ['conveyor:0.2', 'work area:0.2', 'screw feeder:0.6', 'hole:0.1', 'bottle:0.1']\n",
      "Debug: candidates: ['screw feeder:0.8', 'm3:0.7', 'deepM3:0.6', 'prop:0.5', 'bottle:0.4']\n",
      "Debug: candidates: ['m3:1', 'deepM3:0.8', 'hole:0.6', 'screw feeder:0.5', 'work area:0.3']\n",
      "[X] Finding Consultants properties similar to SPC\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'VAR1': 'INDEFINITE'}\n",
      "Utterance: define new screw type m3\n",
      "PARSE: want(brad,defineItem(self,VAR1),{NONE(VAR1),NONE(VAR1),m3(VAR1),INDEFINITE(VAR1)})\n",
      "==================================\n",
      "\n",
      "======== ITEM 2 ============\n",
      "Utterance: 150 millinewton meters\n",
      "DesiredSemantics: UNKNOWN(brad,self:agent,val(150,mNm),{})\n",
      "\n",
      "Processing utterance: 150 millinewton meters\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"150 millinewton meters\",\n",
      "    \"type\": \"number\",\n",
      "    \"role\": \"central\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"wantbel\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"magnitude\",\n",
      "    \"type\": \"concept\"\n",
      "  }\n",
      "}\n",
      "[X] Finding Candidate concepts\n",
      "\tCandidates: ['deepM3: 0.5', 'm3: 0.5', 'prop: 0.3', 'bottle: 0.2', 'hole: 0.2']\n",
      "[X] Selecting best candidate above similarity of 0.8\n",
      "\tBest candidate concept name: NONE\n",
      "[X] Instantiating novel concept\n",
      "[X] Binding novel concept\n",
      "[X] Extracting Properties\n",
      "\tDescriptors: [{'text': '150', 'arguments': ['VAR0']}, {'text': 'millinewton meters', 'arguments': ['VAR0']}]\n",
      "Debug: candidates: ['m3: 0.8', 'deepM3: 0.7', 'left: 0.1', 'right: 0.1', 'top: 0.1']\n",
      "Debug: candidates: ['m3: 0.8', 'deepM3: 0.7', 'prop: 0.3', 'bottle: 0.2', 'hole: 0.1']\n",
      "[X] Finding Consultants properties similar to SPC\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'VAR0': 'INDEFINITE'}\n",
      "Utterance: 150 millinewton meters\n",
      "PARSE: wantbel(brad,magnitude(VAR0),{NONE(VAR0),NONE(VAR0),INDEFINITE(VAR0)})\n",
      "==================================\n",
      "\n",
      "======== ITEM 3 ============\n",
      "Utterance: 300 millinewton meters\n",
      "DesiredSemantics: UNKNOWN(brad,self:agent,val(300,mNm),{})\n",
      "\n",
      "Processing utterance: 300 millinewton meters\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"300 millinewton meters\",\n",
      "    \"type\": \"number\",\n",
      "    \"role\": \"central\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"itk\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"torque\",\n",
      "    \"type\": \"concept\"\n",
      "  }\n",
      "}\n",
      "[X] Finding Candidate concepts\n",
      "\tCandidates: ['screw feeder:0.6', 'm3:0.5', 'deepM3:0.5', 'prop:0.4', 'bottle:0.3']\n",
      "[X] Selecting best candidate above similarity of 0.8\n",
      "\tBest candidate concept name: NONE\n",
      "[X] Instantiating novel concept\n",
      "[X] Binding novel concept\n",
      "[X] Extracting Properties\n",
      "\tDescriptors: [{'text': '300', 'arguments': ['VAR0']}, {'text': 'millinewton meters', 'arguments': ['VAR0']}]\n",
      "Debug: candidates: ['m3:0.8', 'deepM3:0.7', 'left:0.1', 'right:0.1', 'top:0.1']\n",
      "Debug: candidates: ['m3: 0.8', 'deepM3: 0.7', 'prop: 0.3', 'bottle: 0.2', 'hole: 0.1']\n",
      "[X] Finding Consultants properties similar to SPC\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'300 millinewton meters': 'INDEFINITE'}\n",
      "Utterance: 300 millinewton meters\n",
      "PARSE: itk(brad,torque(VAR0),{NONE(VAR0),NONE(VAR0)})\n",
      "==================================\n",
      "\n",
      "======== ITEM 4 ============\n",
      "Utterance: 6500 degrees\n",
      "DesiredSemantics: UNKNOWN(brad,self:agent,val(6500,deg),{})\n",
      "\n",
      "Processing utterance: 6500 degrees\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"temperature\",\n",
      "    \"type\": \"number\",\n",
      "    \"role\": \"central\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"wantbel\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"high\",\n",
      "    \"type\": \"concept\"\n",
      "  }\n",
      "}\n",
      "[X] Finding Candidate concepts\n",
      "\tCandidates: ['deepM3: 0.3', 'top: 0.1', 'bottom: 0.1', 'left: 0.1', 'right: 0.1']\n",
      "[X] Selecting best candidate above similarity of 0.8\n",
      "\tBest candidate concept name: NONE\n",
      "[X] Instantiating novel concept\n",
      "[X] Binding novel concept\n",
      "[X] Extracting Properties\n",
      "\tDescriptors: [{'text': '6500 degrees', 'arguments': ['VAR0']}]\n",
      "Debug: candidates: ['this:0.1', 'conveyor:0.1', 'work area:0.1', 'screw feeder:0.1', 'it:0.1']\n",
      "[X] Finding Consultants properties similar to SPC\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'VAR0': 'INDEFINITE'}\n",
      "Utterance: 6500 degrees\n",
      "PARSE: wantbel(brad,high(VAR0),{NONE(VAR0),INDEFINITE(VAR0)})\n",
      "==================================\n",
      "\n",
      "======== ITEM 5 ============\n",
      "Utterance: pose screw feeder\n",
      "DesiredSemantics: UNKNOWN(brad,self:agent,pose(VAR0),{screw feeder(VAR0),DEFINITE(VAR0)})\n",
      "\n",
      "Processing utterance: pose screw feeder\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"screw feeder\",\n",
      "    \"type\": \"physobj\",\n",
      "    \"role\": \"central\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"want\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"pose\",\n",
      "    \"type\": \"action\"\n",
      "  }\n",
      "}\n",
      "[X] Finding Candidate actions\n",
      "\tCandidate actions: ['gotoCamerapose:0.7', 'goToPose:0.7', 'goToPoseLong:0.7', 'gotocamerapose:0.7', 'moveToCameraHeight:0.5']\n",
      "[X] Selecting best candidate\n",
      "\tBest candidate action name: NONE\n",
      "[X] Extracting Propertiese\n",
      "\tDescriptors: [{'text': 'screw feeder', 'arguments': ['central']}]\n",
      "Debug: candidates: ['screw feeder:1', 'conveyor:0.5', 'work area:0.3', 'prop:0.2', 'bottle:0.1']\n",
      "[X] Finding Consultants properties similar to SPC\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'screw feeder': 'INDEFINITE'}\n",
      "Utterance: pose screw feeder\n",
      "PARSE: want(brad,NONE,{screw feeder(central)})\n",
      "==================================\n",
      "\n",
      "======== ITEM 6 ============\n",
      "Utterance: i will teach you how to screw a screw into a hole\n",
      "DesiredSemantics: STATEMENT(brad,self:agent,want(brad,updateActionLearning(self:agent,screwIn(self:agent,screw,hole(_24822)),start)),{hole(VAR0),DEFINITE(VAR0)})\n",
      "\n",
      "Processing utterance: i will teach you how to screw a screw into a hole\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"screw\",\n",
      "    \"type\": \"physobj\",\n",
      "    \"role\": \"central\"\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"hole\",\n",
      "    \"type\": \"location\",\n",
      "    \"role\": \"supplemental\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"wantbel\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"teaching\",\n",
      "    \"type\": \"concept\"\n",
      "  }\n",
      "}\n",
      "[X] Finding Candidate concepts\n",
      "\tCandidates: ['doit: 0.5', 'dothis: 0.6', 'dothat: 0.6', 'that: 0.4', 'this: 0.4']\n",
      "[X] Selecting best candidate above similarity of 0.8\n",
      "\tBest candidate concept name: NONE\n",
      "[X] Instantiating novel concept\n",
      "[X] Binding novel concept\n",
      "We have a problem. There is a unbound variable here:\n",
      "{\"name\": \"teaching\", \"bindings\": [{\"VAR0\": \"self\"}, {\"VAR1\": \"NONE\"}, {\"VAR2\": \"physobj\"}, {\"VAR3\": \"location\"}]}\n",
      "[X] Extracting Properties\n",
      "\tDescriptors: [{'text': 'screw', 'arguments': ['VAR1']}, {'text': 'hole', 'arguments': ['VAR2']}, {'text': 'into', 'arguments': ['VAR1', 'VAR2']}]\n",
      "Debug: candidates: ['screw feeder:0.8', 'hole:0.6', 'm3:0.5', 'deepM3:0.5', 'prop:0.4']\n",
      "Debug: candidates: ['hole:1', 'prop:0.2', 'bottle:0.1', 'thing:0.3', 'these:0.1']\n",
      "Debug: candidates: ['conveyor:0.2', 'screw feeder:0.5', 'hole:0.8', 'prop:0.1', 'bottle:0.1']\n",
      "[X] Finding Consultants properties similar to SPC\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'screw': 'INDEFINITE', 'hole': 'INDEFINITE'}\n",
      "Utterance: i will teach you how to screw a screw into a hole\n",
      "PARSE: wantbel(brad,teaching(self,VAR1,VAR2,VAR3),{NONE(VAR1),hole(VAR2),NONE(VAR1,VAR2)})\n",
      "==================================\n",
      "\n",
      "======== ITEM 7 ============\n",
      "Utterance: first verify that you can see the hole\n",
      "DesiredSemantics: INSTRUCT(brad,self:agent,want(brad,perceiveEntity(self:agent,VAR0)),{hole(VAR0),DEFINITE(VAR0)})\n",
      "\n",
      "Processing utterance: first verify that you can see the hole\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"hole\",\n",
      "    \"type\": \"physobj\",\n",
      "    \"role\": \"central\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"itk\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"verify\",\n",
      "    \"type\": \"concept\"\n",
      "  }\n",
      "}\n",
      "[X] Finding Candidate concepts\n",
      "\tCandidates: ['conveyor:0.1', 'work area:0.2', 'screw feeder:0.1', 'doit:0.3', 'dothis:0.4']\n",
      "[X] Selecting best candidate above similarity of 0.8\n",
      "\tBest candidate concept name: NONE\n",
      "[X] Instantiating novel concept\n",
      "[X] Binding novel concept\n",
      "We have a problem. There is a unbound variable here:\n",
      "{\n",
      "  \"name\": \"verify\",\n",
      "  \"bindings\": [\n",
      "    {\"VAR0\": \"self\"},\n",
      "    {\"VAR1\": \"hole\"},\n",
      "    {\"VAR2\": \"NONE\"}\n",
      "  ]\n",
      "}\n",
      "[X] Extracting Properties\n",
      "\tDescriptors: [{'text': 'hole', 'arguments': ['VAR1']}, {'text': 'see', 'arguments': ['self', 'VAR1']}, {'text': 'first', 'arguments': ['VAR2']}]\n",
      "Debug: candidates: ['hole:1', 'this:0.2', 'that:0.2', 'thing:0.3', 'these:0.2']\n",
      "Debug: candidates: ['hole:1', 'this:0.5', 'that:0.5', 'thing:0.5', 'these:0.5']\n",
      "Debug: candidates: ['this:0.2', 'it:0.2', 'that:0.2', 'thing:0.2', 'these:0.2']\n",
      "[X] Finding Consultants properties similar to SPC\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'VAR1': 'DEFINITE'}\n",
      "Utterance: first verify that you can see the hole\n",
      "PARSE: itk(brad,verify(self,VAR1,VAR2),{hole(VAR1),hole(self,VAR1),NONE(VAR2),DEFINITE(VAR1)})\n",
      "==================================\n",
      "\n",
      "======== ITEM 8 ============\n",
      "Utterance: then mount the screw\n",
      "DesiredSemantics: INSTRUCT(brad,self:agent,want(brad,mountScrew(self:agent,screw)),{})\n",
      "\n",
      "Processing utterance: then mount the screw\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"screw\",\n",
      "    \"type\": \"physobj\",\n",
      "    \"role\": \"central\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"want\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"mount\",\n",
      "    \"type\": \"action\"\n",
      "  }\n",
      "}\n",
      "[X] Finding Candidate actions\n",
      "\tCandidate actions: ['grab:0.3', 'putdown:0.2', 'pickUp:0.4', 'mountSingleScrew:0.8', 'mountScrew:0.9']\n",
      "[X] Selecting best candidate\n",
      "\tBest candidate action name: mountScrew\n",
      "Central ref: {'text': 'screw', 'type': 'physobj', 'role': 'central'}\n",
      "[X] Binding best candidate\n",
      "\tBound candidate: {'name': 'mountScrew', 'bindings': [{'VAR0': 'self'}, {'VAR1': 'screw'}]}\n",
      "[X] Extracting Properties\n",
      "\tDescriptors: [{'text': 'screw', 'arguments': ['VAR1']}]\n",
      "Debug: candidates: ['screw feeder:0.8', 'hole:0.6', 'm3:0.5', 'deepM3:0.5', 'prop:0.4']\n",
      "[X] Finding Consultants properties similar to SPC\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'VAR1': 'DEFINITE'}\n",
      "Utterance: then mount the screw\n",
      "PARSE: want(brad,mountScrew(self,VAR1),{NONE(VAR1),DEFINITE(VAR1)})\n",
      "==================================\n",
      "\n",
      "======== ITEM 9 ============\n",
      "Utterance: then align with the hole\n",
      "DesiredSemantics: INSTRUCT(brad,self:agent,want(brad,alignWith(self:agent,VAR0)),{hole(VAR0),DEFINITE(VAR0)})\n",
      "\n",
      "Processing utterance: then align with the hole\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"hole\",\n",
      "    \"type\": \"physobj\",\n",
      "    \"role\": \"central\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"want\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"align\",\n",
      "    \"type\": \"action\"\n",
      "  }\n",
      "}\n",
      "[X] Finding Candidate actions\n",
      "\tCandidate actions: ['alignWith:1', 'gotoCamerapose:0.3', 'goToPose:0.3', 'goToPoseLong:0.3', 'gotocamerapose:0.3']\n",
      "[X] Selecting best candidate\n",
      "\tBest candidate action name: alignWith\n",
      "Central ref: {'text': 'hole', 'type': 'physobj', 'role': 'central'}\n",
      "[X] Binding best candidate\n",
      "\tBound candidate: {'name': 'alignWith', 'bindings': [{'VAR0': 'self'}, {'VAR1': 'hole'}]}\n",
      "[X] Extracting Properties\n",
      "\tDescriptors: [{'text': 'hole', 'arguments': ['VAR1']}]\n",
      "Debug: candidates: ['hole:1', 'this:0.2', 'that:0.2', 'thing:0.3', 'these:0.2']\n",
      "[X] Finding Consultants properties similar to SPC\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'VAR1': 'DEFINITE'}\n",
      "Utterance: then align with the hole\n",
      "PARSE: want(brad,alignWith(self,VAR1),{hole(VAR1),DEFINITE(VAR1)})\n",
      "==================================\n",
      "\n",
      "======== ITEM 10 ============\n",
      "Utterance: then run the screwdriver job of the screw\n",
      "DesiredSemantics: INSTRUCT(brad,self:agent,want(brad,runScrewdriverJob(self:agent,screw)),{})\n",
      "\n",
      "Processing utterance: then run the screwdriver job of the screw\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"screwdriver job\",\n",
      "    \"type\": \"action\",\n",
      "    \"role\": \"central\"\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"screw\",\n",
      "    \"type\": \"physobj.\",\n",
      "    \"role\": \"supplemental\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"want\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"perform\",\n",
      "    \"type\": \"action\"\n",
      "  }\n",
      "}\n",
      "[X] Finding Candidate actions\n",
      "\tCandidate actions: ['achieveState:0.6', 'grab:0.5', 'putdown:0.5', 'runScrewdriverJob:0.8', 'assemble:0.5']\n",
      "[X] Selecting best candidate\n",
      "\tBest candidate action name: NONE\n",
      "[X] Extracting Propertiese\n",
      "\tDescriptors: [{'text': 'screwdriver job', 'arguments': ['action']}, {'text': 'screw', 'arguments': ['physobj.']}]\n",
      "Debug: candidates: ['screw feeder: 0.6', 'work area: 0.3', 'conveyor: 0.2', 'hole: 0.4', 'prop: 0.3']\n",
      "Debug: candidates: ['screw feeder:0.8', 'hole:0.6', 'm3:0.5', 'deepM3:0.5', 'prop:0.4']\n",
      "[X] Finding Consultants properties similar to SPC\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'screwdriver job': 'DEFINITE', 'screw': 'DEFINITE'}\n",
      "Utterance: then run the screwdriver job of the screw\n",
      "PARSE: want(brad,NONE,{NONE(action),NONE(physobj.)})\n",
      "==================================\n",
      "\n",
      "======== ITEM 11 ============\n",
      "Utterance: that is how you screw a screw into a hole\n",
      "DesiredSemantics: STATEMENT(brad,self:agent,want(brad,updateActionLearning(self:agent,screwIn(self:agent,screw,hole(_54297)),end)),{hole(VAR0),DEFINITE(VAR0)})\n",
      "\n",
      "Processing utterance: that is how you screw a screw into a hole\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"screw\",\n",
      "    \"type\": \"physobj\",\n",
      "    \"role\": \"central\"\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"hole\",\n",
      "    \"type\": \"location\",\n",
      "    \"role\": \"supplemental\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"wantbel\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"insertion\",\n",
      "    \"type\": \"concept\"\n",
      "  }\n",
      "}\n",
      "[X] Finding Candidate concepts\n",
      "\tCandidates: ['screw feeder:0.4', 'hole:0.6', 'm3:0.2', 'deepM3:0.3', 'prop:0.1']\n",
      "[X] Selecting best candidate above similarity of 0.8\n",
      "\tBest candidate concept name: NONE\n",
      "[X] Instantiating novel concept\n",
      "[X] Binding novel concept\n",
      "[X] Extracting Properties\n",
      "\tDescriptors: [{'text': 'screw', 'arguments': ['VAR0']}, {'text': 'hole', 'arguments': ['VAR2']}]\n",
      "Debug: candidates: ['screw feeder:0.8', 'hole:0.6', 'm3:0.5', 'deepM3:0.5', 'prop:0.4']\n",
      "Debug: candidates: ['hole:1', 'screw feeder:0.5', 'work area:0.3', 'conveyor:0.2', 'prop:0.1']\n",
      "[X] Finding Consultants properties similar to SPC\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'VAR0': 'ACTIVATED', 'VAR2': 'INDEFINITE'}\n",
      "Utterance: that is how you screw a screw into a hole\n",
      "PARSE: wantbel(brad,insertion(VAR0,self,VAR2),{NONE(VAR0),hole(VAR2),ACTIVATED(VAR0),INDEFINITE(VAR2)})\n",
      "==================================\n",
      "\n",
      "======== ITEM 12 ============\n",
      "Utterance: define new item nfsv\n",
      "DesiredSemantics: INSTRUCT(brad,self:agent,want(brad,defineItem(self:agent,nfsv)),{})\n",
      "\n",
      "Processing utterance: define new item nfsv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"new item nfsv\",\n",
      "    \"type\": \"string\",\n",
      "    \"role\": \"central\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"itk\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"definition\",\n",
      "    \"type\": \"concept\"\n",
      "  }\n",
      "}\n",
      "[X] Finding Candidate concepts\n",
      "\tCandidates: ['conveyor:0.2', 'work area:0.3', 'screw feeder:0.4', 'hole:0.1', 'bottle:0.1']\n",
      "[X] Selecting best candidate above similarity of 0.8\n",
      "\tBest candidate concept name: NONE\n",
      "[X] Instantiating novel concept\n",
      "[X] Binding novel concept\n",
      "[X] Extracting Properties\n",
      "\tDescriptors: [{'text': 'new item nfsv', 'arguments': ['VAR0']}]\n",
      "Debug: candidates: ['conveyor: 0.2', 'work area: 0.2', 'screw feeder: 0.2', 'hole: 0.3', 'bottle: 0.3']\n",
      "[X] Finding Consultants properties similar to SPC\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'VAR0': 'INDEFINITE'}\n",
      "Utterance: define new item nfsv\n",
      "PARSE: itk(brad,definition(VAR0),{NONE(VAR0),INDEFINITE(VAR0)})\n",
      "==================================\n",
      "\n",
      "======== ITEM 13 ============\n",
      "Utterance: job circuit breaker face\n",
      "DesiredSemantics: UNKNOWN(brad,self:agent,job(cbDet),{})\n",
      "\n",
      "Processing utterance: job circuit breaker face\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"circuit breaker\",\n",
      "    \"type\": \"physobj\",\n",
      "    \"role\": \"central\"\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"job\",\n",
      "    \"type\": \"agent\",\n",
      "    \"role\": \"supplemental\"\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"face\",\n",
      "    \"type\": \"physobj\",\n",
      "    \"role\": \"supplemental\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"itk\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"face\",\n",
      "    \"type\": \"concept\"\n",
      "  }\n",
      "}\n",
      "[X] Finding Candidate concepts\n",
      "\tCandidates: ['hole:0.2', 'left:0.1', 'right:0.1', 'top:0.1', 'bottom:0.1']\n",
      "[X] Selecting best candidate above similarity of 0.8\n",
      "\tBest candidate concept name: NONE\n",
      "[X] Instantiating novel concept\n",
      "[X] Binding novel concept\n",
      "We have a problem. There is a unbound variable here:\n",
      "{\n",
      "  \"name\": \"face\",\n",
      "  \"bindings\": [\n",
      "    {\"VAR0\": \"circuit breaker\"},\n",
      "    {\"VAR1\": \"job\"},\n",
      "    {\"VAR2\": \"NONE\"}\n",
      "  ]\n",
      "}\n",
      "[X] Extracting Properties\n",
      "\tDescriptors: [{'text': 'circuit breaker', 'arguments': ['VAR0']}, {'text': 'job', 'arguments': ['VAR1']}, {'text': 'face', 'arguments': ['VAR2']}]\n",
      "Debug: candidates: ['conveyor: 0.2', 'work area: 0.3', 'screw feeder: 0.25', 'hole: 0.15', 'bottle: 0.1']\n",
      "Debug: candidates: ['conveyor:0.3', 'work area:0.4', 'screw feeder:0.2', 'prop:0.1', 'bottle:0.1']\n",
      "Debug: candidates: ['conveyor: 0.2', 'work area: 0.2', 'screw feeder: 0.2', 'hole: 0.4', 'prop: 0.3']\n",
      "[X] Finding Consultants properties similar to SPC\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'VAR0': 'INDEFINITE', 'VAR1': 'INDEFINITE', 'face': 'INDEFINITE'}\n",
      "Utterance: job circuit breaker face\n",
      "PARSE: itk(brad,face(VAR0,VAR1,VAR2),{NONE(VAR0),NONE(VAR1),NONE(VAR2),INDEFINITE(VAR0),INDEFINITE(VAR1)})\n",
      "==================================\n",
      "\n",
      "======== ITEM 14 ============\n",
      "Utterance: i will teach you how to assemble a nfsv\n",
      "DesiredSemantics: INSTRUCT(brad,self:agent,want(brad,startLearningAssembleScript(self:agent,VAR0)),{nfsv(VAR0),DEFINITE(VAR0)})\n",
      "\n",
      "Processing utterance: i will teach you how to assemble a nfsv\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"nfsv\",\n",
      "    \"type\": \"physobj\",\n",
      "    \"role\": \"central\"\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"you\",\n",
      "    \"type\": \"agent\",\n",
      "    \"role\": \"supplemental\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"wantbel\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"teach\",\n",
      "    \"type\": \"concept\"\n",
      "  }\n",
      "}\n",
      "[X] Finding Candidate concepts\n",
      "\tCandidates: ['doit: 0.3', 'dothis: 0.4', 'dothat: 0.4', 'prop: 0.2', 'bottle: 0.1']\n",
      "[X] Selecting best candidate above similarity of 0.8\n",
      "\tBest candidate concept name: NONE\n",
      "[X] Instantiating novel concept\n",
      "[X] Binding novel concept\n",
      "We have a problem. There is a unbound variable here:\n",
      "{\"name\": \"teach\", \"bindings\": [{\"VAR0\": \"self\"}, {\"VAR1\": \"nfsv\"}, {\"VAR2\": \"NONE\"}]}\n",
      "[X] Extracting Properties\n",
      "\tDescriptors: [{'text': 'assemble', 'arguments': ['VAR1']}, {'text': 'how', 'arguments': ['VAR1']}]\n",
      "Debug: candidates: ['conveyor: 0.2', 'work area: 0.2', 'screw feeder: 0.3', 'hole: 0.1', 'prop: 0.1']\n",
      "Debug: candidates: ['conveyor: 0.1', 'work area: 0.1', 'screw feeder: 0.1', 'hole: 0.1', 'prop: 0.1']\n",
      "[X] Finding Consultants properties similar to SPC\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'VAR1': 'INDEFINITE', 'you': 'ACTIVATED'}\n",
      "Utterance: i will teach you how to assemble a nfsv\n",
      "PARSE: wantbel(brad,teach(self,VAR1,VAR2),{NONE(VAR1),NONE(VAR1),INDEFINITE(VAR1)})\n",
      "==================================\n",
      "\n",
      "======== ITEM 15 ============\n",
      "Utterance: first go to pose conveyor\n",
      "DesiredSemantics: INSTRUCT(brad,self:agent,want(brad,gotoCamerapose(self:agent,VAR0)),{conveyor(VAR0),DEFINITE(VAR0)})\n",
      "\n",
      "Processing utterance: first go to pose conveyor\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"pose conveyor\",\n",
      "    \"type\": \"location\",\n",
      "    \"role\": \"central\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"want\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"go\",\n",
      "    \"type\": \"action\"\n",
      "  }\n",
      "}\n",
      "[X] Finding Candidate actions\n",
      "\tCandidate actions: ['goToPose:0.9', 'gotoCamerapose:0.8', 'goToPoseLong:0.8', 'gotocamerapose:0.8', 'goToPoseLong:0.8']\n",
      "[X] Selecting best candidate\n",
      "\tBest candidate action name: goToPose\n",
      "Central ref: {'text': 'pose conveyor', 'type': 'location', 'role': 'central'}\n",
      "We have a problem. There is a unbound variable here:\n",
      "{\n",
      "\"name\": \"goToPose\",\n",
      "\"bindings\": [\n",
      "    {\"VAR0\": \"self\"},\n",
      "    {\"VAR1\": \"pose conveyor\"},\n",
      "    {\"VAR2\": \"NONE\"}\n",
      "]\n",
      "}\n",
      "[X] Binding best candidate\n",
      "\tBound candidate: {'name': 'goToPose', 'bindings': [{'VAR0': 'self'}, {'VAR1': 'pose conveyor'}, {'VAR2': 'NONE'}]}\n",
      "[X] Extracting Properties\n",
      "\tDescriptors: [{'text': 'first', 'arguments': ['VAR1']}]\n",
      "Debug: candidates: ['conveyor:0.8', 'work area:0.2', 'screw feeder:0.1', 'hole:0.1', 'bottle:0.1']\n",
      "[X] Finding Consultants properties similar to SPC\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'VAR1': 'INDEFINITE'}\n",
      "Utterance: first go to pose conveyor\n",
      "PARSE: want(brad,goToPose(self,VAR1,VAR2),{NONE(VAR1),INDEFINITE(VAR1)})\n",
      "==================================\n",
      "\n",
      "======== ITEM 16 ============\n",
      "Utterance: then verify that you can see the nfsv\n",
      "DesiredSemantics: INSTRUCT(brad,self:agent,want(brad,perceiveEntity(self:agent,VAR0)),{nfsv(VAR0),DEFINITE(VAR0)})\n",
      "\n",
      "Processing utterance: then verify that you can see the nfsv\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"nfsv\",\n",
      "    \"type\": \"string\",\n",
      "    \"role\": \"central\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"itk\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"see\",\n",
      "    \"type\": \"concept\"\n",
      "  }\n",
      "}\n",
      "[X] Finding Candidate concepts\n",
      "\tCandidates: ['conveyor:0.2', 'work area:0.3', 'screw feeder:0.1', 'hole:0.1', 'bottle:0.1']\n",
      "[X] Selecting best candidate above similarity of 0.8\n",
      "\tBest candidate concept name: NONE\n",
      "[X] Instantiating novel concept\n",
      "[X] Binding novel concept\n",
      "We have a problem. There is a unbound variable here:\n",
      "{\n",
      "  \"name\": \"see\",\n",
      "  \"bindings\": [\n",
      "    {\"VAR0\": \"self\"},\n",
      "    {\"VAR1\": \"nfsv\"},\n",
      "    {\"VAR2\": \"NONE\"}\n",
      "  ]\n",
      "}\n",
      "[X] Extracting Properties\n",
      "\tDescriptors: [{'text': 'verify', 'arguments': ['self', 'VAR1']}]\n",
      "Debug: candidates: ['conveyor:0.2', 'work area:0.3', 'screw feeder:0.2', 'hole:0.1', 'nfsv:0.8']\n",
      "[X] Finding Consultants properties similar to SPC\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'VAR1': 'DEFINITE'}\n",
      "Utterance: then verify that you can see the nfsv\n",
      "PARSE: itk(brad,see(self,VAR1,VAR2),{NONE(self,VAR1),DEFINITE(VAR1)})\n",
      "==================================\n",
      "\n",
      "======== ITEM 17 ============\n",
      "Utterance: then get the nfsv on the work area\n",
      "DesiredSemantics: INSTRUCT(brad,self:agent,want(brad,getOn(self:agent,VAR0,VAR1)),{nfsv(VAR0),work area(VAR1),DEFINITE(VAR0),DEFINITE(VAR1)})\n",
      "\n",
      "Processing utterance: then get the nfsv on the work area\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"nfsv\",\n",
      "    \"type\": \"action\",\n",
      "    \"role\": \"central\"\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"work area\",\n",
      "    \"type\": \"location.\",\n",
      "    \"role\": \"supplemental\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"want\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"place\",\n",
      "    \"type\": \"action\"\n",
      "  }\n",
      "}\n",
      "[X] Finding Candidate actions\n",
      "\tCandidate actions: ['getOn:0.6', 'putDown:0.5', 'moveConveyorForward:0.3', 'moveConveyorBackward:0.3', 'goToPose:0.2']\n",
      "[X] Selecting best candidate\n",
      "\tBest candidate action name: NONE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[X] Extracting Propertiese\n",
      "\tDescriptors: [{'text': 'nfsv', 'arguments': ['action']}, {'text': 'work area', 'arguments': ['location.']}]\n",
      "Debug: candidates: ['nfsv:1', 'bottle:0.2', 'prop:0.1', 'hole:0.1', 'm3:0.1']\n",
      "Debug: candidates: ['work area:1', 'conveyor:0.5', 'screw feeder:0.5', 'hole:0.3', 'bottle:0.3']\n",
      "[X] Finding Consultants properties similar to SPC\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'nfsv': 'DEFINITE', 'work area': 'DEFINITE'}\n",
      "Utterance: then get the nfsv on the work area\n",
      "PARSE: want(brad,NONE,{nfsv(action),work area(location.)})\n",
      "==================================\n",
      "\n",
      "======== ITEM 18 ============\n",
      "Utterance: then search for 2 m3 holes\n",
      "DesiredSemantics: INSTRUCT(brad,self:agent,want(brad,observeDescriptor(self:agent,m3,2)),{})\n",
      "\n",
      "Processing utterance: then search for 2 m3 holes\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"2 m3 holes\",\n",
      "    \"type\": \"physobj\",\n",
      "    \"role\": \"central\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"want\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"search\",\n",
      "    \"type\": \"action\"\n",
      "  }\n",
      "}\n",
      "[X] Finding Candidate actions\n",
      "\tCandidate actions: ['observeDescriptor:0.6', 'perceiveEntity:0.6', 'perceiveEntityFromSymbol:0.6', 'bindResultsRecursive:0.4', 'alignWith:0.4']\n",
      "[X] Selecting best candidate\n",
      "\tBest candidate action name: NONE\n",
      "[X] Extracting Propertiese\n",
      "\tDescriptors: [{'text': '2 m3 holes', 'arguments': ['physobj']}]\n",
      "Debug: candidates: ['m3: 1', 'hole: 0.9', 'deepM3: 0.8', 'prop: 0.2', 'bottle: 0.1']\n",
      "[X] Finding Consultants properties similar to SPC\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'2 m3 holes': 'INDEFINITE'}\n",
      "Utterance: then search for 2 m3 holes\n",
      "PARSE: want(brad,NONE,{m3(physobj)})\n",
      "==================================\n",
      "\n",
      "======== ITEM 19 ============\n",
      "Utterance: screw a m3 screw into the left m3 hole\n",
      "DesiredSemantics: INSTRUCT(brad,self:agent,want(brad,screwIn(self:agent,m3,VAR0)),{m3(VAR0),left(VAR0),DEFINITE(VAR0)})\n",
      "\n",
      "Processing utterance: screw a m3 screw into the left m3 hole\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"m3 screw\",\n",
      "    \"type\": \"physobj\",\n",
      "    \"role\": \"central\"\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"left m3 hole\",\n",
      "    \"type\": \"location.\",\n",
      "    \"role\": \"supplemental\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"want\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"screw\",\n",
      "    \"type\": \"action\"\n",
      "  }\n",
      "}\n",
      "[X] Finding Candidate actions\n",
      "\tCandidate actions: ['grab:0.3', 'putdown:0.3', 'runScrewdriverJob:0.7', 'screwScrew:0.9', 'mountScrew:0.6']\n",
      "[X] Selecting best candidate\n",
      "\tBest candidate action name: screwScrew\n",
      "Central ref: {'text': 'm3 screw', 'type': 'physobj', 'role': 'central'}\n",
      "[X] Binding best candidate\n",
      "\tBound candidate: {'name': 'screwScrew', 'bindings': [{'VAR0': 'self'}, {'VAR1': 'm3 screw'}, {'VAR2': 'left m3 hole'}]}\n",
      "[X] Extracting Properties\n",
      "\tDescriptors: [{'text': 'm3 screw', 'arguments': ['VAR1']}, {'text': 'left m3 hole', 'arguments': ['VAR2']}]\n",
      "Debug: candidates: ['screw feeder: 0.6', 'm3: 0.9', 'deepM3: 0.8', 'left: 0.3', 'prop: 0.2']\n",
      "Debug: candidates: ['hole: 0.8', 'm3: 0.9', 'left: 0.9', 'deepM3: 0.7', 'prop: 0.6']\n",
      "[X] Finding Consultants properties similar to SPC\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'VAR1': 'INDEFINITE', 'VAR2': 'DEFINITE'}\n",
      "Utterance: screw a m3 screw into the left m3 hole\n",
      "PARSE: want(brad,screwScrew(self,VAR1,VAR2),{m3(VAR1),m3(VAR2),INDEFINITE(VAR1),DEFINITE(VAR2)})\n",
      "==================================\n",
      "\n",
      "======== ITEM 20 ============\n",
      "Utterance: then go to pose work area\n",
      "DesiredSemantics: INSTRUCT(brad,self:agent,want(brad,gotoCamerapose(self:agent,VAR0)),{work area(VAR0),DEFINITE(VAR0)})\n",
      "\n",
      "Processing utterance: then go to pose work area\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"pose work area\",\n",
      "    \"type\": \"location\",\n",
      "    \"role\": \"central\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"want\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"go\",\n",
      "    \"type\": \"action\"\n",
      "  }\n",
      "}\n",
      "[X] Finding Candidate actions\n",
      "\tCandidate actions: ['gotoCamerapose:0.8', 'goToPose:1.0', 'goToPoseLong:0.8', 'gotocamerapose:0.8', 'goToPoseLong:0.8']\n",
      "[X] Selecting best candidate\n",
      "\tBest candidate action name: goToPose\n",
      "Central ref: {'text': 'pose work area', 'type': 'location', 'role': 'central'}\n",
      "We have a problem. There is a unbound variable here:\n",
      "{\n",
      "  \"name\": \"goToPose\",\n",
      "  \"bindings\": [\n",
      "    {\"VAR0\": \"self\"},\n",
      "    {\"VAR1\": \"pose work area\"},\n",
      "    {\"VAR2\": \"NONE\"}\n",
      "  ]\n",
      "}\n",
      "[X] Binding best candidate\n",
      "\tBound candidate: {'name': 'goToPose', 'bindings': [{'VAR0': 'self'}, {'VAR1': 'pose work area'}, {'VAR2': 'NONE'}]}\n",
      "[X] Extracting Properties\n",
      "\tDescriptors: []\n",
      "[X] Finding Consultants properties similar to SPC of the Descriptors\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'VAR1': 'INDEFINITE'}\n",
      "Utterance: then go to pose work area\n",
      "PARSE: want(brad,goToPose(self,VAR1,VAR2),{INDEFINITE(VAR1)})\n",
      "==================================\n",
      "\n",
      "======== ITEM 21 ============\n",
      "Utterance: screw a m3 screw into the right m3 hole\n",
      "DesiredSemantics: INSTRUCT(brad,self:agent,want(brad,screwIn(self:agent,m3,VAR0)),{m3(VAR0),right(VAR0),DEFINITE(VAR0)})\n",
      "\n",
      "Processing utterance: screw a m3 screw into the right m3 hole\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"m3 screw\",\n",
      "    \"type\": \"physobj\",\n",
      "    \"role\": \"central\"\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"right m3 hole\",\n",
      "    \"type\": \"location.\",\n",
      "    \"role\": \"supplemental\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"want\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"screw\",\n",
      "    \"type\": \"action\"\n",
      "  }\n",
      "}\n",
      "[X] Finding Candidate actions\n",
      "\tCandidate actions: ['grab:0.3', 'putdown:0.2', 'runScrewdriverJob:0.6', 'screwScrew:0.9', 'mountScrew:0.5']\n",
      "[X] Selecting best candidate\n",
      "\tBest candidate action name: screwScrew\n",
      "Central ref: {'text': 'm3 screw', 'type': 'physobj', 'role': 'central'}\n",
      "[X] Binding best candidate\n",
      "\tBound candidate: {'name': 'screwScrew', 'bindings': [{'VAR0': 'self'}, {'VAR1': 'm3 screw'}, {'VAR2': 'right m3 hole'}]}\n",
      "[X] Extracting Properties\n",
      "\tDescriptors: [{'text': 'm3 screw', 'arguments': ['VAR1']}, {'text': 'right m3 hole', 'arguments': ['VAR2']}]\n",
      "Debug: candidates: ['screw feeder: 0.6', 'm3: 0.8', 'deepM3: 0.7', 'right: 0.5', 'prop: 0.4']\n",
      "Debug: candidates: ['hole: 0.8', 'm3: 0.9', 'right: 0.9', 'deepM3: 0.7', 'prop: 0.6']\n",
      "[X] Finding Consultants properties similar to SPC\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'VAR1': 'INDEFINITE', 'VAR2': 'DEFINITE'}\n",
      "Utterance: screw a m3 screw into the right m3 hole\n",
      "PARSE: want(brad,screwScrew(self,VAR1,VAR2),{NONE(VAR1),m3(VAR2),INDEFINITE(VAR1),DEFINITE(VAR2)})\n",
      "==================================\n",
      "\n",
      "======== ITEM 22 ============\n",
      "Utterance: then get the nfsv on the conveyor\n",
      "DesiredSemantics: INSTRUCT(brad,self:agent,want(brad,getOn(self:agent,VAR0,VAR1)),{nfsv(VAR0),conveyor(VAR1),DEFINITE(VAR0),DEFINITE(VAR1)})\n",
      "\n",
      "Processing utterance: then get the nfsv on the conveyor\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"nfsv\",\n",
      "    \"type\": \"name\",\n",
      "    \"role\": \"central\"\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"conveyor\",\n",
      "    \"type\": \"physobj.\",\n",
      "    \"role\": \"supplemental\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"want\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"get\",\n",
      "    \"type\": \"action\"\n",
      "  }\n",
      "}\n",
      "[X] Finding Candidate actions\n",
      "\tCandidate actions: ['getActDesc:0.8', 'getRefForJob:0.8', 'getTime:0.6', 'getCurrGoals:0.6', 'getContextDescription:0.6']\n",
      "[X] Selecting best candidate\n",
      "\tBest candidate action name: NONE\n",
      "[X] Extracting Propertiese\n",
      "\tDescriptors: [{'text': 'nfsv', 'arguments': ['central']}, {'text': 'conveyor', 'arguments': ['supplemental']}]\n",
      "Debug: candidates: ['nfsv:1', 'conveyor:0.5', 'work area:0.2', 'screw feeder:0.2', 'bottle:0.1']\n",
      "Debug: candidates: ['conveyor:1', 'work area:0.5', 'screw feeder:0.3', 'hole:0.1', 'bottle:0.1']\n",
      "[X] Finding Consultants properties similar to SPC\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'nfsv': 'DEFINITE', 'conveyor': 'DEFINITE'}\n",
      "Utterance: then get the nfsv on the conveyor\n",
      "PARSE: want(brad,NONE,{nfsv(central),conveyor(supplemental)})\n",
      "==================================\n",
      "\n",
      "======== ITEM 23 ============\n",
      "Utterance: then advance the conveyor belt\n",
      "DesiredSemantics: INSTRUCT(brad,self:agent,want(brad,moveConveyorForward(self:agent)),{})\n",
      "\n",
      "Processing utterance: then advance the conveyor belt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"conveyor belt\",\n",
      "    \"type\": \"physobj\",\n",
      "    \"role\": \"central\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"want\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"advance\",\n",
      "    \"type\": \"action\"\n",
      "  }\n",
      "}\n",
      "[X] Finding Candidate actions\n",
      "\tCandidate actions: ['moveConveyorForward:0.8', 'moveConveyorBackward:0.4', 'gotoCamerapose:0.2', 'goToPose:0.2', 'goToPoseLong:0.2']\n",
      "[X] Selecting best candidate\n",
      "\tBest candidate action name: NONE\n",
      "[X] Extracting Propertiese\n",
      "\tDescriptors: [{'text': 'conveyor belt', 'arguments': ['physobj']}]\n",
      "Debug: candidates: ['conveyor:1', 'work area:0.5', 'screw feeder:0.5', 'hole:0.2', 'bottle:0.2']\n",
      "[X] Finding Consultants properties similar to SPC\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'conveyor belt': 'DEFINITE'}\n",
      "Utterance: then advance the conveyor belt\n",
      "PARSE: want(brad,NONE,{conveyor(physobj)})\n",
      "==================================\n",
      "\n",
      "======== ITEM 24 ============\n",
      "Utterance: that is how you assemble a nfsv\n",
      "DesiredSemantics: INSTRUCT(brad,self:agent,want(brad,endLearningAssembleScript(self:agent,VAR0))),{nfsv(VAR0),DEFINITE(VAR0)})\n",
      "\n",
      "Processing utterance: that is how you assemble a nfsv\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"nfsv\",\n",
      "    \"type\": \"NONE\",\n",
      "    \"role\": \"central\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"wantbel\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"assemble\",\n",
      "    \"type\": \"concept\"\n",
      "  }\n",
      "}\n",
      "[X] Finding Candidate concepts\n",
      "\tCandidates: ['conveyor:0.2', 'work area:0.1', 'screw feeder:0.3', 'prop:0.1', 'bottle:0.1']\n",
      "[X] Selecting best candidate above similarity of 0.8\n",
      "\tBest candidate concept name: NONE\n",
      "[X] Instantiating novel concept\n",
      "[X] Binding novel concept\n",
      "We have a problem. There is a unbound variable here:\n",
      "{\n",
      "  \"name\": \"assemble\",\n",
      "  \"bindings\": [\n",
      "    {\"VAR0\": \"self\"},\n",
      "    {\"VAR1\": \"nfsv\"},\n",
      "    {\"VAR2\": \"NONE\"},\n",
      "    {\"VAR3\": \"NONE\"}\n",
      "  ]\n",
      "}\n",
      "[X] Extracting Properties\n",
      "\tDescriptors: [{'text': 'nfsv', 'arguments': ['VAR1']}]\n",
      "Debug: candidates: ['nfsv:1', 'bottle:0.5', 'screw feeder:0.3', 'conveyor:0.2', 'work area:0.1']\n",
      "[X] Finding Consultants properties similar to SPC\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'VAR1': 'INDEFINITE'}\n",
      "Utterance: that is how you assemble a nfsv\n",
      "PARSE: wantbel(brad,assemble(self,VAR1,VAR2,VAR3),{nfsv(VAR1),INDEFINITE(VAR1)})\n",
      "==================================\n",
      "\n",
      "======== ITEM 25 ============\n",
      "Utterance: assemble a nfsv\n",
      "DesiredSemantics: INSTRUCT(brad,self:agent,want(brad,assemble(self:agent,VAR0)),{nfsv(VAR0),DEFINITE(VAR0)})\n",
      "\n",
      "Processing utterance: assemble a nfsv\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"nfsv\",\n",
      "    \"type\": \"string\",\n",
      "    \"role\": \"central\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"want\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"assemble\",\n",
      "    \"type\": \"action\"\n",
      "  }\n",
      "}\n",
      "[X] Finding Candidate actions\n",
      "\tCandidate actions: ['assemble:1', 'assembleVision:0.7', 'startLearningAssembleScript:0.6', 'endLearningAssembleScript:0.6', 'modifyAssemble:0.5']\n",
      "[X] Selecting best candidate\n",
      "\tBest candidate action name: assemble\n",
      "Central ref: {'text': 'nfsv', 'type': 'string', 'role': 'central'}\n",
      "[X] Binding best candidate\n",
      "\tBound candidate: {'name': 'assemble', 'bindings': [{'VAR0': 'self'}, {'VAR1': 'nfsv'}]}\n",
      "[X] Extracting Properties\n",
      "\tDescriptors: [{'text': 'nfsv', 'arguments': ['VAR1']}]\n",
      "Debug: candidates: ['nfsv:1', 'bottle:0.5', 'prop:0.5', 'hole:0.3', 'm3:0.3']\n",
      "[X] Finding Consultants properties similar to SPC\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'VAR1': 'INDEFINITE'}\n",
      "Utterance: assemble a nfsv\n",
      "PARSE: want(brad,assemble(self,VAR1),{nfsv(VAR1),INDEFINITE(VAR1)})\n",
      "==================================\n",
      "\n",
      "======== ITEM 26 ============\n",
      "Utterance: define new item nvfau\n",
      "DesiredSemantics: INSTRUCT(brad,self:agent,want(brad,defineItem(self:agent,nvfau)),{})\n",
      "\n",
      "Processing utterance: define new item nvfau\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"new item nvfau\",\n",
      "    \"type\": \"name\",\n",
      "    \"role\": \"central\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"want\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"define\",\n",
      "    \"type\": \"action\"\n",
      "  }\n",
      "}\n",
      "[X] Finding Candidate actions\n",
      "\tCandidate actions: ['defineItem:0.9', 'defineScrewType:0.6', 'believeFact:0.3', 'believeRule:0.3', 'updateParam:0.2']\n",
      "[X] Selecting best candidate\n",
      "\tBest candidate action name: defineItem\n",
      "Central ref: {'text': 'new item nvfau', 'type': 'name', 'role': 'central'}\n",
      "[X] Binding best candidate\n",
      "\tBound candidate: {'name': 'defineItem', 'bindings': [{'VAR0': 'self'}, {'VAR1': 'new item nvfau'}]}\n",
      "[X] Extracting Properties\n",
      "\tDescriptors: [{'text': 'new item nvfau', 'arguments': ['VAR1']}]\n",
      "Debug: candidates: ['new item nvfau:1', 'thing:0.5', 'prop:0.5', 'bottle:0.5', 'nfsv:0.5']\n",
      "[X] Finding Consultants properties similar to SPC\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'VAR1': 'INDEFINITE'}\n",
      "Utterance: define new item nvfau\n",
      "PARSE: want(brad,defineItem(self,VAR1),{new item nvfau(VAR1),INDEFINITE(VAR1)})\n",
      "==================================\n",
      "\n",
      "======== ITEM 27 ============\n",
      "Utterance: job n v face\n",
      "DesiredSemantics: UNKNOWN(brad,self:agent,job(nvDet),{})\n",
      "\n",
      "Processing utterance: job n v face\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"job\",\n",
      "    \"type\": \"action\",\n",
      "    \"role\": \"central\"\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"face\",\n",
      "    \"type\": \"physobj.\",\n",
      "    \"role\": \"supplemental\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"itk\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"face\",\n",
      "    \"type\": \"concept\"\n",
      "  }\n",
      "}\n",
      "[X] Finding Candidate concepts\n",
      "\tCandidates: ['conveyor:0.2', 'screw feeder:0.1', 'hole:0.3', 'prop:0.1', 'bottle:0.1']\n",
      "[X] Selecting best candidate above similarity of 0.8\n",
      "\tBest candidate concept name: NONE\n",
      "[X] Instantiating novel concept\n",
      "[X] Binding novel concept\n",
      "[X] Extracting Properties\n",
      "\tDescriptors: [{'text': 'job', 'arguments': ['VAR0']}, {'text': 'face', 'arguments': ['VAR1']}]\n",
      "Debug: candidates: ['conveyor:0.3', 'work area:0.4', 'screw feeder:0.2', 'hole:0.1', 'bottle:0.1']\n",
      "Debug: candidates: ['work area: 0.2', 'hole: 0.3', 'left: 0.1', 'right: 0.1', 'top: 0.1']\n",
      "[X] Finding Consultants properties similar to SPC\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'VAR0': 'INDEFINITE', 'VAR1': 'INDEFINITE'}\n",
      "Utterance: job n v face\n",
      "PARSE: itk(brad,face_job(VAR0,VAR1),{NONE(VAR0),NONE(VAR1),INDEFINITE(VAR0),INDEFINITE(VAR1)})\n",
      "==================================\n",
      "\n",
      "======== ITEM 28 ============\n",
      "Utterance: assemble an nvfau is like assemble an nfsv\n",
      "DesiredSemantics: INSTRUCT(brad,self:agent,want(brad,modifyAssemble(self:agent,assemble(self:agent,VAR0),assemble(self:agent,VAR1))),{nvfau(VAR0),nfsv(VAR1),DEFINITE(VAR0),DEFINITE(VAR1)})\n",
      "\n",
      "Processing utterance: assemble an nvfau is like assemble an nfsv\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"nvfau and nfsv\",\n",
      "    \"type\": \"NONE\",\n",
      "    \"role\": \"central\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"wantbel\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"similarity\",\n",
      "    \"type\": \"concept\"\n",
      "  }\n",
      "}\n",
      "[X] Finding Candidate concepts\n",
      "\tCandidates: ['conveyor:0.3', 'work area:0.3', 'screw feeder:0.3', 'hole:0.3', 'bottle:0.3']\n",
      "[X] Selecting best candidate above similarity of 0.8\n",
      "\tBest candidate concept name: NONE\n",
      "[X] Instantiating novel concept\n",
      "[X] Binding novel concept\n",
      "[X] Extracting Properties\n",
      "\tDescriptors: [{'text': 'nvfau', 'arguments': ['VAR0']}, {'text': 'nfsv', 'arguments': ['VAR1']}, {'text': 'assemble', 'arguments': ['VAR0']}, {'text': 'assemble', 'arguments': ['VAR1']}]\n",
      "Debug: candidates: ['nvfau:1', 'nfsv:0.8', 'bottle:0.2', 'prop:0.1', 'hole:0.1']\n",
      "Debug: candidates: ['nfsv:1', 'bottle:0.2', 'prop:0.1', 'hole:0.1', 'm3:0.1']\n",
      "Debug: candidates: ['conveyor:0.3', 'work area:0.2', 'screw feeder:0.4', 'doit:0.5', 'dothis:0.5']\n",
      "Debug: candidates: ['conveyor:0.3', 'work area:0.3', 'screw feeder:0.3', 'doit:0.5', 'dothis:0.5']\n",
      "[X] Finding Consultants properties similar to SPC\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'nvfau and nfsv': 'INDEFINITE'}\n",
      "Utterance: assemble an nvfau is like assemble an nfsv\n",
      "PARSE: wantbel(brad,similarity(VAR0,VAR1),{nvfau(VAR0),nfsv(VAR1),NONE(VAR0),NONE(VAR1)})\n",
      "==================================\n",
      "\n",
      "======== ITEM 29 ============\n",
      "Utterance: replace search for 2 m3 holes with search for 2 deep m3 holes\n",
      "DesiredSemantics: UNKNOWN(brad,self:agent,mod(replace(observeDescriptor(self:agent,deepM3,2),observeDescriptor(self:agent,m3,2))),{})\n",
      "\n",
      "Processing utterance: replace search for 2 m3 holes with search for 2 deep m3 holes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"search for 2 deep m3 holes\",\n",
      "    \"type\": \"action\",\n",
      "    \"role\": \"central\"\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"search for 2 m3 holes\",\n",
      "    \"type\": \"action.\",\n",
      "    \"role\": \"supplemental\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"want\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"replace\",\n",
      "    \"type\": \"action\"\n",
      "  }\n",
      "}\n",
      "[X] Finding Candidate actions\n",
      "\tCandidate actions: ['modifyAssemble:0.6', 'updateParam:0.5', 'defineScrewType:0.4', 'defineItem:0.4', 'believeFact:0.3']\n",
      "[X] Selecting best candidate\n",
      "\tBest candidate action name: NONE\n",
      "[X] Extracting Propertiese\n",
      "\tDescriptors: [{'text': 'search for 2 deep m3 holes', 'arguments': ['central']}, {'text': 'search for 2 m3 holes', 'arguments': ['supplemental']}, {'text': 'deep', 'arguments': ['central']}]\n",
      "Debug: candidates: ['hole:0.8', 'm3:0.9', 'deepM3:1.0', 'prop:0.6', 'bottle:0.5']\n",
      "Debug: candidates: ['m3: 0.9', 'deepM3: 0.95', 'hole: 0.8', 'prop: 0.6', 'bottle: 0.5']\n",
      "Debug: candidates: ['deepM3: 0.9', 'hole: 0.7', 'bottom: 0.6', 'top: 0.5', 'left: 0.4']\n",
      "[X] Finding Consultants properties similar to SPC\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'search for 2 deep m3 holes': 'INDEFINITE', 'search for 2 m3 holes': 'INDEFINITE'}\n",
      "Utterance: replace search for 2 m3 holes with search for 2 deep m3 holes\n",
      "PARSE: want(brad,NONE,{deepM3(central),deepM3(supplemental),deepM3(central)})\n",
      "==================================\n",
      "\n",
      "======== ITEM 30 ============\n",
      "Utterance: replace screw an m3 screw into the left m3 hole with screw an m3 screw into the bottom deep m3 hole\n",
      "DesiredSemantics: UNKNOWN(brad,self:agent,mod(replace(screwIn(self:agent,m3,VAR1),screwIn(self:agent,m3,VAR0))),{m3(VAR0),left(VAR0),deepM3(VAR1),bottom(VAR1),DEFINITE(VAR0),DEFINITE(VAR1)})\n",
      "\n",
      "Processing utterance: replace screw an m3 screw into the left m3 hole with screw an m3 screw into the bottom deep m3 hole\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"m3 screw\",\n",
      "    \"type\": \"physobj\",\n",
      "    \"role\": \"central\"\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"left m3 hole\",\n",
      "    \"type\": \"physobj.\",\n",
      "    \"role\": \"supplemental\"\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"bottom deep m3 hole\",\n",
      "    \"type\": \"location.\",\n",
      "    \"role\": \"supplemental\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"want\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"replace\",\n",
      "    \"type\": \"action\"\n",
      "  }\n",
      "}\n",
      "[X] Finding Candidate actions\n",
      "\tCandidate actions: ['modifyAssemble:0.6', 'undoThenDo:0.4', 'supersedeCurrentGoal:0.4', 'supersedeAndUndo:0.4', 'updateParam:0.3']\n",
      "[X] Selecting best candidate\n",
      "\tBest candidate action name: NONE\n",
      "[X] Extracting Propertiese\n",
      "\tDescriptors: [{'text': 'm3 screw', 'arguments': ['central']}, {'text': 'left m3 hole', 'arguments': ['supplemental']}, {'text': 'bottom deep m3 hole', 'arguments': ['supplemental']}, {'text': 'into', 'arguments': ['central', 'supplemental']}]\n",
      "Debug: candidates: ['screw feeder: 0.8', 'm3: 0.9', 'deepM3: 0.7', 'prop: 0.6', 'bottle: 0.5']\n",
      "Debug: candidates: ['left:0.9', 'hole:0.8', 'm3:0.8', 'bottom:0.5', 'deepM3:0.5']\n",
      "Debug: candidates: ['hole: 0.8', 'deepM3: 0.9', 'bottom: 0.9', 'm3: 0.8', 'prop: 0.6']\n",
      "Debug: candidates: ['conveyor:0.2', 'work area:0.2', 'screw feeder:0.3', 'hole:0.5', 'prop:0.2']\n",
      "[X] Finding Consultants properties similar to SPC\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'m3 screw': 'INDEFINITE', 'left m3 hole': 'DEFINITE', 'bottom deep m3 hole': 'DEFINITE'}\n",
      "Utterance: replace screw an m3 screw into the left m3 hole with screw an m3 screw into the bottom deep m3 hole\n",
      "PARSE: want(brad,NONE,{m3(central),left(supplemental),deepM3(supplemental),NONE(central,supplemental)})\n",
      "==================================\n",
      "\n",
      "======== ITEM 31 ============\n",
      "Utterance: replace screw an m3 screw into the right m3 hole with screw an m3 screw into the top deep m3 hole\n",
      "DesiredSemantics: UNKNOWN(brad,self:agent,mod(replace(screwIn(self:agent,m3,VAR1),screwIn(self:agent,m3,VAR0))),{m3(VAR0),right(VAR0),deepM3(VAR1),top(VAR1),DEFINITE(VAR0),DEFINITE(VAR1)})\n",
      "\n",
      "Processing utterance: replace screw an m3 screw into the right m3 hole with screw an m3 screw into the top deep m3 hole\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"m3 screw\",\n",
      "    \"type\": \"physobj\",\n",
      "    \"role\": \"central\"\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"right m3 hole\",\n",
      "    \"type\": \"physobj.\",\n",
      "    \"role\": \"supplemental\"\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"top deep m3 hole\",\n",
      "    \"type\": \"location.\",\n",
      "    \"role\": \"supplemental\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"want\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"replace\",\n",
      "    \"type\": \"action\"\n",
      "  }\n",
      "}\n",
      "[X] Finding Candidate actions\n",
      "\tCandidate actions: ['modifyAssemble:0.6', 'undoThenDo:0.4', 'supersedeCurrentGoal:0.4', 'supersedeAndUndo:0.4', 'updateParam:0.3']\n",
      "[X] Selecting best candidate\n",
      "\tBest candidate action name: NONE\n",
      "[X] Extracting Propertiese\n",
      "\tDescriptors: [{'text': 'm3 screw', 'arguments': ['central']}, {'text': 'right m3 hole', 'arguments': ['supplemental']}, {'text': 'top deep m3 hole', 'arguments': ['supplemental']}]\n",
      "Debug: candidates: ['m3:0.9', 'deepM3:0.8', 'hole:0.7', 'screw feeder:0.6', 'prop:0.5']\n",
      "Debug: candidates: ['hole: 0.8', 'm3: 0.9', 'deepM3: 0.7', 'right: 1.0', 'top: 0.6']\n",
      "Debug: candidates: ['hole: 0.8', 'deepM3: 0.9', 'top: 0.7', 'm3: 0.6', 'prop: 0.5']\n",
      "[X] Finding Consultants properties similar to SPC\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'m3 screw': 'INDEFINITE', 'right m3 hole': 'DEFINITE', 'top deep m3 hole': 'DEFINITE'}\n",
      "Utterance: replace screw an m3 screw into the right m3 hole with screw an m3 screw into the top deep m3 hole\n",
      "PARSE: want(brad,NONE,{m3(central),right(supplemental),deepM3(supplemental)})\n",
      "==================================\n",
      "\n",
      "======== ITEM 32 ============\n",
      "Utterance: that is all\n",
      "DesiredSemantics: UNKNOWN(brad,self:agent,mod(none),{})\n",
      "\n",
      "Processing utterance: that is all\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"n/a\",\n",
      "    \"type\": \"NONE\",\n",
      "    \"role\": \"central\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"itk\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"completion\",\n",
      "    \"type\": \"concept\"\n",
      "  }\n",
      "}\n",
      "[X] Finding Candidate concepts\n",
      "\tCandidates: ['conveyor:0.2', 'work area:0.3', 'screw feeder:0.2', 'prop:0.1', 'bottle:0.1']\n",
      "[X] Selecting best candidate above similarity of 0.8\n",
      "\tBest candidate concept name: NONE\n",
      "[X] Instantiating novel concept\n",
      "[X] Binding novel concept\n",
      "[X] Extracting Properties\n",
      "\tDescriptors: []\n",
      "[X] Finding Consultants properties similar to SPC of the Descriptors\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'n/a': 'ACTIVATED'}\n",
      "Utterance: that is all\n",
      "PARSE: itk(brad,completion(),{})\n",
      "==================================\n",
      "\n",
      "======== ITEM 33 ============\n",
      "Utterance: assemble an nvfau\n",
      "DesiredSemantics: INSTRUCT(brad,self:agent,want(brad,assemble(self:agent,VAR0)),{nvfau(VAR0),DEFINITE(VAR0)})\n",
      "\n",
      "Processing utterance: assemble an nvfau\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"nvfau\",\n",
      "    \"type\": \"NONE\",\n",
      "    \"role\": \"central\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"want\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"assemble\",\n",
      "    \"type\": \"action\"\n",
      "  }\n",
      "}\n",
      "[X] Finding Candidate actions\n",
      "\tCandidate actions: ['assemble:1', 'startLearningAssembleScript:0.8', 'endLearningAssembleScript:0.8', 'assembleVision:0.6', 'modifyAssemble:0.5']\n",
      "[X] Selecting best candidate\n",
      "\tBest candidate action name: assemble\n",
      "Central ref: {'text': 'nvfau', 'type': 'NONE', 'role': 'central'}\n",
      "[X] Binding best candidate\n",
      "\tBound candidate: {'name': 'assemble', 'bindings': [{'VAR0': 'self'}, {'VAR1': 'nvfau'}]}\n",
      "[X] Extracting Properties\n",
      "\tDescriptors: []\n",
      "[X] Finding Consultants properties similar to SPC of the Descriptors\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'VAR1': 'INDEFINITE'}\n",
      "Utterance: assemble an nvfau\n",
      "PARSE: want(brad,assemble(self,VAR1),{INDEFINITE(VAR1)})\n",
      "==================================\n"
     ]
    }
   ],
   "source": [
    "outputs=[]\n",
    "parses = []\n",
    "for idx,item in enumerate(dataset.data):\n",
    "    print(f\"\\n======== ITEM {idx} ============\")\n",
    "    print(f\"Utterance: {item['utterance']}\")\n",
    "    print(f\"DesiredSemantics: {item['desired_semantics']}\")\n",
    "    output = parse(utterance=item['utterance'],robot_model=item['robot_model'])\n",
    "    output['desired_semantics'] = item['desired_semantics']\n",
    "    outputs.append(output)\n",
    "    parses.append(output['parse'])\n",
    "    \n",
    "    # Throw into a file\n",
    "    with open('../data/output/out.json', 'w') as fout:\n",
    "        json.dump(outputs, fout, indent=4, sort_keys=True)\n",
    "    print(\"==================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "323b8855",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/output/out.json\", \"r\") as fin:\n",
    "    results = json.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7d827378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "176f7bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_parses = []\n",
    "for r in results:\n",
    "    item  = f\"{r['utterance']}, {r['parse']}, {r['desired_semantics']}\"\n",
    "    result_parses.append(item)\n",
    "\n",
    "with open(\"../data/output/result_parses.csv\", \"w\") as fout:\n",
    "    for line in result_parses:\n",
    "        fout.write(f\"{line}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f51016a",
   "metadata": {},
   "source": [
    "# Next steps\n",
    "\n",
    "- think about how to generalize this for PDDL\n",
    "    \n",
    "- the action/concept repertoire seems to be off here...many utterances are not supported by the underlying model \n",
    "- think about  what the two papers will look like\n",
    "    - constraint understanding --> challenge here is for formal verifiability? \n",
    "    - parsing --> challenge here is to define an NLP pipeline that can ground human-robot interactions. \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
