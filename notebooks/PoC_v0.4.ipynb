{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be2c88d9",
   "metadata": {},
   "source": [
    "# Version 4\n",
    "6/22/2023\n",
    "\n",
    "New  data structure for the parsing. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8426730",
   "metadata": {},
   "source": [
    "```\n",
    "        referents = [\n",
    "            {\"text\": \"m3 screw\", \n",
    "            \"type\": \"physobj\",\n",
    "            \"variable_name\": \"VAR0\",\n",
    "            \"cognitive status\": \"ACTIVATED\",\n",
    "            \"role\": \"central\"},\n",
    "            \n",
    "            {\"text\": \"evan\", \n",
    "            \"type\": \"agent\",\n",
    "            \"variable_name\": \"VAR1\",\n",
    "            \"cognitive status\": \"FAMILIAR\",\n",
    "            \"role\": \"supplemental\"}\n",
    "            ]\n",
    "            \n",
    "        descriptors = [\n",
    "            {\"text\": \"m3 screw\", \n",
    "            \"name\": \"m3\",\n",
    "            \"arguments\": [\"VAR0\"] },\n",
    "            \n",
    "            {\"text\": \"evan\", \n",
    "            \"name\": \"NONE\",\n",
    "            \"arguments\": [] }\n",
    "            ]\n",
    "        \n",
    "        intention: {\n",
    "            \"speech_act\": \"wantBel\",\n",
    "            \"proposition\":\n",
    "                {\"text\": belonging\",\n",
    "                \"type\": \"concept\",\n",
    "                \"arguments\": [\"VAR0\", \"VAR1\"]}\n",
    "            }\n",
    "               \n",
    "            \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40f4a32",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b09c865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\r\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI,ChatAnthropic\n",
    "from langchain.chains import LLMChain\n",
    "import json\n",
    "\n",
    "!echo $OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652c69d8",
   "metadata": {},
   "source": [
    "# Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "382f737a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a list of dictionaries, and a key, return the entry in the list that matches\n",
    "def find_dict_in_list(lst, key, target):\n",
    "    for item in lst:\n",
    "        if not key in item:\n",
    "            #print(\"Key not in Dict\")\n",
    "            return None\n",
    "        if item[key] == target:\n",
    "            return item\n",
    "    #print(\"Nothing found\")\n",
    "    return None\n",
    "\n",
    "def find_all_dicts_in_list(lst, key, target):\n",
    "    output = []\n",
    "    for item in lst:\n",
    "        if not key in item:\n",
    "            return output\n",
    "        if item[key] == target:\n",
    "            output.append(item)\n",
    "    #print(\"Nothing found\")\n",
    "    return output\n",
    "    \n",
    "\n",
    "def clean_candidates(candidates):\n",
    "    \"\"\"\n",
    "    Cleans the list of candidates to extract a list of names and a list of scores of the candidates\n",
    "    \"\"\"\n",
    "    names = []\n",
    "    scores = []\n",
    "    for candidate in candidates:\n",
    "        name = candidate.split(\":\")[0]\n",
    "        score = float(candidate.split(\":\")[1])\n",
    "        names.append(name)\n",
    "        scores.append(score)\n",
    "        \n",
    "    return names, scores\n",
    "\n",
    "\n",
    "def prune_candidates(names, scores, threshold=0.75):\n",
    "    return [(x,y) for x,y in zip(names,scores) if y > threshold ]\n",
    "\n",
    "def select_best_candidate(names, scores, threshold=0.75):\n",
    "    \"\"\"\n",
    "    Selects best name and score above a threshold. \n",
    "    \"\"\"\n",
    "    pruned_names = []\n",
    "    pruned_scores = []\n",
    "    for n,s in zip(names,scores):\n",
    "        if s>threshold:\n",
    "            pruned_names.append(n)\n",
    "            pruned_scores.append(s)\n",
    "    \n",
    "    if pruned_names:\n",
    "        return pruned_names[pruned_scores.index(max(pruned_scores))]\n",
    "    return \"NONE\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae2ef044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More helper functions GMR\n",
    "\n",
    "def central_referent(gmr):\n",
    "    return find_dict_in_list(gmr['referents'], \"role\", \"central\")\n",
    "\n",
    "def supp_referents(gmr):\n",
    "    return find_all_dicts_in_list(gmr['referents'], \"role\", \"supplemental\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca542a0c",
   "metadata": {},
   "source": [
    "# Initialize LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7b3cdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.0)\n",
    "#llm = OpenAI(temperature=0.0)\n",
    "#llm = Anthropic(model=\"claude-instant-1.1-100k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1079388a",
   "metadata": {},
   "source": [
    "# Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "212e7678",
   "metadata": {},
   "outputs": [],
   "source": [
    "## (1) Speech Act Classification \n",
    "\n",
    "template_speech_act= \"\"\"\n",
    "Decide whether the utterance below from a speaker to a listener is one of \"want\", \"wantBel\", \"itk\"\n",
    "A \"want\" is an imperative statement or a request by the speaker to have the listener do an action or stop doing an action.\n",
    "An \"itk\" is a 'wh' or 'yes/no' query (what, why, when, where, who) or request from a speaker for more information from the listener about the listeners knowledge, beliefs or perceptions\n",
    "A \"wantBel\" (note the uppercase B) is a statement of fact or opinion that the speaker conveys to a listener and  expects to listener to come to believe. \n",
    "\n",
    "\n",
    "\n",
    "utterance: \\n{utterance}\\n\n",
    "act:\n",
    "\"\"\"\n",
    "\n",
    "prompt_speech_act = PromptTemplate(\n",
    "    input_variables=[\"utterance\"],\n",
    "    template=template_speech_act\n",
    ")\n",
    "\n",
    "chain_speech_act = LLMChain(llm=llm, prompt=prompt_speech_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be062373",
   "metadata": {},
   "outputs": [],
   "source": [
    "## (2) Central Referents \n",
    "\n",
    "template_centralref = \"\"\"\n",
    "What is the central item (which could be a single thing or a collection of things) that is being referred to in the below sentence?\n",
    "\n",
    "Remember, the central referent is a thing or object, not an action or descriptor.It is meant to capture the central real world item being referenced in the utterance. \n",
    "\n",
    "\n",
    "sentence: \\n{utterance}\\n \n",
    "referent:\n",
    "\"\"\"\n",
    "\n",
    "prompt_centralref = PromptTemplate(\n",
    "    input_variables=[\"utterance\"],\n",
    "    template=template_centralref\n",
    ")\n",
    "\n",
    "chain_centralref = LLMChain(llm=llm, prompt=prompt_centralref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f731b719",
   "metadata": {},
   "outputs": [],
   "source": [
    "## (3) Supporting Referents\n",
    "\n",
    "template_suppref = \"\"\"\n",
    "What are some objects (which could be a single thing or a collection of things) that is being referred to in the below sentence not including the central referent? Return as a python list.\n",
    "If none, then return empty list []. Even if only one item, return as a list.  \n",
    "Remember, the supporting referents are things or objects, not actions or descriptors. They are meant to capture the real world items being referenced in the utterance. \n",
    "\n",
    "Do NOT include objects or collections that have already been covered in the central referent. \n",
    "\n",
    "sentence: \\n{utterance}\\n \n",
    "central referent: \\n{centralref}\\n\n",
    "supporting referents (noun(s) from utterance):\n",
    "\"\"\"\n",
    "\n",
    "prompt_suppref = PromptTemplate(\n",
    "    input_variables=[\"utterance\", \"centralref\"],\n",
    "    template=template_suppref\n",
    ")\n",
    "\n",
    "chain_suppref = LLMChain(llm=llm, prompt=prompt_suppref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b95d451",
   "metadata": {},
   "outputs": [],
   "source": [
    "## (4) Getting the type of thing that the referents are \n",
    "\n",
    "template_typeof = \"\"\"\n",
    "Determine whether or not the referent item mentioned below in the context of the provided utterance is one of the types also provided below. To check if the referent is of a type, follow the below procedure\n",
    "1. Iterate through each item mentioned in the list of types. \n",
    "2. For each item X in the list of types expand on the meaning of each item, and then ask if the central referent is of type X given that meaning. \n",
    "3. If the central referent is of type X in the list, return X.\n",
    "\n",
    "\\n\\n EXAMPLE \\n\n",
    "utterance: The lemon is on the table\n",
    "referent: lemon\n",
    "types: ['area', 'physobj', 'location', 'pose']\n",
    "typeOf: Looking through the items in the list of types above. physobj is a physical object. lemon is a type of physical object. So, it is of type physobj\n",
    "\n",
    "Remember, return specifically ONE of the items in the list, or if none apply then return NONE. \n",
    "\n",
    "utterance: \\n{utterance}\\n\n",
    "referent: \\n{ref}\\n\n",
    "types: \\n{types}\\n\n",
    "typeOf:\n",
    "\"\"\"\n",
    "\n",
    "prompt_typeof = PromptTemplate(\n",
    "    input_variables=[\"ref\", \"types\", \"utterance\"],\n",
    "    template=template_typeof\n",
    ")\n",
    "\n",
    "chain_typeof = LLMChain(llm=llm, prompt=prompt_typeof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2261958",
   "metadata": {},
   "outputs": [],
   "source": [
    "## (5) Extract CPC\n",
    "\n",
    "template_cpc = \"\"\"\n",
    "Determine the core propositional content (cpc) of the utterance below in the context of its central referent and speech act type\n",
    "To do so, use the following procedure\n",
    "\n",
    "1. Determine the type of cpc (\"action\", \"concept\") associated with the utterance.\n",
    "If the speech act is a \"want\" that means the utterance is an imperative and the cpc is an \"action\".\n",
    "If the speech act is a \"wantBel\" (note the capital B) that means the utterance is a statement assertion, and the cpc will be a \"concept\"\n",
    "If the speech act is an \"itk\" that means the utterance contains a question about some concept, so the cpc is a \"concept\"\n",
    "\n",
    "2. If the type of cpc is an \"action\", then the core propositional content (or cpc) is the action that is being performed on the central referent.\n",
    "If the type of cpc is a \"concept\", then the core propositional content (or cpc) is a concept that is being associated with the central referent.\n",
    "\n",
    "3. Convert the cpc into a single representative word that captures its meaning, without any reference to the referents.\n",
    "\n",
    "4. return the converted cpc and its type in the following format \"<CPC>:<TYPE>\" \n",
    "\n",
    "utterance: \\n{utterance}\\n\n",
    "speech act: \\n{speechact}\\n\n",
    "central referent: \\n{centralref}\n",
    "core propositional content and:\n",
    "\"\"\"\n",
    "\n",
    "prompt_cpc = PromptTemplate(\n",
    "    input_variables=[\"centralref\", \"utterance\",\"speechact\"],\n",
    "    template=template_cpc\n",
    ")\n",
    "\n",
    "chain_cpc = LLMChain(llm=llm, prompt=prompt_cpc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce026e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## (6) Candidate Real Actions \n",
    "## \"Real\" == actions implemented in the robot system. \n",
    "\"\"\"\n",
    "Approach: look to see if there exists an action that captures this.\n",
    "\n",
    "Criteria\n",
    "(1) Semantic similarity of Name \n",
    "(2) The arguments in the robot action exist in the linguistic parse. If not then we are either in the wrong action or we are missing an action\n",
    "\"\"\"\n",
    "\n",
    "template_candidate_realactions =\"\"\"\n",
    "Select a list of 5 candidate actions from the list of available actions that is most relevant to the core action performed on the central referent as understood in the context of the utterance. \n",
    "\n",
    "To decide the list of applicable candidate actions, use the following procedure to systematically filter the list of available actions:\n",
    "1. Compare the name and description (if any) of each action in the available actions to the core action. Narrow the list of actions to include only those with a semantically similar name or description to the central action. \n",
    "2. Return the narrowed list of actions as a python list of string action names followed by a colon and then a numeric score between 0 and 1 signifying the semantic similarity between the name or description and the central action.\n",
    "For example \"move:0.5\" where \"move\" is the action name and 0.5 is the similarity score. \n",
    "\n",
    "\\n\\n LIST OF AVAILABLE ACTIONS \\n:\n",
    "{actions}\n",
    "\n",
    "utterance: \\n{utterance}\\n\n",
    "central referent: \\n{centralref}\\n\n",
    "core action: \\n{cpc}\\n\n",
    "candidate actions:\n",
    "\"\"\"\n",
    "\n",
    "prompt_candidate_realactions = PromptTemplate(\n",
    "    input_variables=[\"centralref\", \"utterance\",\"cpc\", \"actions\"],\n",
    "    template=template_candidate_realactions\n",
    ")\n",
    "\n",
    "chain_candidate_realactions = LLMChain(llm=llm, prompt=prompt_candidate_realactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "986ae067",
   "metadata": {},
   "outputs": [],
   "source": [
    "## (7) Tether Real Action\n",
    "# provided a list of realarguments, bind referents to them. \n",
    "\n",
    "template_bound_action = \"\"\"\n",
    "Try to bind the candidate action's arguments to the central and supplementary referents. Use the following procedure:\n",
    "1. Look at the candidate action's arguments in order written as \"VAR<NUM>:<TYPE>\". If the first argument is of TYPE \"agent\", then bind that to \"self\".\n",
    "2. For the second argument (if it exists), if the central referent is an object of  type TYPE in the argument, then bind the central referent to the TYPE. If not, bind to NONE. \n",
    "3. For  any subsequent arguments, attempt to bind the supplementary referents in the same way. \n",
    "4. Return output as a python dictionary, with following format (Do NOT include any special characters like newlines):\n",
    "\"name\": \"<NAME OF THE ACTION>\",\"bindings\": [{{\"<VARIABLE NAME (E.g.VAR0)>\": \"<REFERENT>\"}}, ...]\n",
    "\n",
    "\n",
    "utterance: \\n{utterance}\\n\n",
    "central referent: \\n{centralref}\\n\n",
    "supplementary referents: \\n{supprefs}\\n\n",
    "candidate action: \\n{candidate_full_info}\\n\n",
    "bound action:\n",
    "\"\"\"\n",
    "\n",
    "prompt_bound_action = PromptTemplate(\n",
    "    input_variables=[\"centralref\", \"supprefs\", \"utterance\",\"candidate_full_info\"],\n",
    "    template=template_bound_action\n",
    ")\n",
    "\n",
    "chain_bound_action = LLMChain(llm=llm, prompt=prompt_bound_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f16d7de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## (6b) Candidate Real Concepts\n",
    "## \"Real\" == concepts understandable to a robotic system (some consultant exists for it)\n",
    "\"\"\"\n",
    "Approach: look to see if there exists an action that captures this.\n",
    "\n",
    "Criteria\n",
    "(1) Semantic similarity of Name \n",
    "(2) The arguments in the concept exist in the linguistic parse. If not then we are either in the wrong action or we are missing an action\n",
    "\"\"\"\n",
    "\n",
    "template_candidate_realconcepts=\"\"\"\n",
    "Select a list of 5 candidate concept from the list of available concepts that is most relevant to the core concept associated with the central referent as understood in the context of the utterance. \n",
    "\n",
    "To decide the list of applicable candidate concepts, use the following procedure to systematically filter the list of available concepts:\n",
    "1. Compare the name and description (if any) of each concept in the available concepts to the core concepts. Narrow the list of concepts to include only those with a semantically similar name or description to ONLY the core concept. \n",
    "2. Return the narrowed list of concepts as a python list of string concept names followed by a colon and then a numeric score between 0 and 1 signifying the semantic similarity between the name or description of the available concepts and the core concept. Do NOT return this as a dictionary\n",
    "\n",
    "\\n\\n LIST OF AVAILABLE CONCEPTS \\n:\n",
    "{concepts}\n",
    "\n",
    "utterance: \\n{utterance}\\n\n",
    "central referent: \\n{centralref}\\n\n",
    "core concept: \\n{cpc}\\n\n",
    "candidate concepts:\n",
    "\"\"\"\n",
    "\n",
    "prompt_candidate_realconcepts = PromptTemplate(\n",
    "    input_variables=[\"centralref\", \"utterance\",\"cpc\", \"concepts\"],\n",
    "    template=template_candidate_realconcepts\n",
    ")\n",
    "\n",
    "chain_candidate_realconcepts = LLMChain(llm=llm, prompt=prompt_candidate_realconcepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29e8d37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## (7b) Tether Real Concept, if available\n",
    "# provided a list of realarguments, bind referents to them. \n",
    "\n",
    "template_bound_concept = \"\"\"\n",
    "Try to bind each candidate concept's arguments to the central and supplementary referents. Use the following procedure:\n",
    "For each candidate concept: \n",
    "1. Look at its arguments in order written as \"VAR<NUM>:<TYPE>\". If the first argument is of TYPE \"agent\", then bind that to \"self\".\n",
    "2. For the second argument (if it exists), if the central referent is an object of  type TYPE in the argument, then bind the central referent to the TYPE. If not, bind to NONE. \n",
    "3. For  any subsequent arguments, attempt to bind the supplementary referents in the same way. \n",
    "4. Return output as a python dictionary, with following format (Do NOT include any special characters like newlines):\n",
    "\"name\": \"<NAME OF THE CONCEPT>\",\"bindings\": [{{\"<VARIABLE NAME (E.g.VAR0)>\": \"<REFERENT>\"}}, ...]\n",
    "\n",
    "utterance: \\n{utterance}\\n\n",
    "central referent: \\n{centralref}\\n\n",
    "supplementary referents: \\n{supprefs}\\n\n",
    "candidate concepts: \\n{candidate_full_info}\\n\n",
    "bound concept:\n",
    "\"\"\"\n",
    "\n",
    "prompt_bound_concept = PromptTemplate(\n",
    "    input_variables=[\"centralref\", \"supprefs\", \"utterance\",\"candidate_full_info\"],\n",
    "    template=template_bound_concept\n",
    ")\n",
    "\n",
    "chain_bound_concept = LLMChain(llm=llm, prompt=prompt_bound_concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "caa8ca34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (8) Novel concept induction\n",
    "\n",
    "template_novel_concept = \"\"\"\n",
    "Generate a concept template for the core concept within the context of the utterance. Use the following procedure:\n",
    "\n",
    "1. Extract a concept name. The name can be from the core concept itself. \n",
    "2. Generate a list of arguments, where each argument states the type of argument that can be bound to the concept.\n",
    "Here, we want to make sure that each argument type makes sense for the concept, and also can be bound to the central referent and zero or more of the supplemental references.\n",
    "\n",
    "Return output as a python dictionary, with following format (Do NOT include any special characters like newlines):\n",
    "\"name\": \"<NAME OF THE CORE CONCEPT>\",\"roles\": [{{\"<VARIABLE NAME (E.g.VAR0)>\": \"<TYPE>\"}}, ...]\n",
    "\n",
    "\n",
    "utterance: \\n{utterance}\\n\n",
    "core concept: \\n{cpc}\\n\n",
    "types: \\n{types}\\n\n",
    "central referent: \\n{centralref}\\n\n",
    "supplementary referents: \\n{supprefs}\\n\n",
    "novel concept: \n",
    "\"\"\"\n",
    "\n",
    "prompt_novel_concept = PromptTemplate(\n",
    "    input_variables=[\"centralref\", \"supprefs\", \"utterance\", \"cpc\", \"types\"],\n",
    "    template=template_novel_concept\n",
    ")\n",
    "\n",
    "chain_novel_concept = LLMChain(llm=llm, prompt=prompt_novel_concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7cefa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (9) SPC Property Candidate identification \n",
    "## getting the properties of interest\n",
    "## For each of the referents, we want to find any individual descriptors, we also want to find and apply any given relations between referents\n",
    "\n",
    "template_properties = \"\"\"\n",
    "Determine the properties of the referents. Use the following procedure for each of the referents:\n",
    "1. The names of each of the referents itself should be added as a property to the list.\n",
    "2. From the utterance, extract all the adjectival descriptors used to describe the properties of the referents, and add to list.\n",
    "3. Add to this list, any relations (mentioned in the utterance) between two or more of the referents. Do NOT include any relations that can be reasonably assumed to be already covered by the meaning of the core propositional content. \n",
    "4. Return this list as a list of python dictionaries with the following format:\n",
    "\"text\": <NAME OF PROPERTY/DESCRIPTOR/RELATION>, \"arguments\": <LIST OF VARIABLE NAMES> \n",
    "\n",
    "where the variable names correspond to the variable names associated with each of the referents. Remember, the variable names have to be correct.\n",
    "\n",
    "Remember, DO NOT include in the list anything that is semantically similar to the core propositional content since it would be redundant\n",
    "\n",
    "utterance: \\n{utterance}\\n\n",
    "referents: \\n{referent_info}\\n\n",
    "core propositional content: \\n{cpc}\\n\n",
    "supplemental properties, descriptors and relations not in the core propositional content:\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "prompt_properties = PromptTemplate(\n",
    "    input_variables=[\"referent_info\", \"utterance\", \"cpc\"],\n",
    "    template=template_properties\n",
    ")\n",
    "\n",
    "chain_properties = LLMChain(llm=llm, prompt=prompt_properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87ebc922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (10) Candidate real properties: Find the properties (SPCs) in the consultant properties. THese are things the robot perception/cognition can understand\n",
    "## \"Real\" == concepts understandable to a robotic system (some consultant exists for it)\n",
    "\n",
    "template_candidate_realprops=\"\"\"\n",
    "Select a list of 5 candidate concept from the list of available concepts that is most semantically similar to the property associated with the referent, as understood in the context of the utterance. \n",
    "\n",
    "To decide the list of applicable candidate concepts, use the following procedure to systematically filter the list of available concepts:\n",
    "1. Compare the name and description (if any) of each concept in the available concepts to the properties. Narrow the list of concepts to include only those with a semantically similar name or description to ONLY the property. \n",
    "2. Return the narrowed list of concepts as a python list of string concept names followed by a colon and then a numeric score between 0 and 1 signifying the semantic similarity between the name or description of the available concepts and the property.\n",
    " Do NOT return this as a dictionary\n",
    " \n",
    "\\n\\n LIST OF AVAILABLE CONCEPTS \\n:\n",
    "{concepts}\n",
    "\n",
    "utterance: \\n{utterance}\\n\n",
    "property: \\n{prop}\\n\n",
    "candidate concepts:\n",
    "\"\"\"\n",
    "\n",
    "prompt_candidate_realprops = PromptTemplate(\n",
    "    input_variables=[\"utterance\",\"prop\", \"concepts\"],\n",
    "    template=template_candidate_realprops\n",
    ")\n",
    "\n",
    "chain_candidate_realprops = LLMChain(llm=llm, prompt=prompt_candidate_realprops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b884a191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (11) Cognitive Status\n",
    "\n",
    "template_cognitive_status= \"\"\"\n",
    "Determine the cognitive status of each of the referents mentioned in the bindings. Use the following procedure for each of the referents:\n",
    "\n",
    "1. Decide which ONE (and only one) of the following five cognitive statuses the referents could fall into:\n",
    "statuses: [INFOCUS, ACTIVATED\", FAMILIAR, DEFINITE, INDEFINITE]\n",
    "\n",
    "As shown in the table below, the Givenness Hierarchy is comprised of six hierarchically nested tiers of cognitive status, \n",
    "where information with one cognitive status can be inferred to also have all\n",
    "lower statuses. Each level of the GH is “cued” by a set\n",
    "of linguistic forms, as seen in the table. For example, the second\n",
    "row of the table shows that the definite use of “this” can be\n",
    "used to infer that the speaker assumes the referent to be at\n",
    "least activated to their interlocutor.\n",
    "\\n\\n\n",
    "Cognitive Status | Mnemonic Status | Form |\n",
    "-----------------|-----------------|------|\n",
    "INFOCUS | in the focus of attention | it |\n",
    "ACTIVATED | in short term memory | this,that,this N |\n",
    "FAMILIAR | in long term memory| that N |\n",
    "DEFINITE | in long term memory  or new | the N |\n",
    "INDEFINITE | new or hypothetical | a N |\n",
    "\\n\\n\n",
    "\n",
    "When deciding the one cognitive status for each referent, use the table above and compare the form (pronoun, determiner, article) of the utterance to its status.\n",
    "\n",
    "Return this as a python dictionary using the following format for the dictionary entry. Note it MUST be a python dictionary\n",
    "<VARIABLE NAME> : <COGNITIVE STATUS>\n",
    "\n",
    "where the variable names correspond to the variable names associated with each of the referents. Remember, the variable names have to be correct.\n",
    "\n",
    "\n",
    "utterance: \\n{utterance}\\n\n",
    "referents: \\n{referent_info}\\n\n",
    "cognitive statuses:\n",
    "\"\"\"\n",
    "\n",
    "prompt_cognitive_status = PromptTemplate(\n",
    "    input_variables=[\"referent_info\", \"utterance\"],\n",
    "    template=template_cognitive_status\n",
    ")\n",
    "\n",
    "chain_cognitive_status = LLMChain(llm=llm, prompt=prompt_cognitive_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe7615a",
   "metadata": {},
   "source": [
    "# Overall Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f185e3f",
   "metadata": {},
   "source": [
    "### Extract referents and intentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "719ac1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import string\n",
    "\n",
    "SIMILARITY_THRESHOLD = 0.8\n",
    "\n",
    "def extract_referents_intention(utterance):\n",
    "    \n",
    "    # Initialize the important datastructures\n",
    "    referents = []\n",
    "    intention = {}\n",
    "    descriptors = []\n",
    "    \n",
    "    # 1. Speech Act classification\n",
    "    print(f\"\\nProcessing utterance: {utterance}\")\n",
    "    print(\"[ ] Classifying speech act\", end=\"\\r\")\n",
    "    speech_act = chain_speech_act.run(utterance=utterance).lower() #string name \"want\" or \"wantBel\"\n",
    "    print(\"[X] Classifying speech act\")\n",
    "\n",
    "    intention['speech_act'] = speech_act\n",
    "    \n",
    "    \n",
    "    # 2. Central Referent Extraction\n",
    "    print(\"[ ] Extracting referents\", end=\"\\r\")\n",
    "    centralref = chain_centralref.run(utterance=utterance).lower()\n",
    "    centralref_type = chain_typeof.run(ref=centralref, types=types, utterance=utterance ).split(\" \")[-1]\n",
    "    centralref_type = centralref_type.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    referents.append({\"text\": centralref, \n",
    "                      \"type\":centralref_type, \n",
    "                      \"role\": \"central\"})\n",
    "    \n",
    "    \n",
    "    # 3. Supporting Referents Extraction\n",
    "    supprefs = chain_suppref.run(utterance=utterance, centralref=centralref).lower()\n",
    "    supprefs = ast.literal_eval(supprefs)\n",
    "    \n",
    "    #supprefs_full = [] #with type info\n",
    "    if supprefs:\n",
    "        for suppref in supprefs:\n",
    "            suppref_type = chain_typeof.run(ref=suppref, types=types, utterance=utterance ).split(\" \")[-1]\n",
    "            #supprefs_full.append(f\"{suppref}:{suppref_type}\")\n",
    "            \n",
    "            referents.append({\"text\": suppref, \n",
    "                              \"type\": suppref_type, \n",
    "                              \"role\": \"supplemental\"})\n",
    "            \n",
    "            \n",
    "    print(\"[X] Extracting referents\")\n",
    "    print(f\"Referents: {json.dumps(referents, indent=2)}\")\n",
    "\n",
    "    # 4. CPC extraction \n",
    "    \n",
    "    print(\"[ ] Extracting CPC\", end=\"\\r\")\n",
    "    cpc = chain_cpc.run(utterance=utterance, speechact=speech_act, centralref=centralref)\n",
    "    \n",
    "    intention['proposition'] = {\"text\": cpc.split(\":\")[0], \n",
    "                               \"type\": cpc.split(\":\")[-1]}\n",
    "    \n",
    "    \n",
    "    print(\"[X] Extracting CPC\")\n",
    "    print(f\"Intention: {json.dumps(intention, indent=2)}\")\n",
    "    \n",
    "    # Groundable meaning representation\n",
    "    gmr = {'referents': referents, \n",
    "           'intention': intention,\n",
    "           'descriptors': descriptors}\n",
    "    return gmr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d2cedd",
   "metadata": {},
   "source": [
    "### For requests: bind action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19b93d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bind_action(utterance, gmr, robot_model):\n",
    "    \"\"\"\n",
    "    1. Find candidate actions in robot's model repertoire\n",
    "    2. Select most similar one (based on name and description)\n",
    "    3. Bind the referents to this selected one \n",
    "    4. Update referents list \n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Find Candidates in the robot's action repertoire\n",
    "    print(\"[ ]Finding Candidate actions\", end=\"\\r\")\n",
    "    candidates = chain_candidate_realactions.run(utterance=utterance, \n",
    "                                                   centralref=central_referent(gmr),\n",
    "                                                   cpc=gmr['intention']['proposition']['text'],\n",
    "                                                   actions=robot_model['actions']) \n",
    "    candidates = ast.literal_eval(candidates)\n",
    "    print(\"[X] Finding Candidate actions\")\n",
    "    print(f\"\\tCandidate actions: {candidates}\")\n",
    "    \n",
    "    \n",
    "    # 2. Select best candidate\n",
    "    print(\"[ ] Selecting best candidate\", end=\"\\r\")\n",
    "    names, scores = clean_candidates(candidates)\n",
    "    best_candidate_name = select_best_candidate(names=names, scores=scores, threshold=SIMILARITY_THRESHOLD)\n",
    "    print(\"[X] Selecting best candidate\")\n",
    "    print(f\"\\tBest candidate action name: {best_candidate_name}\")\n",
    "    \n",
    "    # 3. Bind the referents to the selected best candidate\n",
    "    print(\"[ ] Binding best candidate\", end=\"\\r\")\n",
    "    bound_candidate=None\n",
    "    if not \"NONE\" in best_candidate_name:\n",
    "        # Bind best candidate to a real action   \n",
    "        print(f\"Central ref: {central_referent(gmr)}\")\n",
    "        bound_candidate = chain_bound_action.run(utterance=utterance,\n",
    "                                              centralref=central_referent(gmr),\n",
    "                                              supprefs=supp_referents(gmr),\n",
    "                                              candidate_full_info=find_dict_in_list(robot_model['actions'], \n",
    "                                                                                     \"name\", \n",
    "                                                                                     best_candidate_name))\n",
    "        # check if bound_candidate contains a \"NONE\"\n",
    "        if \"NONE\" in bound_candidate:\n",
    "            print(f\"We have a problem. There is a unbound variable here:\\n{bound_candidate}\")\n",
    "\n",
    "        # eval string\n",
    "        bound_candidate = ast.literal_eval(bound_candidate)\n",
    "        \n",
    "        print(\"[X] Binding best candidate\")\n",
    "        print(f\"\\tBound candidate: {bound_candidate}\")\n",
    "        \n",
    "        \n",
    "        # 4. Update referents and intention object \n",
    "        for referent in gmr['referents']:\n",
    "            for binding in bound_candidate['bindings']:           \n",
    "                if list(binding.values())[0] == referent['text']:\n",
    "                    referent['variable_name'] = list(binding.keys())[0]\n",
    "\n",
    "        # 4b. Update intentions object            \n",
    "        arguments = []    \n",
    "        for binding in bound_candidate['bindings']:  \n",
    "            if list(binding.values())[0] == \"self\":\n",
    "                arguments.append(\"self\") \n",
    "            else:\n",
    "                arguments.append(list(binding.keys())[0])        \n",
    "\n",
    "        gmr['intention']['proposition']['arguments'] = arguments\n",
    "        gmr['intention']['proposition']['name'] = bound_candidate['name']\n",
    "        \n",
    "    \n",
    "    return gmr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd37e052",
   "metadata": {},
   "source": [
    "### For statements/assertions: bind concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d31fde9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bind_concept(utterance, gmr, robot_model):\n",
    "    \"\"\"\n",
    "    1. Find candidate concepts in robot's model repertoire together with similarity scores\n",
    "    2. Choose the best found one \n",
    "    3. if the best one is below the similarity threshold, then create a novel concept\n",
    "    4. Bind the referents to either found concept or novel concept candidate\n",
    "    5. Update referent list and intention\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Find candidates in the robot's conceptual and perceptual repertoire \n",
    "    ## (look up consultant properties and belief rules, unless Belief is also a consultant)\n",
    "    print(\"[ ] Finding Candidate concepts\", end=\"\\r\")\n",
    "    candidates = chain_candidate_realconcepts.run(utterance=utterance, \n",
    "                                                   centralref=central_referent(gmr),\n",
    "                                                   cpc=gmr['intention']['proposition']['text'],\n",
    "                                                   concepts=robot_model['concepts']) \n",
    "    candidates = ast.literal_eval(candidates)\n",
    "    print(\"[X] Finding Candidate concepts\")\n",
    "    print(f\"\\tCandidates: {candidates}\")\n",
    "    \n",
    "    \n",
    "    # 2. Select best candidate above a threshold\n",
    "    print(f\"[ ] Selecting best candidate above similarity of {SIMILARITY_THRESHOLD}\", end=\"\\r\")\n",
    "    names, scores = clean_candidates(candidates)\n",
    "    best_candidate_name = select_best_candidate(names=names, scores=scores, threshold=SIMILARITY_THRESHOLD)\n",
    "    print(f\"[X] Selecting best candidate above similarity of {SIMILARITY_THRESHOLD}\")\n",
    "    print(f\"\\tBest candidate concept name: {best_candidate_name}\")\n",
    "    \n",
    "\n",
    "    bound_candidate = None\n",
    "    if not \"none\" in best_candidate_name.lower(): #Case where a property detector exists in the consultants\n",
    "        # Bind best candidate to a real concept\n",
    "        print(\"[ ] Binding best candidate concept\", end=\"\\r\")\n",
    "        bound_candidate = chain_bound_concept.run(utterance=utterance,\n",
    "                                              centralref=central_referent(gmr),\n",
    "                                              supprefs=supp_referents(gmr),\n",
    "                                              candidate_full_info=find_dict_in_list(robot_model['concepts'], \n",
    "                                                                                     \"name\", \n",
    "                                                                                     best_candidate_name))\n",
    "        \n",
    "        # check if bound_candidate contains a \"NONE\"\n",
    "        if \"NONE\" in bound_candidate:\n",
    "            print(f\"We have a problem. There is a unbound variable here:\\n{bound_candidate}\")\n",
    "\n",
    "        # eval string\n",
    "        bound_candidate = ast.literal_eval(bound_candidate)\n",
    "        print(\"[X] Binding best candidate\")\n",
    "        print(f\"\\tBound candidate: {bound_candidate}\")\n",
    "        \n",
    "    else: # Case of novel concept\n",
    "        \n",
    "        # need to hypothesize a name and arguments. \n",
    "        print(\"[ ] Instantiating novel concept\", end=\"\\r\")\n",
    "        new_concept = chain_novel_concept.run(utterance=utterance,\n",
    "                                             types=robot_model['types'],\n",
    "                                             centralref=central_referent(gmr),\n",
    "                                             supprefs=supp_referents(gmr),\n",
    "                                             cpc=gmr['intention']['proposition']['text'])\n",
    "\n",
    "        new_concept = ast.literal_eval(new_concept)\n",
    "        print(\"[X] Instantiating novel concept\")\n",
    "\n",
    "        print(\"[ ] Binding novel concept\", end=\"\\r\")\n",
    "        bound_candidate = chain_bound_concept.run(utterance=utterance,\n",
    "                                              centralref=central_referent(gmr),\n",
    "                                              supprefs=supp_referents(gmr),\n",
    "                                              candidate_full_info=find_dict_in_list([new_concept], \n",
    "                                                                                     \"name\", \n",
    "                                                                                     new_concept['name']))\n",
    "\n",
    "        print(\"[X] Binding novel concept\")\n",
    "\n",
    "        # check if bound_candidate contains a \"NONE\"\n",
    "        if \"NONE\" in bound_candidate:\n",
    "            print(f\"We have a problem. There is a unbound variable here:\\n{bound_candidate}\")\n",
    "\n",
    "        bound_candidate = ast.literal_eval(bound_candidate)\n",
    "    \n",
    "    if not bound_candidate:\n",
    "        print(\"\\nERROR!!!\\n\")\n",
    "        return gmr\n",
    "    \n",
    "    # 4. Update referents and intention object \n",
    "    for referent in gmr['referents']:\n",
    "        for binding in bound_candidate['bindings']:           \n",
    "            if list(binding.values())[0] == referent['text']:\n",
    "                referent['variable_name'] = list(binding.keys())[0]\n",
    "    \n",
    "    # 4b. Update intentions object            \n",
    "    arguments = []    \n",
    "    for binding in bound_candidate['bindings']:  \n",
    "        if list(binding.values())[0] == \"self\":\n",
    "            arguments.append(\"self\") \n",
    "        else:\n",
    "            arguments.append(list(binding.keys())[0])        \n",
    "    \n",
    "    gmr['intention']['proposition']['arguments'] = arguments\n",
    "    gmr['intention']['proposition']['name'] = bound_candidate['name']\n",
    "    \n",
    "    return gmr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596ef28c",
   "metadata": {},
   "source": [
    "### Extract descriptors and referential properties and relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9cc2278a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_supplementals(utterance, gmr, robot_model):\n",
    "\n",
    "    # 1. Getting candidate properties from language\n",
    "    print(\"[ ] Extracting Properties\", end=\"\\r\")\n",
    "    spc = chain_properties.run(utterance=utterance,\n",
    "                                     referent_info=gmr['referents'],\n",
    "                              cpc=gmr['intention']['proposition'])\n",
    "    descriptors = ast.literal_eval(spc)\n",
    "    print(\"[X] Extracting Properties\")\n",
    "    print(f\"\\tDescriptors: {descriptors}\")\n",
    "    \n",
    "    # 2. Finding consultant properties that match the identified spc \n",
    "    print(\"[ ] Finding Consultant properties similar to each of the Descriptors\", end=\"\\r\")\n",
    "    props_all = []\n",
    "    for descriptor in descriptors:\n",
    "    \n",
    "        ## 2.a. Get some candidate matches from the robot's perceptual/conceptual repertoire (Concepts)\n",
    "        candidates = chain_candidate_realprops.run(utterance=utterance,\n",
    "                                                                   concepts=robot_model['concepts'],\n",
    "                                                                   prop=descriptor )\n",
    "        candidates = ast.literal_eval(candidates)\n",
    "        print(f\"Debug: candidates: {candidates}\")\n",
    "        # 2.b. Pick the best one that is also above a threshold\n",
    "        names, scores = clean_candidates(candidates)\n",
    "        best_candidate_name = select_best_candidate(names=names, scores=scores, threshold=SIMILARITY_THRESHOLD)\n",
    "\n",
    "            \n",
    "        descriptor['name'] = best_candidate_name\n",
    "        \n",
    "    print(\"[X] Finding Consultants properties similar to SPC\")    \n",
    "    \n",
    "    gmr['descriptors'] = descriptors\n",
    "    \n",
    "    return gmr\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de61aa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_cognitive_status(utterance, gmr, robot_model):\n",
    "    print(\"[ ] Classifying cognitive status\", end=\"\\r\")\n",
    "    cognitive_statuses = chain_cognitive_status.run(utterance=utterance,\n",
    "                                                   referent_info=gmr['referents'])\n",
    "    \n",
    "    cognitive_statuses = ast.literal_eval(cognitive_statuses)\n",
    "    print(\"[X] Classifying cognitive status\")\n",
    "    print(f\"\\tCognitive Status: {cognitive_statuses}\")\n",
    "    \n",
    "    \n",
    "    for ref in gmr['referents']:\n",
    "        if \"variable_name\" in ref:\n",
    "            varname = ref['variable_name']\n",
    "            status = cognitive_statuses[varname]\n",
    "            ref['cognitive_status'] = status\n",
    "    \n",
    "    return gmr\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c22a37b",
   "metadata": {},
   "source": [
    "### Generate the actual parse from the GMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47abc5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_parse(gmr, speaker):\n",
    "    \n",
    "    # Build the CPC\n",
    "    if 'name' in gmr['intention']['proposition']:\n",
    "        cpc_template = \"{cpc_name}({cpc_variables})\"\n",
    "        cpc = cpc_template.format(cpc_name=gmr['intention']['proposition']['name'],\n",
    "                                 cpc_variables=\",\".join(gmr['intention']['proposition']['arguments']))\n",
    "    else:\n",
    "        cpc = \"NONE\"\n",
    "    \n",
    "                              \n",
    "    # Build the SPC\n",
    "    spcs = []\n",
    "    spc_template = \"{spc_name}({spc_variables})\"\n",
    "    for descriptor in gmr['descriptors']:\n",
    "        spc_predicate = spc_template.format(spc_name=descriptor['name'],\n",
    "                                     spc_variables=\",\".join(descriptor['arguments']))\n",
    "        spcs.append(spc_predicate)\n",
    "    \n",
    "    for ref in gmr['referents']:\n",
    "        if 'variable_name' in ref and 'cognitive_status' in ref:\n",
    "            spc_predicate = spc_template.format(spc_name=ref['cognitive_status'],\n",
    "                                         spc_variables=ref['variable_name'])\n",
    "            spcs.append(spc_predicate)\n",
    "                      \n",
    "    spc_all = \",\".join(spcs)                        \n",
    "                              \n",
    "    \n",
    "    final_template = \"{speech_act}({speaker},{cpc},{{{spcs}}})\"\n",
    "    parsed = final_template.format(speech_act=gmr['intention']['speech_act'],\n",
    "                                  speaker=speaker,\n",
    "                                  cpc=cpc,\n",
    "                                  spcs=spc_all)\n",
    "    \n",
    "    return parsed\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d713892b",
   "metadata": {},
   "source": [
    "### Overall Parsing Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6956592a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall Algorithm\n",
    "def parse(utterance, robot_model):\n",
    "    \n",
    "    gmr = extract_referents_intention(utterance)\n",
    "    if gmr['intention']['proposition']['type'] == \"action\":\n",
    "        gmr = bind_action(utterance, gmr, robot_model)\n",
    "    elif gmr['intention']['proposition']['type'] == \"concept\":\n",
    "        gmr = bind_concept(utterance, gmr, robot_model)\n",
    "    gmr = extract_supplementals(utterance, gmr, robot_model)\n",
    "    \n",
    "    gmr = classify_cognitive_status(utterance, gmr, robot_model)\n",
    "    \n",
    "    parsed = generate_parse(gmr, \"brad\")\n",
    "    output = {\"utterance\": utterance,\n",
    "                   \"robot_model\": robot_model,                  \n",
    "                   \"parse\": parsed,\n",
    "                   \"gmr\": gmr}\n",
    "    \n",
    "    print(f\"Utterance: {utterance}\")\n",
    "    print(f\"PARSE: {parsed}\")\n",
    "    \n",
    "    return output\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66264c3c",
   "metadata": {},
   "source": [
    "# Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babe67c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct Sample dev dataset \n",
    "import json \n",
    "\n",
    "with open(\"../data/actions_short.json\", \"r\") as f:\n",
    "    actions_dev = json.load(f)\n",
    "with open(\"../data/properties.json\", \"r\") as f:\n",
    "    concepts_dev = json.load(f)\n",
    "types = [\"physobj\", \"agent\", \"location\", \"pose\", \"action\", \"number\", \"direction\", \"name\", \"string\"]\n",
    "\n",
    "utterances = [\"then assemble the screw feeder\",\n",
    "             \"that m3 screw belongs to Evan\",\n",
    "             \"screw the m3 into that bottle on the conveyor\",\n",
    "             \"that m3 screw can couple with the conveyor\",\n",
    "             \"Can you please grab one of these m3 screws and screw it into that bottle on the conveyor\"]\n",
    "\n",
    "dataset = []\n",
    "for utt in utterances:\n",
    "    item = {\"utterance\": utt,\n",
    "            \"robot_model\": {\n",
    "                \"actions\": actions_dev,\n",
    "                \"concepts\": concepts_dev,\n",
    "                \"types\": types}\n",
    "           }\n",
    "    dataset.append(item)\n",
    "\n",
    "print(f\"Available utterances: {utterances}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdff3d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 4\n",
    "output = parse(utterance=dataset[idx]['utterance'],robot_model=dataset[idx]['robot_model'])\n",
    "#print(json.dumps(out, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cd1699",
   "metadata": {},
   "outputs": [],
   "source": [
    "output['gmr']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007ecbd3",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485dae40",
   "metadata": {},
   "source": [
    "### Evaluation Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dc60514d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data processing classes and functions\n",
    "import json\n",
    "\n",
    "def process_data_item(json_item):\n",
    "    actions = json_item['promptInfo']['actions']\n",
    "    concepts = json_item['promptInfo']['properties']\n",
    "    return actions, concepts\n",
    "\n",
    "class DIARCDataset:\n",
    "    def __init__(self, annotations_file, types=None):\n",
    "        with open(annotations_file, \"r\") as f:\n",
    "            self.data = json.load(f)\n",
    "        if not self.data:\n",
    "            print(\"Dataset did not load because .json file could not be opened\")\n",
    "            return\n",
    "        \n",
    "        # initialize dataset \n",
    "        self.types = types\n",
    "        if not self.types:\n",
    "            # default types\n",
    "            self.types = [\"physobj\", \"agent\", \"location\", \"pose\", \"action\", \"number\", \"direction\", \"name\", \"string\"]\n",
    "        self.initialize()\n",
    "    \n",
    "    def initialize(self):\n",
    "        \"\"\"\n",
    "        updates self.data into this nice list of items amenable for later processing. \n",
    "        \"\"\"\n",
    "        data = []\n",
    "        for item in self.data['utterances']:\n",
    "            actions = item['promptInfo']['actions']\n",
    "            concepts = item['promptInfo']['properties']\n",
    "            utterance = item['utteranceText']\n",
    "            desired_semantics= item['desiredSemantics']\n",
    "            \n",
    "            datum = {\"utterance\": utterance,\n",
    "                     'desired_semantics': desired_semantics,\n",
    "                     \"robot_model\": {\n",
    "                         \"actions\": actions,\n",
    "                         \"concepts\": concepts,\n",
    "                         \"types\": self.types}\n",
    "                    }\n",
    "            \n",
    "            data.append(datum)\n",
    "        self.data = data\n",
    "        \n",
    "    \n",
    "    def stats(self):\n",
    "        num_items = len(self.data)\n",
    "        print(f\"Number of utterances: {num_items}\")\n",
    "            \n",
    "    def xy(self):\n",
    "        \"\"\"\n",
    "        returns all the utterances and desired semantics\n",
    "        \"\"\"\n",
    "        utterances = []\n",
    "        desired_semantics = []\n",
    "        for item in self.data:\n",
    "            utt = item['utterance']\n",
    "            des = item['desired_semantics']\n",
    "            utterances.append(utt)\n",
    "            desired_semantics.append(des)\n",
    "        return utterances, desired_semantics\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc50781f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'utterance': 'place the donut left of the carrot',\n",
       " 'desired_semantics': 'INSTRUCT(tyler,self:agent,place(self:agent,leftof(VAR0,VAR1)),{carrot(VAR0),donut(VAR1),DEFINITE(VAR0),DEFINITE(VAR1)})',\n",
       " 'robot_model': {'actions': [{'name': 'carry',\n",
       "    'roles': ['?actor', '?objectRef', '?desiredLocation', '?initialLocation'],\n",
       "    'description': ''},\n",
       "   {'name': 'findGraspableObject',\n",
       "    'roles': ['?actor', '?objectRef'],\n",
       "    'description': '?actor looks for on(grasp_points, ?descriptors) in current FOV.\\n                This is exactly like findObject, except the ?descriptors are wrapped\\n                in an on(grasp_points, ?descriptors) predicate so vision will look for\\n                grasp points on the object.'},\n",
       "   {'name': 'approach',\n",
       "    'roles': ['?actor', '?desiredLocation'],\n",
       "    'description': ''},\n",
       "   {'name': 'getCurrGoals',\n",
       "    'roles': ['?actor'],\n",
       "    'description': 'get list of current goals and assert it to belief'},\n",
       "   {'name': 'initializeContainer',\n",
       "    'roles': ['?actor', '?refId'],\n",
       "    'description': ''},\n",
       "   {'name': 'pickup',\n",
       "    'roles': ['?actor', '?item', '?objectType', '?location'],\n",
       "    'description': 'picks up a ?item at a location and manages fluent property for locations'},\n",
       "   {'name': 'deliverkit',\n",
       "    'roles': ['?actor', '?item', '?destination'],\n",
       "    'description': '?actor delivers an ?item to ?destination'},\n",
       "   {'name': 'releaseObject',\n",
       "    'roles': ['?actor', '?objectRef', '?arm'],\n",
       "    'description': ''},\n",
       "   {'name': 'deliver',\n",
       "    'roles': ['?actor', '?recipe', '?location'],\n",
       "    'description': '?actor delivers a lunch box of ?recipe'},\n",
       "   {'name': 'startVisualSearch',\n",
       "    'roles': ['?actor', '?objectRef'],\n",
       "    'description': '?actor starts a visual search for ?objectRef in current FOV'},\n",
       "   {'name': 'createRecipeGoal',\n",
       "    'roles': ['?actor', '?recipeID'],\n",
       "    'description': 'creates goal state to submit to planner based on ?recipeID'},\n",
       "   {'name': 'placeOn',\n",
       "    'roles': ['?actor', '?objectRef_0', '?objectRef_1', '?arm'],\n",
       "    'description': ''},\n",
       "   {'name': 'pickup',\n",
       "    'roles': ['?actor', '?objectRef', '?arm'],\n",
       "    'description': ''},\n",
       "   {'name': 'take', 'roles': ['?actor', '?prep'], 'description': ''},\n",
       "   {'name': 'defineRecipe',\n",
       "    'roles': ['?actor', '?descriptor'],\n",
       "    'description': 'defines new recipe which is essentially a goal state to be achieved a planner'},\n",
       "   {'name': 'unstack',\n",
       "    'roles': ['?actor',\n",
       "     '?bottom',\n",
       "     '?top',\n",
       "     '?topprop',\n",
       "     '?botprop',\n",
       "     '?location'],\n",
       "    'description': ''},\n",
       "   {'name': 'handleAck',\n",
       "    'roles': ['?actor', '?speaker', '?addressee', '?semanticType'],\n",
       "    'description': 'Handle ack semantics'},\n",
       "   {'name': 'handleGreeting',\n",
       "    'roles': ['?actor',\n",
       "     '?speaker',\n",
       "     '?addressee',\n",
       "     '?greeting',\n",
       "     '?semanticType'],\n",
       "    'description': 'Handle greeting semantics'},\n",
       "   {'name': 'put', 'roles': ['?actor', '?prep'], 'description': ''},\n",
       "   {'name': 'unstack', 'roles': ['?actor', '?prep'], 'description': ''},\n",
       "   {'name': 'approach',\n",
       "    'roles': ['?actor', '?desiredLocation', '?initialLocation'],\n",
       "    'description': ''},\n",
       "   {'name': 'detectObjectAtLocation',\n",
       "    'roles': ['?actor', '?refId', '?property', '?location'],\n",
       "    'description': ''},\n",
       "   {'name': 'getTime',\n",
       "    'roles': ['?actor'],\n",
       "    'description': 'get the system time and assert it to belief'},\n",
       "   {'name': 'gotomovebase',\n",
       "    'roles': ['?actor', '?origin', '?destination'],\n",
       "    'description': 'the robot moves from ?origin to ?destination'},\n",
       "   {'name': 'stack',\n",
       "    'roles': ['?actor',\n",
       "     '?bottom',\n",
       "     '?top',\n",
       "     '?topprop',\n",
       "     '?botprop',\n",
       "     '?location'],\n",
       "    'description': ''},\n",
       "   {'name': 'findObject',\n",
       "    'roles': ['?actor', '?objectRef'],\n",
       "    'description': '?actor looks for object ref ?objectRef in current FOV. This is similar\\n                to lookForObject except with success/failure based on if object is found.'},\n",
       "   {'name': 'lookForObject',\n",
       "    'roles': ['?actor', '?objectRef'],\n",
       "    'description': '?actor looks for ?objectRef in current FOV and returns list of ?tokenIds'},\n",
       "   {'name': 'graspObject',\n",
       "    'roles': ['?actor', '?objectRef', '?arm'],\n",
       "    'description': ''},\n",
       "   {'name': 'carry',\n",
       "    'roles': ['?actor', '?objectRef', '?desiredLocation'],\n",
       "    'description': ''},\n",
       "   {'name': 'placeIn',\n",
       "    'roles': ['?actor', '?objectRef_0', '?objectRef_1', '?arm'],\n",
       "    'description': ''},\n",
       "   {'name': 'place', 'roles': ['?actor', '?prep'], 'description': ''},\n",
       "   {'name': 'translateLastGoal', 'roles': ['?actor'], 'description': ''},\n",
       "   {'name': 'putdown',\n",
       "    'roles': ['?actor', '?item', '?objectType', '?location'],\n",
       "    'description': 'puts down a (packable) ?item at a location and manages fluent property for locations'},\n",
       "   {'name': 'putin',\n",
       "    'roles': ['?actor', '?item', '?objectType', '?container', '?location'],\n",
       "    'description': 'puts down a (packable) ?item in a packable object'},\n",
       "   {'name': 'stack', 'roles': ['?actor', '?prep'], 'description': ''},\n",
       "   {'name': 'setupscene', 'roles': ['?actor'], 'description': ''},\n",
       "   {'name': 'moveObject',\n",
       "    'roles': ['?actor', '?objectRef', '?dir'],\n",
       "    'description': ''}],\n",
       "  'concepts': [{'name': 'this', 'roles': ['X:context']},\n",
       "   {'name': 'it', 'roles': ['X:context']},\n",
       "   {'name': 'that', 'roles': ['X:context']},\n",
       "   {'name': 'thing', 'roles': ['X:context']},\n",
       "   {'name': 'those', 'roles': ['X:context']},\n",
       "   {'name': 'they', 'roles': ['X:context']},\n",
       "   {'name': 'these', 'roles': ['X:context']},\n",
       "   {'name': 'doit', 'roles': ['X:dialog']},\n",
       "   {'name': 'dothis', 'roles': ['Xdialog:dialog']},\n",
       "   {'name': 'dothat', 'roles': ['Xdialog:dialog']},\n",
       "   {'name': 'that', 'roles': ['Xdialog:dialog']},\n",
       "   {'name': 'this', 'roles': ['X:physobj']},\n",
       "   {'name': 'any', 'roles': ['X:physobj']},\n",
       "   {'name': 'physobj', 'roles': ['X:physobj']},\n",
       "   {'name': 'person', 'roles': ['X:physobj']},\n",
       "   {'name': 'grasp_point', 'roles': ['X:physobj']},\n",
       "   {'name': 'on', 'roles': ['X:physobj', 'Y:physobj']},\n",
       "   {'name': 'caddy', 'roles': ['X:physobj']},\n",
       "   {'name': 'screwbin', 'roles': ['X:physobj']},\n",
       "   {'name': 'partOf', 'roles': ['X:physobj', 'Y:physobj']},\n",
       "   {'name': 'painkiller', 'roles': ['X:physobj']},\n",
       "   {'name': 'antiseptic', 'roles': ['X:physobj']},\n",
       "   {'name': 'bandagebox', 'roles': ['X:physobj']},\n",
       "   {'name': 'gearboxtop', 'roles': ['X:physobj']},\n",
       "   {'name': 'gearboxbottom', 'roles': ['X:physobj']},\n",
       "   {'name': 'medicalcaddy', 'roles': ['X:physobj']},\n",
       "   {'name': 'apple', 'roles': ['X:physobj']},\n",
       "   {'name': 'baseball', 'roles': ['X:physobj']},\n",
       "   {'name': 'glassbottle', 'roles': ['X:physobj']},\n",
       "   {'name': 'bowl', 'roles': ['X:physobj']},\n",
       "   {'name': 'carrot', 'roles': ['X:physobj']},\n",
       "   {'name': 'donut', 'roles': ['X:physobj']},\n",
       "   {'name': 'flowerpot', 'roles': ['X:physobj']},\n",
       "   {'name': 'computermouse', 'roles': ['X:physobj']},\n",
       "   {'name': 'car', 'roles': ['X:physobj']},\n",
       "   {'name': 'sportsbottle', 'roles': ['X:physobj']},\n",
       "   {'name': 'teddybear', 'roles': ['X:physobj']},\n",
       "   {'name': 'tennisball', 'roles': ['X:physobj']},\n",
       "   {'name': 'waterbottle', 'roles': ['X:physobj']},\n",
       "   {'name': 'box', 'roles': ['X:physobj']},\n",
       "   {'name': 'it', 'roles': ['X:physobj']},\n",
       "   {'name': 'this', 'roles': ['X:physobj']},\n",
       "   {'name': 'that', 'roles': ['X:physobj']},\n",
       "   {'name': 'thing', 'roles': ['X:physobj']},\n",
       "   {'name': 'those', 'roles': ['X:physobj']},\n",
       "   {'name': 'they', 'roles': ['X:physobj']},\n",
       "   {'name': 'these', 'roles': ['X:physobj']},\n",
       "   {'name': 'this', 'roles': ['X:movebaselocation']},\n",
       "   {'name': 'caddylocation', 'roles': ['VAR0:movebaselocation']},\n",
       "   {'name': 'screwlocation', 'roles': ['VAR0:movebaselocation']},\n",
       "   {'name': 'smallgearlocation', 'roles': ['VAR0:movebaselocation']},\n",
       "   {'name': 'largegearlocation', 'roles': ['VAR0:movebaselocation']},\n",
       "   {'name': 'tableELocation', 'roles': ['VAR0:movebaselocation']},\n",
       "   {'name': 'gearboxbottomlocation', 'roles': ['VAR0:movebaselocation']},\n",
       "   {'name': 'tableGLocation', 'roles': ['VAR0:movebaselocation']},\n",
       "   {'name': 'handoverlocation', 'roles': ['VAR0:movebaselocation']},\n",
       "   {'name': 'it', 'roles': ['X:movebaselocation']},\n",
       "   {'name': 'that', 'roles': ['X:movebaselocation']},\n",
       "   {'name': 'thing', 'roles': ['X:movebaselocation']},\n",
       "   {'name': 'those', 'roles': ['X:movebaselocation']},\n",
       "   {'name': 'they', 'roles': ['X:movebaselocation']},\n",
       "   {'name': 'these', 'roles': ['X:movebaselocation']}],\n",
       "  'types': ['physobj',\n",
       "   'agent',\n",
       "   'location',\n",
       "   'pose',\n",
       "   'action',\n",
       "   'number',\n",
       "   'direction',\n",
       "   'name',\n",
       "   'string']}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = DIARCDataset(annotations_file=\"../data/tasks/dev/CoRLTestOrdered.json\")\n",
    "dataset.data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970d7bec",
   "metadata": {},
   "source": [
    "### Spot Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5ad821f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing utterance: put the carrot in the bowl\n",
      "[X] Classifying speech act\n",
      "[X] Extracting referents\n",
      "Referents: [\n",
      "  {\n",
      "    \"text\": \"carrot\",\n",
      "    \"type\": \"physobj\",\n",
      "    \"role\": \"central\"\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"bowl\",\n",
      "    \"type\": \"physobj.\",\n",
      "    \"role\": \"supplemental\"\n",
      "  }\n",
      "]\n",
      "[X] Extracting CPC\n",
      "Intention: {\n",
      "  \"speech_act\": \"want\",\n",
      "  \"proposition\": {\n",
      "    \"text\": \"putting\",\n",
      "    \"type\": \"action\"\n",
      "  }\n",
      "}\n",
      "[X] Finding Candidate actions\n",
      "\tCandidate actions: ['placeIn:0.8', 'putin:0.9', 'pickup:0.6', 'carry:0.5', 'moveObject:0.6']\n",
      "[X] Selecting best candidate\n",
      "\tBest candidate action name: putin\n",
      "Central ref: {'text': 'carrot', 'type': 'physobj', 'role': 'central'}\n",
      "We have a problem. There is a unbound variable here:\n",
      "{\"name\": \"putin\",\"bindings\": [{\"VAR0\": \"self\"}, {\"VAR1\": \"carrot\"}, {\"VAR2\": \"NONE\"}, {\"VAR3\": \"bowl\"}, {\"VAR4\": \"NONE\"}]}\n",
      "[X] Binding best candidate\n",
      "\tBound candidate: {'name': 'putin', 'bindings': [{'VAR0': 'self'}, {'VAR1': 'carrot'}, {'VAR2': 'NONE'}, {'VAR3': 'bowl'}, {'VAR4': 'NONE'}]}\n",
      "[X] Extracting Properties\n",
      "\tDescriptors: [{'text': 'carrot', 'arguments': ['VAR1']}, {'text': 'bowl', 'arguments': ['VAR3']}]\n",
      "Debug: candidates: ['carrot:1', 'apple:0.2', 'baseball:0.1', 'glassbottle:0.1', 'bowl:0.1']\n",
      "Debug: candidates: ['bowl:1', 'box:0.5', 'flowerpot:0.5', 'glassbottle:0.5', 'sportsbottle:0.5']\n",
      "[X] Finding Consultants properties similar to SPC\n",
      "[X] Classifying cognitive status\n",
      "\tCognitive Status: {'VAR1': 'DEFINITE', 'VAR3': 'DEFINITE'}\n",
      "Utterance: put the carrot in the bowl\n",
      "PARSE: want(brad,putin(self,VAR1,VAR2,VAR3,VAR4),{carrot(VAR1),bowl(VAR3),DEFINITE(VAR1),DEFINITE(VAR3)})\n"
     ]
    }
   ],
   "source": [
    "idx = 11\n",
    "dataset.data[11]['utterance'] = \"put the carrot in the bowl\"\n",
    "types = [\"physobj\", \"agent\", \"location\", \"pose\", \"action\", \"number\", \"direction\", \"name\", \"string\"]\n",
    "output = parse(utterance=dataset.data[idx]['utterance'],robot_model=dataset.data[idx]['robot_model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4fbd9ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'referents': [{'text': 'tennis ball, bowl',\n",
       "   'type': 'physobj',\n",
       "   'role': 'central'}],\n",
       " 'intention': {'speech_act': '\"want\"',\n",
       "  'proposition': {'text': '\"putting', 'type': 'action\"'}},\n",
       " 'descriptors': [{'text': 'tennis ball',\n",
       "   'arguments': ['physobj'],\n",
       "   'name': 'tennisball'},\n",
       "  {'text': 'bowl', 'arguments': ['physobj'], 'name': 'bowl'}]}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['gmr']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01f7d6f",
   "metadata": {},
   "source": [
    "### Run Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1939233",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs=[]\n",
    "parses = []\n",
    "for idx,item in enumerate(dataset.data):\n",
    "    print(f\"\\n======== ITEM {idx} ============\")\n",
    "    print(f\"Utterance: {item['utterance']}\")\n",
    "    print(f\"DesiredSemantics: {item['desired_semantics']}\")\n",
    "    output = parse(utterance=item['utterance'],robot_model=item['robot_model'])\n",
    "    output['desired_semantics'] = item['desired_semantics']\n",
    "    outputs.append(output)\n",
    "    parses.append(output['parse'])\n",
    "    \n",
    "    # Throw into a file\n",
    "    with open('../data/output/out.json', 'w') as fout:\n",
    "        json.dump(outputs, fout, indent=4, sort_keys=True)\n",
    "    print(\"==================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323b8855",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/output/out.json\", \"r\") as fin:\n",
    "    results = json.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d827378",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176f7bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_parses = []\n",
    "for r in results:\n",
    "    item  = f\"{r['utterance']}, {r['parse']}, {r['desired_semantics']}\"\n",
    "    result_parses.append(item)\n",
    "\n",
    "with open(\"../data/output/result_parses.csv\", \"w\") as fout:\n",
    "    for line in result_parses:\n",
    "        fout.write(f\"{line}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f51016a",
   "metadata": {},
   "source": [
    "# Next steps\n",
    "\n",
    "- think about how to generalize this for PDDL\n",
    "    \n",
    "- the action/concept repertoire seems to be off here...many utterances are not supported by the underlying model \n",
    "- think about  what the two papers will look like\n",
    "    - constraint understanding --> challenge here is for formal verifiability? \n",
    "    - parsing --> challenge here is to define an NLP pipeline that can ground human-robot interactions. \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
