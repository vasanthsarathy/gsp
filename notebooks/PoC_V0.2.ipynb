{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bce98a8",
   "metadata": {},
   "source": [
    "# Version 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db2a7e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf479bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LLM \n",
    "\n",
    "#llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.0)\n",
    "llm = OpenAI(temperature=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060bec82",
   "metadata": {},
   "source": [
    "## (1) Speech Act Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1774002",
   "metadata": {},
   "outputs": [],
   "source": [
    "## (1) Speech Act Classification \n",
    "\n",
    "template_speech_act_classifier= \"\"\"\n",
    "Decide whether the utterance below from a speaker to a listener is one of INSTRUCT, STATEMENT, GREETING, QUESTIONWH ('wh', questions), QUESTIONYN ('yes/no' questions), ACK (e.g. \"yes\" or \"ok\"), or UNKNOWN \n",
    "An INSTRUCT is an imperative statement or a request by the speaker to have the listener do an action or stop doing an action.\n",
    "A QUESTIONWH is a 'wh' query (what, why, when, where, who) or request from a speaker for more information from the listener about the listeners knowledge, beliefs or perceptions\n",
    "A QUESTIONYN is a 'yes/no' query or request from a speaker for more information from the listener about the listeners knowledge, beliefs or perceptions, but the speaker expects a yes or no for an answer\n",
    "A STATEMENT is a statement of fact or opinion that the speaker conveys to a listener. \n",
    "A GREETING is an expression of social connection establishing the start of the conversation. E.g., \"Hello\"\n",
    "A ACK is an acknowledgement (either \"yes\" or \"no\").\n",
    "A UNKNOWN is an utterance not one of the above. \n",
    "\n",
    "utterance: \\n{utterance}\\n\n",
    "act:\n",
    "\"\"\"\n",
    "\n",
    "prompt_speech_act_classifier = PromptTemplate(\n",
    "    input_variables=[\"utterance\"],\n",
    "    template=template_speech_act_classifier\n",
    ")\n",
    "\n",
    "chain_speech_act_classifier = LLMChain(llm=llm, prompt=prompt_speech_act_classifier)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d694820",
   "metadata": {},
   "source": [
    "## (2) Central Referrent being talked about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0009cff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1. CENTRAL REF\n",
    "What is the central item (which could be a single thing or a collection of things) that is being referred to in the below sentence?\n",
    "sentence: stack some lemons on the table central \n",
    "referent: lemons\n",
    "→ What are they talking about? \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "template_centralref = \"\"\"\n",
    "What is the central item (which could be a single thing or a collection of things) that is being referred to in the below sentence?\n",
    "\n",
    "sentence: \\n{utterance}\\n \n",
    "referent:\n",
    "\"\"\"\n",
    "\n",
    "prompt_centralref = PromptTemplate(\n",
    "    input_variables=[\"utterance\"],\n",
    "    template=template_centralref\n",
    ")\n",
    "\n",
    "chain_centralref = LLMChain(llm=llm, prompt=prompt_centralref)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c347ea6f",
   "metadata": {},
   "source": [
    "## (3A) What central action is performed on central referent (if INSTRUCT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76bf5030",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "2a. ACTION ON CENTRAL REF (if INSTRUCT)\n",
    "In the below sentence, describe the action that is being performed on the central referent \n",
    "sentence: stack some lemons on the table \n",
    "central referent: lemons |\n",
    "action: stacking\n",
    "→ What do they want me to do with the thing they are talking about? \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "template_centralaction = \"\"\"\n",
    "In the below sentence, describe the action that is being performed on the central referent \n",
    "\n",
    "sentence: \\n{utterance}\\n\n",
    "central referent: \\n{centralref}\\n\n",
    "action:\n",
    "\"\"\"\n",
    "\n",
    "prompt_centralaction = PromptTemplate(\n",
    "    input_variables=[\"utterance\", \"centralref\"],\n",
    "    template=template_centralaction\n",
    ")\n",
    "\n",
    "chain_centralaction = LLMChain(llm=llm, prompt=prompt_centralaction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcab297",
   "metadata": {},
   "source": [
    "## (4A) What \"feasible action\" (if any) is being described (if INSTRUCT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc760386",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "3a. ACTION GROUNDING (INSTRUCT)\n",
    "3a-i. Generate \n",
    "Given a set of actions….select one that is close in meaning to \"action\". If none, then return NONE. If several, then return AMBIGUOUS.  \n",
    "3a-ii. Test \n",
    "Check if the parameter types of the action sufficiently captures the nature of the referent. \n",
    ">> Iterate on 3a until stopping condition or action found. \n",
    "\n",
    "→ Can I really do the thing they want me to do? \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# GENERATE [Select a candidate action]\n",
    "template_candidateaction = \"\"\"\n",
    "Select an action from the list of available actions that is most relevant to the given central action performed on the central referent as understood in the context of the utterance. \n",
    "To decide the applicable action, use the following procedure to systematically filter the most relevant action:\n",
    "1. Compare the name and description of the action to the central action. Narrow the list of actions to include only those with a semantically similar name or description to the central action. \n",
    "2. If the narrowed list contains one action, then return its name. If it contains no actions, then return NONE. If it contains more than one action, then return AMBIGUOUS.\n",
    "\n",
    "\\n\\n LIST OF AVAILABLE ACTIONS \\n:\n",
    "{actions}\n",
    "\n",
    "utterance: \\n{utterance}\\n\n",
    "central referent: \\n{centralref}\\n\n",
    "central action: \\n{centralaction}\\n\n",
    "candidate action:\n",
    "\"\"\"\n",
    "\n",
    "prompt_candidateaction = PromptTemplate(\n",
    "    input_variables=[\"utterance\", \"actions\", \"centralref\", \"centralaction\"],\n",
    "    template=template_candidateaction\n",
    ")\n",
    "\n",
    "chain_candidateaction = LLMChain(llm=llm, prompt=prompt_candidateaction)\n",
    "\n",
    "# TEST\n",
    "template_typeof = \"\"\"\n",
    "Determine whether or not the central referent item mentioned below is one of the types also provided below. To check if the referent is of a type, follow the below procedure\n",
    "1. Iterate through each item mentioned in the list of types. \n",
    "2. For each item X in the list of types expand on the meaning of each item, and then ask if the central referent is of type X given that meaning. \n",
    "3. If the central referent is of type X in the list, return X.\n",
    "\n",
    "\\n\\n EXAMPLE \\n\n",
    "central referent: lemon\n",
    "types: ['area', 'physobj', 'location']\n",
    "typeOf: Looking through the items in the list of types above. physobj is a physical object. lemon is a type of physical object. So, it is of type physobj\n",
    "\n",
    "Remember, return specifically ONE of the items in the list, or if none apply then return NONE. \n",
    "\n",
    "central referent: \\n{centralref}\\n\n",
    "types: \\n{types}\\n\n",
    "typeOf:\n",
    "\"\"\"\n",
    "\n",
    "prompt_typeof = PromptTemplate(\n",
    "    input_variables=[\"centralref\", \"types\"],\n",
    "    template=template_typeof\n",
    ")\n",
    "\n",
    "chain_typeof = LLMChain(llm=llm, prompt=prompt_typeof)\n",
    "\n",
    "# Note: will need to input \"types\" which we can get from the actions list. Also, will need to post process as we use CoT\n",
    "# Note: we also don't consider multiple referents. Would need to check if action has additional parameters and then ask for clarification or additional input\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae86edf",
   "metadata": {},
   "source": [
    "## (3B) What concept is being told about the central referent (if STATEMENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a1789bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In the below sentence, describe the concept that is being associated with the central referent \n",
    "sentence: The lemons on the table are sour. \n",
    "central referent: lemons \n",
    "concept: sourness\n",
    "→ What do they want me to know about the thing they are talking about? \n",
    "\"\"\"\n",
    "\n",
    "template_centralconcept = \"\"\"\n",
    "In the below sentence, describe the concept that is being associated with the central referent. Your answer should be a single word. \n",
    "\n",
    "sentence: \\n{utterance}\\n \n",
    "central referent: \\n{centralref}\n",
    "concept:\n",
    "\"\"\"\n",
    "\n",
    "prompt_centralconcept = PromptTemplate(\n",
    "    input_variables=[\"utterance\", \"centralref\"],\n",
    "    template=template_centralconcept\n",
    ")\n",
    "\n",
    "chain_centralconcept = LLMChain(llm=llm, prompt=prompt_centralconcept)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59f06ee",
   "metadata": {},
   "source": [
    "## (4B) What \"feasible concept\" (if any) is being described (if STATEMENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c5b0c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "3b. CONCEPT GROUNDING (STATEMENT)\n",
    "3b-i. Generate \n",
    "Given a set of known concepts… select one that is close in meaning to \"concept\". If several then return AMBIGUOUS. If none, then create a new concept. \n",
    "3b-ii. Test (not apply if new concept) \n",
    "Check if the parameter types of the concept sufficiently capture the nature of the referent \n",
    "→ Do I already know the thing they want me to know? \n",
    "\n",
    "note: if 3a or 3b requires more arguments than referents (e.g., ditransitive verb) then need to revisit the sentence \n",
    "\"\"\"\n",
    "\n",
    "# GENERATE\n",
    "template_candidateconcept = \"\"\"\n",
    "Select a concept from the list available concepts (or properties) that is most relevant to the given central concept as associated with the central reference and understood in the context of the utterance.\n",
    "To decide the applicable concept, use the following procedure to systematically filter the most relevant concept:\n",
    "1. Compare the name and description of the concept in the list of the concepts to the central concept. Narrow the list of properties to include only those with a semantically similar name or description to the central concept. \n",
    "2. If the narrowed list contains one concept, then return its name. If the narrowed list contains no concepts, then generate a new symbol with the suffix \"_GENSYM\" (for example a central concept \"ownership\" could be \"own_GENSYM\")\n",
    "\n",
    "\\n\\n LIST OF AVAILABLE PROPERTIES/CONCEPTS \\n:\n",
    "{concepts}\n",
    "\n",
    "utterance: \\n{utterance}\\n\n",
    "central referent: \\n{centralref}\\n\n",
    "central concept: \\n{centralconcept}\\n\n",
    "candidate concept:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt_candidateconcept = PromptTemplate(\n",
    "    input_variables=[\"utterance\", \"concepts\", \"centralref\", \"centralconcept\"],\n",
    "    template=template_candidateconcept\n",
    ")\n",
    "\n",
    "chain_candidateconcept = LLMChain(llm=llm, prompt=prompt_candidateconcept)\n",
    "\n",
    "\n",
    "# TEST\n",
    "### Same as test available earlier. See \"chain_typeof\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e3b900",
   "metadata": {},
   "source": [
    "## (5) Generate Variables for the CPC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfa56ec",
   "metadata": {},
   "source": [
    "# Get Actions and Concepts Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d726db19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Helper method \n",
    "def reformat_term(input_string):\n",
    "    # Extract function name\n",
    "    name_match = re.match(r\"(\\w+)\\(\", input_string)\n",
    "    if not name_match:\n",
    "        return None\n",
    "\n",
    "    function_name = name_match.group(1)\n",
    "\n",
    "    # Extract parameters and type\n",
    "    params_type_match = re.search(r\"\\((.*?)\\)\", input_string)\n",
    "    if not params_type_match:\n",
    "        return None\n",
    "\n",
    "    params_type_string = params_type_match.group(1)\n",
    "    params_type_list = params_type_string.split(',')\n",
    "\n",
    "    parameters = []\n",
    "    types = []\n",
    "\n",
    "    for param_type in params_type_list:\n",
    "        param_type = param_type.strip()\n",
    "\n",
    "        if ':' in param_type:\n",
    "            param, type_ = param_type.split(':')\n",
    "            parameters.append(param.strip())\n",
    "            types.append(type_.strip())\n",
    "        else:\n",
    "            parameters.append(param_type)\n",
    "            types.append(None)\n",
    "\n",
    "    result = {\n",
    "        'name': function_name,\n",
    "        'parameters': parameters,\n",
    "        'types': types\n",
    "    }\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# Robot capabilities\n",
    "actions_file = \"../data/actions.txt\"\n",
    "concepts_file = \"../data/concepts.txt\"\n",
    "\n",
    "with open(actions_file, \"r\") as f:\n",
    "    raw_actions = f.readlines()[0]\n",
    "    \n",
    "with open(concepts_file, \"r\") as f:\n",
    "    raw_concepts = f.readlines()[0]\n",
    "    \n",
    "actions = [reformat_term(x) for x in raw_actions.split(\" \")]\n",
    "\n",
    "concepts = [reformat_term(x) for x in raw_concepts.split(\" \")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f27ac8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'doit', 'parameters': ['X'], 'types': ['dialog']},\n",
       " {'name': 'dothis', 'parameters': ['Xdialog'], 'types': ['dialog']},\n",
       " {'name': 'dothat', 'parameters': ['Xdialog'], 'types': ['dialog']},\n",
       " {'name': 'that', 'parameters': ['Xdialog'], 'types': ['dialog']},\n",
       " {'name': 'this', 'parameters': ['X'], 'types': ['physobj']},\n",
       " {'name': 'any', 'parameters': ['X'], 'types': ['physobj']},\n",
       " {'name': 'physobj', 'parameters': ['X'], 'types': ['physobj']},\n",
       " {'name': 'person', 'parameters': ['X'], 'types': ['physobj']},\n",
       " {'name': 'grasp_point', 'parameters': ['X'], 'types': ['physobj']},\n",
       " {'name': 'on', 'parameters': ['X', 'Y'], 'types': ['physobj', 'physobj']},\n",
       " {'name': 'caddy', 'parameters': ['X'], 'types': ['physobj']},\n",
       " {'name': 'screwbin', 'parameters': ['X'], 'types': ['physobj']},\n",
       " {'name': 'partOf', 'parameters': ['X', 'Y'], 'types': ['physobj', 'physobj']},\n",
       " {'name': 'painkiller', 'parameters': ['X'], 'types': ['physobj']},\n",
       " {'name': 'antiseptic', 'parameters': ['X'], 'types': ['physobj']},\n",
       " {'name': 'bandagebox', 'parameters': ['X'], 'types': ['physobj']},\n",
       " {'name': 'gearboxtop', 'parameters': ['X'], 'types': ['physobj']},\n",
       " {'name': 'gearboxbottom', 'parameters': ['X'], 'types': ['physobj']},\n",
       " {'name': 'medicalcaddy', 'parameters': ['X'], 'types': ['physobj']},\n",
       " {'name': 'temi', 'parameters': ['X'], 'types': ['physobj']},\n",
       " {'name': 'it', 'parameters': ['X'], 'types': ['physobj']},\n",
       " {'name': 'this', 'parameters': ['X'], 'types': ['physobj']},\n",
       " {'name': 'that', 'parameters': ['X'], 'types': ['physobj']},\n",
       " {'name': 'thing', 'parameters': ['X'], 'types': ['physobj']},\n",
       " {'name': 'those', 'parameters': ['X'], 'types': ['physobj']},\n",
       " {'name': 'they', 'parameters': ['X'], 'types': ['physobj']},\n",
       " {'name': 'these', 'parameters': ['X'], 'types': ['physobj']},\n",
       " {'name': 'this', 'parameters': ['X'], 'types': ['movebaselocation']},\n",
       " {'name': 'caddylocation',\n",
       "  'parameters': ['VAR0'],\n",
       "  'types': ['movebaselocation']},\n",
       " {'name': 'screwlocation',\n",
       "  'parameters': ['VAR0'],\n",
       "  'types': ['movebaselocation']},\n",
       " {'name': 'smallgearlocation',\n",
       "  'parameters': ['VAR0'],\n",
       "  'types': ['movebaselocation']},\n",
       " {'name': 'largegearlocation',\n",
       "  'parameters': ['VAR0'],\n",
       "  'types': ['movebaselocation']},\n",
       " {'name': 'tableELocation',\n",
       "  'parameters': ['VAR0'],\n",
       "  'types': ['movebaselocation']},\n",
       " {'name': 'gearboxbottomlocation',\n",
       "  'parameters': ['VAR0'],\n",
       "  'types': ['movebaselocation']},\n",
       " {'name': 'tableGLocation',\n",
       "  'parameters': ['VAR0'],\n",
       "  'types': ['movebaselocation']},\n",
       " {'name': 'handoverlocation',\n",
       "  'parameters': ['VAR0'],\n",
       "  'types': ['movebaselocation']},\n",
       " {'name': 'it', 'parameters': ['X'], 'types': ['movebaselocation']},\n",
       " {'name': 'that', 'parameters': ['X'], 'types': ['movebaselocation']},\n",
       " {'name': 'thing', 'parameters': ['X'], 'types': ['movebaselocation']},\n",
       " {'name': 'those', 'parameters': ['X'], 'types': ['movebaselocation']},\n",
       " {'name': 'they', 'parameters': ['X'], 'types': ['movebaselocation']},\n",
       " {'name': 'these', 'parameters': ['X'], 'types': ['movebaselocation']},\n",
       " {'name': 'this', 'parameters': ['X'], 'types': ['context']},\n",
       " {'name': 'it', 'parameters': ['X'], 'types': ['context']},\n",
       " {'name': 'that', 'parameters': ['X'], 'types': ['context']},\n",
       " {'name': 'thing', 'parameters': ['X'], 'types': ['context']},\n",
       " {'name': 'those', 'parameters': ['X'], 'types': ['context']},\n",
       " {'name': 'they', 'parameters': ['X'], 'types': ['context']},\n",
       " {'name': 'these', 'parameters': ['X'], 'types': ['context']}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c2b2bc",
   "metadata": {},
   "source": [
    "## RUN PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b48413a9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import json\n",
    "\n",
    "\n",
    "# Helper Method\n",
    "# Given a list of dictionaries, and a key, return the entry in the list that matches\n",
    "def find_dict_in_list(lst, key, target):\n",
    "    for item in lst:\n",
    "        if not key in item:\n",
    "            #print(\"Key not in Dict\")\n",
    "            return None\n",
    "        if item[key] == target:\n",
    "            return item\n",
    "    #print(\"Nothing found\")\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def parse(speaker, listener, utterance, actions, concepts):\n",
    "    \n",
    "    output = {}\n",
    "    \n",
    "    # 1 Speech act classification\n",
    "    speech_act = chain_speech_act_classifier.run(utterance=utterance)\n",
    "    \n",
    "    # 2. Central Referent Extraction\n",
    "    centralref = chain_centralref.run(utterance=utterance)\n",
    "    \n",
    "    if speech_act == 'INSTRUCT':\n",
    "        # 3A. Central Action\n",
    "        centralcpc = chain_centralaction.run(utterance=utterance, centralref=centralref)\n",
    "        \n",
    "        done = False\n",
    "        cpc_search_tries = 0\n",
    "        while not done: \n",
    "            cpc_search_tries += 1\n",
    "            # 4A -- Feasible Canidate Action (Generate)\n",
    "            candidatecpc_name = chain_candidateaction.run(utterance=utterance,\n",
    "                                                       actions=[x['name'] for x in actions],\n",
    "                                                       centralref=centralref,\n",
    "                                                       centralaction=centralcpc) \n",
    "            candidatecpc = find_dict_in_list(actions, 'name', candidatecpc_name)\n",
    "            \n",
    "            # 4A -- Test feasible candidate (Test)\n",
    "            parameters = candidatecpc['parameters']\n",
    "            typeof = chain_typeof.run(centralref=centralref, types=parameters).split(\" \")[-1]\n",
    "            typeof = ''.join(e for e in typeof if e.isalnum())\n",
    "            index_of_param = -1\n",
    "            if not typeof.lower() == 'none':\n",
    "                index_of_param = parameters.index(typeof)\n",
    "                \n",
    "            output = {\n",
    "                'speaker': speaker,\n",
    "                'listener': listener,\n",
    "                'utterance': utterance,\n",
    "                'speech_act': speech_act,\n",
    "                'centralref': centralref,\n",
    "                'centralcpc': centralcpc,\n",
    "                'candidatecpc': candidatecpc,\n",
    "                'typeof': typeof,\n",
    "                'index_of_param': index_of_param,\n",
    "                'meta': {'cpc_search_tries': action_search_tries}\n",
    "\n",
    "            }\n",
    "            \n",
    "            # TESTING HACK -- REMOVE WHEN DONE --> should be thresholding how many times Gen-test will be retried. \n",
    "            done = True\n",
    "            \n",
    "    elif speech_act == 'STATEMENT':\n",
    "        # 3B Central Concept\n",
    "        centralcpc = chain_centralconcept.run(utterance=utterance, centralref=centralref)\n",
    "        \n",
    "        done = False\n",
    "        cpc_search_tries = 0\n",
    "        while not done: \n",
    "            cpc_search_tries += 1\n",
    "            # 4A -- Feasible Canidate Concept (Generate)\n",
    "            candidatecpc_name = chain_candidateconcept.run(utterance=utterance,\n",
    "                                                       concepts=[x['name'] for x in concepts],\n",
    "                                                       centralref=centralref,\n",
    "                                                       centralconcept=centralcpc) \n",
    "            \n",
    "            candidatecpc = find_dict_in_list(concepts, 'name', candidatecpc_name)\n",
    "            # dealing with novel concepts\n",
    "            if not candidatecpc:\n",
    "                candidatecpc = candidatecpc_name\n",
    "                typeof = \"\"\n",
    "                index_of_param = -1\n",
    "            else:\n",
    "                # 4A -- Test feasible candidate (Test)\n",
    "                types = candidatecpc['types']\n",
    "                typeof = chain_typeof.run(centralref=centralref, types=types).split(\" \")[-1]\n",
    "                typeof = ''.join(e for e in typeof if e.isalnum())\n",
    "                index_of_param = -1\n",
    "                if not typeof.lower() == 'none':\n",
    "                    index_of_param = types.index(typeof)\n",
    "\n",
    "            output = {\n",
    "                'speaker': speaker,\n",
    "                'listener': listener,\n",
    "                'utterance': utterance,\n",
    "                'speech_act': speech_act,\n",
    "                'centralref': centralref,\n",
    "                'centralcpc': centralcpc,\n",
    "                'candidatecpc': candidatecpc,\n",
    "                'typeof': typeof,\n",
    "                'index_of_param': index_of_param,\n",
    "                'meta': {'cpc_search_tries': cpc_search_tries}\n",
    "\n",
    "            }\n",
    "            \n",
    "            # TESTING HACK -- REMOVE WHEN DONE --> should be thresholding how many times Gen-test will be retried. \n",
    "            done = True\n",
    "        \n",
    "        \n",
    "    else: \n",
    "        pass\n",
    "    \n",
    "    \n",
    "    \n",
    "    return \"\", output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab634188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\n",
      "  \"speaker\": \"vasanth\",\n",
      "  \"listener\": \"self\",\n",
      "  \"utterance\": \"that spot is where the caddy goes\",\n",
      "  \"speech_act\": \"STATEMENT\",\n",
      "  \"centralref\": \"Caddy\",\n",
      "  \"centralcpc\": \"Location\",\n",
      "  \"candidatecpc\": {\n",
      "    \"name\": \"caddylocation\",\n",
      "    \"parameters\": [\n",
      "      \"VAR0\"\n",
      "    ],\n",
      "    \"types\": [\n",
      "      \"movebaselocation\"\n",
      "    ]\n",
      "  },\n",
      "  \"typeof\": \"NONE\",\n",
      "  \"index_of_param\": -1,\n",
      "  \"meta\": {\n",
      "    \"cpc_search_tries\": 1\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "examples = [\n",
    "    \"pick up the box\",\n",
    "    \"pick up the box that is on the table next to the lamp\",\n",
    "    \"that thing over there is a mug\",\n",
    "    \"that lemon belongs to Evan\"\n",
    "]\n",
    "\n",
    "\n",
    "utterance = \"that spot is where the caddy goes\"\n",
    "parsed, output = parse(\"vasanth\", \"self\", utterance, actions, concepts)\n",
    "\n",
    "print(parsed)\n",
    "print(json.dumps(output, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a84793ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def nlu(utterance):\n",
    "    parsed, output = parse(\"brad\", \"self\", utterance, actions, concepts)\n",
    "    return parsed, output, json.dumps(actions, indent=2), json.dumps(concepts, indent=2)\n",
    "\n",
    "demo = gr.Interface(fn=nlu, \n",
    "                    inputs=\"text\", \n",
    "                    outputs=[\"text\", \"text\", \"text\", \"text\"],\n",
    "                   examples=examples)\n",
    "\n",
    "demo.launch(debug=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20629570",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
